# log4j client configuration.
#
# Note: This is the configuration that the application should use.  It
# sends log events to a log4j server using the [socketLogger].  This
# lets you aggregate log events across a cluster.  The log4j server
# handles things like rolling over the log files. 
#
# Note: If the network link to the log4j server goes down, then the
# application will block.  This makes that link a single point of
# failure.
#
# Note: If the log4j server goes down, then a warning will be logged
# on stderr for the application.
#
# Note: The application will proceed no faster than the TCP packets
# containing the log events that are being sent to the server. This
# should not be a problem unless very detailed logging is turned on.
#
# Note: The layout is NOT used by the SocketAppender.  The layout is
# decided on the other end by the log4j server's configuration file.
#
# You can also enable local logging.  You will have to choose a well
# known location for the log file since the same log4j configuration
# is used by all of the services (at least, by all of the same service
# type since you can not have a per-service instance override) in the
# federation.

##
# Configure appenders to be used.
##

# Setup relays log messages to a remote socket logger. The remote socket
# logger is then configured in [log4jServer.properties].  It will log ALL
# on the detailLog, ERROR+ on the errorLog and events on the eventLog. 
# However, it will ONLY log those messages which are logged here onto the
# [socketLogger].
# 
# Note: ERROR+ is also logged onto a local console so you can see any problems
# during startup when the socket logger might not be running.
#
# Note: You can control many of the logger levels (on a service-by-service
# bases) using remote JMX MBeans.
#
log4j.rootCategory=WARN, console

# Loggers.
log4j.logger.com.bigdata=WARN

# This package is extremely verbose.
log4j.logger.com.bigdata.btree=WARN

log4j.logger.com.bigdata.jini.start=INFO
log4j.logger.com.bigdata.jini.start.MonitorConfigZNodeTask=WARN
#log4j.logger.com.bigdata.jini.start.ManageLogicalServiceTask=WARN
log4j.logger.com.bigdata.jini.start.ServiceConfigurationZNodeMonitorTask=WARN
log4j.logger.com.bigdata.jini.start.MonitorCreatePhysicalServiceLocksTask=WARN
log4j.logger.com.bigdata.jini.start.config=WARN

# This logs the output of the ServicesManagerServer's child processes. You may
# need to raise this to INFO to figure out what is going wrong with a child
# process start.
log4j.logger.com.bigdata.jini.start.process=INFO

# The bigdata server abstract base class.
log4j.logger.com.bigdata.service.AbstractServer=INFO

# The resources package manages the persistent state for the data services,
# including synchronous and asynchronous overflow processing, moves, splits,
# etc.
#log4j.logger.com.bigdata.resources.AsynchronousOverflowTask=INFO

# To debug the counter collection.
#log4j.logger.com.bigdata.counters=INFO

# To see the httpd log (performance counter and event reporting via httpd)
#log4j.logger.com.bigdata.util.httpd.NanoHTTPD=INFO

# This logs the bigdata events, which are things like index partition splits,
# joins, moves, synchronous and asynchronous overflow, as well as index segment
# builds, etc.
log4j.logger.com.bigdata.service.EventReceiver=INFO

# The zookeeper integration package.
log4j.logger.com.bigdata.zookeeper=WARN

# This class is way too verbose (SendThread @ WARN)
log4j.logger.org.apache.zookeeper.ClientCnxn=ERROR

# If trying to debug zookeeper problems.
#log4j.logger.org.apache.zookeeper=DEBUG

# Distributed job execution.
log4j.logger.com.bigdata.service.jini.master=INFO

# This can get quite verbose @ WARN if the consumer/producer are proceeding
# at very different rates.
#log4j.logger.com.bigdata.relation.accesspath.BlockingBuffer=ERROR

# Bulk distributed RDF data load.
#log4j.logger.com.bigdata.rdf.rio.AsynchronousStatementBufferWithoutSids=INFO
log4j.logger.com.bigdata.rdf.load.MappedRDFFileLoadTask=INFO
log4j.logger.com.bigdata.rdf.load.MappedRDFDataLoadMaster=INFO

# Lehigh benchmark integration
log4j.logger.edu.lehigh.swat.bench.ubt.bigdata=INFO

# Rule execution (query, closure, etc).
log4j.logger.com.bigdata.relation.rule.eval.RuleLog=INFO

# Pipeline join details.
log4j.logger.com.bigdata.relation.rule.eval.pipeline.JoinMasterTask=INFO



##
# Setup the possible appenders (log destinations and layouts).
##

# console
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.Threshold=INFO
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%-5p: %r %X{clientname} %X{hostname} %X{serviceName} %t %l: %m%n

##
# log bigdata events onto the eventLog.
#
# This is the sink for bigdata events, which describe things such as index
# partition operations.  The events are written using a tab-delimited format.
# The logger layout should not add anything or it can cause problems when
# reading the events back into a worksheet or the like.  The event log is
# written by the LBS, so it will wind up in the service directory for that
# service when running the standalone configuration.
#
log4j.logger.com.bigdata.service.EventReceiver=INFO,eventLog
log4j.additivity.com.bigdata.service.EventReceiver=false
log4j.appender.eventLog=org.apache.log4j.FileAppender
log4j.appender.eventLog.Threshold=INFO
log4j.appender.eventLog.File=eventLog
log4j.appender.eventLog.Append=true
# While this is less critical, I still like to have each event flushed
# through to the log file so you don't wind up with partial events in the
# file.
log4j.appender.eventLog.BufferedIO=false
log4j.appender.eventLog.layout=org.apache.log4j.PatternLayout
log4j.appender.eventLog.layout.ConversionPattern=%m
