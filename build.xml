<!-- @todo add dependencies for GOM and add GOM to sources that are compiled, jared, etc. -->
<!-- @todo trim fastutils using a tool to chase the actual class files that we use. -->
<!-- @todo change the release target to put release notes into the root of the archives. -->
<!-- @todo maven2 setup so we can run and publish unit tests results. -->
<!-- $Id$ -->
<project name="bigdata" default="jar" basedir=".">

	<property file="build.properties" />

	<!-- build-time classpath. -->
	<path id="build.classpath">
		<fileset dir="${bigdata.dir}/bigdata/lib">
			<include name="**/*.jar" />
		</fileset>
		<fileset dir="${bigdata.dir}/bigdata-jini/lib">
			<include name="**/*.jar" />
		</fileset>
		<fileset dir="${bigdata.dir}/bigdata-rdf/lib">
			<include name="**/*.jar" />
		</fileset>
		<fileset dir="${bigdata.dir}/bigdata-sails/lib">
			<include name="**/*.jar" />
		</fileset>
	</path>

	<!-- runtime classpath w/o install. -->
	<path id="runtime.classpath">
		<pathelement location="${build.dir}/classes" />
		<path refid="build.classpath" />
	</path>

	<!-- classpath as installed. -->
	<!-- @todo .so and .dll -->
	<path id="install.classpath">
		<fileset dir="${install.lib.dir}">
			<include name="**/*.jar" />
		</fileset>
	</path>

	<target name="clean" description="cleans everything in [build.dir], but not the releases.">
		<delete dir="${build.dir}" />
        <delete dir="${bigdata.dir}/bigdata-test" quiet="true" />
        <delete dir="${bigdata.dir}/dist" quiet="true" />
	</target>

	<target name="prepare">
		<!-- setup ${version} for regular or snapshot. -->
		<tstamp>
			<format property="today" pattern="ddMMyy" locale="en,US" />
		</tstamp>
		<condition property="version" value="bigdata-${build.ver}-${today}" else="bigdata-${build.ver}">
			<istrue value="${snapshot}" />
		</condition>
		<!--<echo message="today=${today}"/>-->
		<echo message="version=${version}" />
		<!-- create directories. -->
		<mkdir dir="${build.dir}" />
		<mkdir dir="${build.dir}/classes" />
		<mkdir dir="${build.dir}/docs" />
		<mkdir dir="${build.dir}/lib" />
	</target>

	<!-- Note: javac error results often if verbose is disabled. -->
	<!-- I was able to perform a build with 1.6.0_07. -->
	<!-- I set the target to 1.5 to support deployment on non-1.6 JVMs. -->
	<target name="compile" depends="prepare">
		<mkdir dir="${build.dir}" />
		<javac destdir="${build.dir}/classes" classpathref="build.classpath"
		 debug="${javac.debug}" debuglevel="${javac.debuglevel}" verbose="${javac.verbose}"
	     encoding="${javac.encoding}"
	     	>
			<!-- note: must also specify -bootclasspath and -extdirs when cross-compiling -->
			<!-- target="${javac.target}" source="${javac.source}" -->
			<src path="${bigdata.dir}/lgpl-utils/src/java" />
			<src path="${bigdata.dir}/bigdata/src/java" />
			<src path="${bigdata.dir}/bigdata-jini/src/java" />
			<src path="${bigdata.dir}/bigdata-rdf/src/java" />
			<src path="${bigdata.dir}/bigdata-sails/src/java" />
			<!-- Do not include the unit tests @todo conditionally include?
            <src path="${bigdata.dir}/bigdata/src/test"/>
            <src path="${bigdata.dir}/bigdata-jini/src/test"/>
            <src path="${bigdata.dir}/bigdata-rdf/src/test"/>
            <src path="${bigdata.dir}/bigdata-sails/src/test"/>
            -->
			<compilerarg value="-version"/>
		</javac>
		<!-- copy resources. -->
		<copy toDir="${build.dir}/classes">
			<fileset dir="${bigdata.dir}/bigdata/src/java">
				<exclude name="**/*.java" />
				<exclude name="**/package.html" />
				<exclude name="**/BytesUtil.c" />
			</fileset>
			<fileset dir="${bigdata.dir}/bigdata-jini/src/java">
				<exclude name="**/*.java" />
				<exclude name="**/package.html" />
			</fileset>
			<fileset dir="${bigdata.dir}/bigdata-rdf/src/java">
				<exclude name="**/*.java" />
				<exclude name="**/package.html" />
			</fileset>
			<fileset dir="${bigdata.dir}/bigdata-sails/src/java">
				<exclude name="**/*.java" />
				<exclude name="**/package.html" />
			</fileset>
			<fileset dir="${bigdata.dir}/bigdata-sails/src/resources/sesame-server">
	            <include name="META-INF/**"/>
			</fileset>
		</copy>
	</target>

	<!-- Builds the bigdata JAR and bundles it together with all of its dependencies in the ${build.dir}/lib directory. -->
	<target name="bundleJar" depends="bundle, jar"
		description="Builds the bigdata JAR and bundles it together with all of its dependencies in the ${build.dir}/lib directory.">
		<copy file="${build.dir}/${version}.jar" todir="${build.dir}/lib"/>
		<!--<property name="myclasspath" refid="runtime.classpath" />
		<echo message="${myclasspath}"/>-->
	</target>

	<!-- This generates the jar, but does not bundled the dependencies.
		 See 'bundleJar'. -->
	<target name="jar" depends="compile" description="Generates the jar (see also bundleJar).">
		<jar destfile="${build.dir}/${version}.jar">
			<fileset dir="${build.dir}/classes" 
                                 excludes="test/**" />
			<manifest>
				<!--<attribute name="Main-Class" value="com/bigdata/rdf/rio/TestRioIntegration"/>-->
			</manifest>
		</jar>
	</target>

	<!-- This generates an osgi bundle jar, and does not bundled the dependencies.
		 See 'bundleJar'. -->
	<target name="osgi" depends="compile" description="Generates the osgi bundle jar (see also bundleJar).">
		<jar destfile="${build.dir}/com.bigdata-${build.ver.osgi}.jar">
			<fileset dir="${build.dir}/classes"  />
			<manifest>
				<attribute name="Bundle-Name" value="com.bigdata"/>
				<attribute name="Bundle-Vendor" value="Systap"/>
				<attribute name="Bundle-Version" value="${build.ver.osgi}"/>
				<attribute name="Bundle-ManifestVersion" value="2"/>
				<attribute name="Bundle-SymbolicName" value="com.bigdata"/>
				<attribute name="Bundle-DocURL" value="http://www.bigdata.com"/>
				<attribute name="Bundle-Description" value="Bigdata API"/>
				
				
				<attribute name="Export-Package" value='
com.bigdata;version="${build.ver.osgi}",
com.bigdata.bfs;version="${build.ver.osgi}",
com.bigdata.btree;version="${build.ver.osgi}",
com.bigdata.btree.data;version="${build.ver.osgi}",
com.bigdata.btree.filter;version="${build.ver.osgi}",
com.bigdata.btree.isolation;version="${build.ver.osgi}",
com.bigdata.btree.keys;version="${build.ver.osgi}",
com.bigdata.btree.proc;version="${build.ver.osgi}",
com.bigdata.btree.raba;version="${build.ver.osgi}",
com.bigdata.btree.raba.codec;version="${build.ver.osgi}",
com.bigdata.btree.view;version="${build.ver.osgi}",
com.bigdata.cache;version="${build.ver.osgi}",
com.bigdata.concurrent;version="${build.ver.osgi}",
com.bigdata.config;version="${build.ver.osgi}",
com.bigdata.counters;version="${build.ver.osgi}",
com.bigdata.counters.httpd;version="${build.ver.osgi}",
com.bigdata.counters.linux;version="${build.ver.osgi}",
com.bigdata.counters.query;version="${build.ver.osgi}",
com.bigdata.counters.render;version="${build.ver.osgi}",
com.bigdata.counters.store;version="${build.ver.osgi}",
com.bigdata.counters.win;version="${build.ver.osgi}",
com.bigdata.gis;version="${build.ver.osgi}",
com.bigdata.io;version="${build.ver.osgi}",
com.bigdata.io.compression;version="${build.ver.osgi}",
com.bigdata.jini.lookup.entry;version="${build.ver.osgi}",
com.bigdata.jini.start;version="${build.ver.osgi}",
com.bigdata.jini.start.config;version="${build.ver.osgi}",
com.bigdata.jini.start.process;version="${build.ver.osgi}",
com.bigdata.jini.util;version="${build.ver.osgi}",
com.bigdata.journal;version="${build.ver.osgi}",
com.bigdata.mdi;version="${build.ver.osgi}",
com.bigdata.net;version="${build.ver.osgi}",
com.bigdata.rawstore;version="${build.ver.osgi}",
com.bigdata.rdf.axioms;version="${build.ver.osgi}",
com.bigdata.rdf.inf;version="${build.ver.osgi}",
com.bigdata.rdf.lexicon;version="${build.ver.osgi}",
com.bigdata.rdf.load;version="${build.ver.osgi}",
com.bigdata.rdf.magic;version="${build.ver.osgi}",
com.bigdata.rdf.model;version="${build.ver.osgi}",
com.bigdata.rdf.rio;version="${build.ver.osgi}",
com.bigdata.rdf.rules;version="${build.ver.osgi}",
com.bigdata.rdf.spo;version="${build.ver.osgi}",
com.bigdata.rdf.store;version="${build.ver.osgi}",
com.bigdata.rdf.vocab;version="${build.ver.osgi}",
com.bigdata.relation;version="${build.ver.osgi}",
com.bigdata.relation.accesspath;version="${build.ver.osgi}",
com.bigdata.relation.locator;version="${build.ver.osgi}",
com.bigdata.relation.rule;version="${build.ver.osgi}",
com.bigdata.relation.rule.eval;version="${build.ver.osgi}",
com.bigdata.relation.rule.eval.pipeline;version="${build.ver.osgi}",
com.bigdata.resources;version="${build.ver.osgi}",
com.bigdata.search;version="${build.ver.osgi}",
com.bigdata.service;version="${build.ver.osgi}",
com.bigdata.service.jini;version="${build.ver.osgi}",
com.bigdata.service.jini.benchmark;version="${build.ver.osgi}",
com.bigdata.service.jini.lookup;version="${build.ver.osgi}",
com.bigdata.service.jini.master;version="${build.ver.osgi}",
com.bigdata.service.jini.util;version="${build.ver.osgi}",
com.bigdata.service.mapred;version="${build.ver.osgi}",
com.bigdata.service.mapred.jini;version="${build.ver.osgi}",
com.bigdata.service.mapred.jobs;version="${build.ver.osgi}",
com.bigdata.service.mapred.tasks;version="${build.ver.osgi}",
com.bigdata.service.ndx;version="${build.ver.osgi}",
com.bigdata.service.ndx.pipeline;version="${build.ver.osgi}",
com.bigdata.service.proxy;version="${build.ver.osgi}",
com.bigdata.sparse;version="${build.ver.osgi}",
com.bigdata.striterator;version="${build.ver.osgi}",
com.bigdata.util;version="${build.ver.osgi}",
com.bigdata.util.concurrent;version="${build.ver.osgi}",
com.bigdata.util.httpd;version="${build.ver.osgi}",
com.bigdata.zookeeper;version="${build.ver.osgi}",
org.apache.system;version="${build.ver.osgi}",
org.openrdf.rio.rdfxml;version="${build.ver.osgi}"'/>
				<attribute name="Import-Package" value='
cern.clhep;version="1.2.0",
cern.colt;version="1.2",
cern.colt.bitvector;version="1.2.0",
cern.colt.function;version="1.2",
com.bigdata;version="${build.ver.osgi}",
com.bigdata.bfs;version="${build.ver.osgi}",
com.bigdata.btree;version="${build.ver.osgi}",
com.bigdata.btree.data;version="${build.ver.osgi}",
com.bigdata.btree.filter;version="${build.ver.osgi}",
com.bigdata.btree.isolation;version="${build.ver.osgi}",
com.bigdata.btree.keys;version="${build.ver.osgi}",
com.bigdata.btree.proc;version="${build.ver.osgi}",
com.bigdata.btree.raba;version="${build.ver.osgi}",
com.bigdata.btree.raba.codec;version="${build.ver.osgi}",
com.bigdata.btree.view;version="${build.ver.osgi}",
com.bigdata.cache;version="${build.ver.osgi}",
com.bigdata.concurrent;version="${build.ver.osgi}",
com.bigdata.config;version="${build.ver.osgi}",
com.bigdata.counters;version="${build.ver.osgi}",
com.bigdata.counters.httpd;version="${build.ver.osgi}",
com.bigdata.counters.linux;version="${build.ver.osgi}",
com.bigdata.counters.query;version="${build.ver.osgi}",
com.bigdata.counters.render;version="${build.ver.osgi}",
com.bigdata.counters.store;version="${build.ver.osgi}",
com.bigdata.counters.win;version="${build.ver.osgi}",
com.bigdata.gis;version="${build.ver.osgi}",
com.bigdata.io;version="${build.ver.osgi}",
com.bigdata.io.compression;version="${build.ver.osgi}",
com.bigdata.jini.lookup.entry;version="${build.ver.osgi}",
com.bigdata.jini.start;version="${build.ver.osgi}",
com.bigdata.jini.start.config;version="${build.ver.osgi}",
com.bigdata.jini.start.process;version="${build.ver.osgi}",
com.bigdata.jini.util;version="${build.ver.osgi}",
com.bigdata.journal;version="${build.ver.osgi}",
com.bigdata.mdi;version="${build.ver.osgi}",
com.bigdata.net;version="${build.ver.osgi}",
com.bigdata.rawstore;version="${build.ver.osgi}",
com.bigdata.rdf.axioms;version="${build.ver.osgi}",
com.bigdata.rdf.inf;version="${build.ver.osgi}",
com.bigdata.rdf.lexicon;version="${build.ver.osgi}",
com.bigdata.rdf.load;version="${build.ver.osgi}",
com.bigdata.rdf.magic;version="${build.ver.osgi}",
com.bigdata.rdf.model;version="${build.ver.osgi}",
com.bigdata.rdf.rio;version="${build.ver.osgi}",
com.bigdata.rdf.rules;version="${build.ver.osgi}",
com.bigdata.rdf.spo;version="${build.ver.osgi}",
com.bigdata.rdf.store;version="${build.ver.osgi}",
com.bigdata.rdf.vocab;version="${build.ver.osgi}",
com.bigdata.relation;version="${build.ver.osgi}",
com.bigdata.relation.accesspath;version="${build.ver.osgi}",
com.bigdata.relation.locator;version="${build.ver.osgi}",
com.bigdata.relation.rule;version="${build.ver.osgi}",
com.bigdata.relation.rule.eval;version="${build.ver.osgi}",
com.bigdata.relation.rule.eval.pipeline;version="${build.ver.osgi}",
com.bigdata.resources;version="${build.ver.osgi}",
com.bigdata.search;version="${build.ver.osgi}",
com.bigdata.service;version="${build.ver.osgi}",
com.bigdata.service.jini;version="${build.ver.osgi}",
com.bigdata.service.jini.benchmark;version="${build.ver.osgi}",
com.bigdata.service.jini.lookup;version="${build.ver.osgi}",
com.bigdata.service.jini.master;version="${build.ver.osgi}",
com.bigdata.service.jini.util;version="${build.ver.osgi}",
com.bigdata.service.mapred;version="${build.ver.osgi}",
com.bigdata.service.mapred.jini;version="${build.ver.osgi}",
com.bigdata.service.mapred.jobs;version="${build.ver.osgi}",
com.bigdata.service.mapred.tasks;version="${build.ver.osgi}",
com.bigdata.service.ndx;version="${build.ver.osgi}",
com.bigdata.service.ndx.pipeline;version="${build.ver.osgi}",
com.bigdata.service.proxy;version="${build.ver.osgi}",
com.bigdata.sparse;version="${build.ver.osgi}",
com.bigdata.striterator;version="${build.ver.osgi}",
com.bigdata.util;version="${build.ver.osgi}",
com.bigdata.util.concurrent;version="${build.ver.osgi}",
com.bigdata.util.httpd;version="${build.ver.osgi}",
com.bigdata.zookeeper;version="${build.ver.osgi}",
com.ibm.icu.text,
com.ibm.icu.util;version="3.8.1",
com.sun.jini.admin;version="2.1",
com.sun.jini.config;version="2.1.0",
com.sun.jini.resource;version="2.1.0",
com.sun.jini.start;version="2.1",
com.sun.jini.tool;version="2.1.0",
cutthecrap.utils.striterators;version="5.4",
info.aduna.net,
info.aduna.xml,
it.unimi.dsi.bits;version="5.1",
it.unimi.dsi.compression;version="5.1",
it.unimi.dsi.fastutil.booleans;version="5.1",
it.unimi.dsi.fastutil.bytes;version="5.1",
it.unimi.dsi.fastutil.ints;version="5.1",
it.unimi.dsi.fastutil.io;version="5.1",
it.unimi.dsi.fastutil.longs;version="5.1",
it.unimi.dsi.fastutil.objects;version="5.1",
it.unimi.dsi.io;version="5.1",
it.unimi.dsi.util;version="5.1",
javax.xml.datatype,
javax.xml.namespace,
javax.xml.parsers,
net.jini.admin;version="2.1",
net.jini.config;version="2.1",
net.jini.core.discovery;version="2.1",
net.jini.core.entry;version="2.1",
net.jini.core.lookup;version="2.1",
net.jini.discovery;version="2.1",
net.jini.entry;version="2.1",
net.jini.export;version="2.1",
net.jini.io.context;version="2.1",
net.jini.jeri;version="2.1",
net.jini.jeri.tcp;version="2.1",
net.jini.lease;version="2.1",
net.jini.lookup;version="2.1",
net.jini.lookup.entry;version="2.1",
org.CognitiveWeb.extser;version="1.1",
org.apache.commons.io;version="1.4",
org.apache.log4j,
org.apache.lucene.analysis;version="3.0.0",
org.apache.lucene.analysis.br;version="3.0.0",
org.apache.lucene.analysis.cjk;version="3.0.0",
org.apache.lucene.analysis.cn;version="3.0.0",
org.apache.lucene.analysis.cz;version="3.0.0",
org.apache.lucene.analysis.de;version="3.0.0",
org.apache.lucene.analysis.el;version="3.0.0",
org.apache.lucene.analysis.fr;version="3.0.0",
org.apache.lucene.analysis.nl;version="3.0.0",
org.apache.lucene.analysis.ru;version="3.0.0",
org.apache.lucene.analysis.standard;version="3.0.0",
org.apache.lucene.analysis.th;version="3.0.0",
org.apache.lucene.analysis.tokenattributes;version="3.0.0",
org.apache.lucene.util;version="3.0.0",
org.apache.system;version="${build.ver.osgi}",
org.apache.zookeeper;version="3.1",
org.apache.zookeeper.data;version="3.1",
org.apache.zookeeper.server;version="3.2.1",
org.apache.zookeeper.server.quorum;version="3.1",
org.deri.iris.api;version="0.58",
org.deri.iris.api.basics;version="0.58",
org.deri.iris.api.builtins;version="0.58",
org.deri.iris.api.factory;version="0.58",
org.deri.iris.api.terms;version="0.58",
org.deri.iris.basics;version="0.58",
org.deri.iris.builtins;version="0.58",
org.deri.iris.optimisations.magicsets;version="0.58",
org.deri.iris.terms;version="0.58",
org.openrdf.model;version="2.0",
org.openrdf.model.datatypes;version="2.0",
org.openrdf.model.impl;version="2.0",
org.openrdf.model.util;version="2.0",
org.openrdf.model.vocabulary;version="2.0",
org.openrdf.rio;version="2.0",
org.openrdf.rio.helpers;version="2.0",
org.openrdf.rio.rdfxml;version="2.0",
org.openrdf.sail;version="2.0.0",
org.xml.sax,
org.xml.sax.helpers,
sun.misc;resolution:=optional
				'/>
			</manifest>
		</jar>
	</target>
	
	
	<!-- Note: the javadoc requires a LOT of RAM, but runs quickly on a
		 server	class machine. 
		 
		 @todo man page for [bigdata] script to @{build.dir}/docs
 	     
		 -->
	<target name="javadoc" depends="prepare" if="javadoc">
		<mkdir dir="${build.dir}/docs/api" />
		<javadoc destdir="${build.dir}/docs/api" defaultexcludes="yes" author="true" version="true" use="true" overview="../bigdata/overview.html" windowtitle="bigdata&#174;" classpathref="build.classpath">
			<arg value="-J-Xmx1000m"/>
			<packageset dir="${bigdata.dir}/bigdata/src/java" />
			<packageset dir="${bigdata.dir}/bigdata-jini/src/java" />
			<packageset dir="${bigdata.dir}/bigdata-rdf/src/java" />
			<packageset dir="${bigdata.dir}/bigdata-sails/src/java" />
			<packageset dir="${bigdata.dir}/bigdata-sails/src/samples" />
			<doctitle>
				<![CDATA[<h1>bigdata&#174;</h1>]]></doctitle>
		<bottom>
			<![CDATA[<i>Copyright &#169; 2006-2009 SYSTAP, LLC. All Rights Reserved.</i>]]></bottom>
	<tag name="todo" scope="all" description="TODO:" />
	<tag name="issue" scope="all" description="ISSUE:" />
	<!--tag name="FIXME" scope="all" description="FIXME:"/-->
	<link href="http://java.sun.com/j2se/1.5.0/docs/api/" />
	<link href="http://openrdf.org/doc/sesame/api/" />
</javadoc>
</target>

<target name="bundle" description="Bundles all dependencies for easier deployments and releases (does not bundle the bigdata jar).">
<copy toDir="${build.dir}/lib">
	<fileset dir="${bigdata.dir}/bigdata/lib">
		<include name="**/*.jar" />
		<include name="**/*.so" />
		<include name="**/*.dll" />
		<!-- ICU4JNI is not a supported configuration at this time. -->
		<exclude name="**/icu4jni.jar" />
		<exclude name="**/icu*.dll" />
		<exclude name="**/ICU*.dll" />
		<!-- The BytesUtil JNI class is not recommended at this time (no performance gain). -->
		<exclude name="**/*BytesUtil*" />
	</fileset>
	<fileset dir="${bigdata.dir}/bigdata-jini/lib">
		<include name="**/*.jar" />
	</fileset>
	<fileset dir="${bigdata.dir}/bigdata-rdf/lib">
		<include name="**/*.jar" />
	</fileset>
	<fileset dir="${bigdata.dir}/bigdata-sails/lib">
		<include name="**/*.jar" />
	</fileset>
</copy>
</target>

<target name="release-prepare" depends="jar, bundle, javadoc" description="create a release.">
<!-- The source tree. -->
<copy toDir="${build.dir}/bigdata/src">
	<fileset dir="${bigdata.dir}/bigdata/src" />
</copy>
<copy toDir="${build.dir}/bigdata-jini/src">
	<fileset dir="${bigdata.dir}/bigdata-jini/src" />
</copy>
<copy toDir="${build.dir}/bigdata-rdf/src">
	<fileset dir="${bigdata.dir}/bigdata-rdf/src" />
</copy>
<copy toDir="${build.dir}/bigdata-sails/src">
	<fileset dir="${bigdata.dir}/bigdata-sails/src" />
</copy>
<!-- common files for the root of the archive. -->
<copy tofile="${build.dir}/build.properties" file="build.properties" />
<copy tofile="${build.dir}/build.xml" file="build.xml" />
<copy tofile="${build.dir}/LICENSE.txt" file="LICENSE.txt" />
<copy tofile="${build.dir}/overview.html" file="overview.html" />
<copy tofile="${build.dir}/README-JINI" file="README-JINI" />
<copy toDir="${build.dir}/LEGAL" flatten="true">
	<fileset dir="${bigdata.dir}">
		<include name="**/LEGAL/*" />
	</fileset>
</copy>
</target>

<target name="release" depends="release-prepare" description="create source and binary tarballs.">
<mkdir dir="${release.dir}" />
<!-- binary distribution. -->
<tar destfile="${release.dir}/${version}-bin.tgz" compression="gzip">
	<!-- binary distribution (docs, but no source). -->
	<tarfileset dir="${build.dir}" prefix="${version}">
		<!-- common files from the root of the archive. -->
		<include name="build.properties" />
		<include name="build.xml" />
		<include name="LICENSE.txt" />
		<include name="overview.html" />
		<include name="README-JINI" />
		<include name="LEGAL/*" />
		<!-- src, classes, jar, lib, docs. -->
		<exclude name="bigdata/src/**" />
		<exclude name="bigdata-jini/src/**" />
		<exclude name="bigdata-rdf/src/**" />
		<exclude name="bigdata-sails/src/**" />
		<exclude name="classes/**" />
		<include name="${version}.jar" />
		<include name="lib/**" />
		<include name="docs/**" />
	</tarfileset>
</tar>
<!-- source distribution. -->
<!-- Note: use GNU long file names for paths GT 100 characters. -->
<tar destfile="${release.dir}/${version}-src.tgz" compression="gzip">
	<!-- source, but no jar, compiled, docs, etc. -->
	<tarfileset dir="${build.dir}" prefix="${version}">
		<!-- common files from the root of the archive. -->
		<include name="build.properties" />
		<include name="build.xml" />
		<include name="LICENSE.txt" />
		<include name="overview.html" />
		<include name="README-JINI" />
		<include name="LEGAL/*" />
		<!-- src, classes, jar, lib, docs. -->
		<include name="bigdata/src/**" />
		<include name="bigdata-jini/src/**" />
		<include name="bigdata-rdf/src/**" />
		<include name="bigdata-sails/src/**" />
		<include name="lgpl-utils/src/**" />
		<include name="src/**" />
		<exclude name="classes/**" />
		<exclude name="${version}.jar" />
		<exclude name="lib/**" />
		<exclude name="docs/**" />
	</tarfileset>
</tar>
</target>

<!-- Note: I use a public/private key to do this.  You can uncomment the
	     ssh.password lines if you are going to authenticate directly.
	     
	     Note: If you do not have the public key for frs.sourceforge.net cached
	     in your SSH repository then this will not work since it requests that
	     you confirm the public key interactively.
	     -->
<target name="upload" depends="release" description="copy release files to server.">
<input message="username:" addproperty="ssh.username" defaultValue="${ssh.username}" />
<!-- unless automated by public/private key
		<input message="password:" addproperty="ssh.password" defaultValue="${ssh.password}"/>
		-->
<exec executable="${ssh.scp}">
	<!-- verbose protocol. -->
	<arg value="-v" />
	<!-- compression. -->
	<arg value="-C" />
	<!-- pscp specific
			<arg value="-l"/><arg value="${ssh.username}"/>
			<arg value="-pw"/><arg value="${ssh.password}"/>
			-->
	<!-- from -->
	<arg value="${release.dir}/${version}-bin.tgz" />
	<!-- to -->
	<arg value="${ssh.username}@frs.sourceforge.net:uploads" />
</exec>
<exec executable="${ssh.scp}">
	<!-- verbose protocol. -->
	<arg value="-v" />
	<!-- compression. -->
	<arg value="-C" />
	<!-- pscp specific
			<arg value="-l"/><arg value="${ssh.username}"/>
			<arg value="-pw"/><arg value="${ssh.password}"/>
			-->
	<!-- from -->
	<arg value="${release.dir}/${version}-src.tgz" />
	<!-- to -->
	<arg value="${ssh.username}@frs.sourceforge.net:uploads" />
</exec>
</target>

<target name="publish-api" depends="javadoc" description="copy javadoc to server.">
<fail message="Javadoc not generated.">
	<condition>
		<not>
			<available file="${build.dir}/docs/api" type="dir" />
		</not>
	</condition>
</fail>
<input message="username:" addproperty="ssh.username2" defaultValue="${ssh.username2}" />
	<!--
<input message="password:" addproperty="ssh.password2" defaultValue="${ssh.password2}" />
-->
<exec executable="${ssh.scp}">
	<!-- recursive. -->
	<arg value="-r" />
	<!-- verbose protocol (too much info, but let's you observe progress during recursive copy). -->
	<arg value="-v" />
	<!-- compression. -->
	<arg value="-C" />
	<!-- pscp specific.
	<arg value="-l" />
	<arg value="${ssh.username2}" />
	<arg value="-pw" />
	<arg value="${ssh.password2}" />-->
	<!-- from -->
	<arg value="${build.dir}/docs" />
	<!-- to -->
	<arg value="${ssh.username2}@shell.speakeasy.net:systap.com/bigdata/" />
</exec>
</target>

<target name="banner" depends="jar" description="Displays the banner (verifies runtime classpath).">

	<java classname="com.bigdata.Banner"
		failonerror="true" fork="false" logerror="true">
		<classpath refid="runtime.classpath" />
	</java>

</target>


	<!--                                                                   -->
	<!--                    CLUSTER INSTALL TARGETS                        -->
	<!--                                                                   -->
	
<!--

This is the cluster-based install.  You need to edit build.properties, decide
which configuration is going to be the basis for your cluster, and then edit
that configuration file.  When you are ready, you can use this target to install
bigdata onto a cluster.

In order to get things moving you need to setup a cron job that will run the
'bigdata' script which is installed by this target.  Documentation on how to
do this is written onto the console after a successfull install.  Those notes
are in the "POST-INSTALL" file in the source distribution and are also copied
into the $binDir when bigdata is installed.

Once you have cron setup, and once you have adjusted the owner and group
properties if you are running bigdata as root, you must edit the $stateFile
and change the run state from 'status' to 'start'.

If you want to shutdown the bigdata services, change the run state to 'stop'.
This will halt all services, but they can be restarted by changing the run
state back to 'start'.

To remove a bigdata installation, first change the run state to 'destroy' and
wait for all services to halt.  THIS WILL DESTROY ALL PERSISTENT STATE!!!!
When that is done, you can remove the shared $NAS directory.  The cron job
will still be trying to run the 'bigdata' script, so either replace it with
an "NOP" bash script or edit your crontab. 
-->
<target name="install" depends="jar, banner, javadoc, bundle" description="Install bigdata on a cluster.">
<!-- create NAS/LAS directories. -->
<mkdir dir="${NAS}" />
<mkdir dir="${LAS}" />
<!-- NAS/LAS directories must be read/write for the group. -->
<chmod perm="ug+rw,o-rw">
	<fileset dir="${NAS}" />
</chmod>
<chmod perm="ug+rw,o-rw">
	<fileset dir="${LAS}" />
</chmod>
<!-- create subdirectories of NAS - should inherit permissions. -->
<mkdir dir="${install.config.dir}" />
<mkdir dir="${install.doc.dir}" />
<mkdir dir="${install.lib.dir}" />
<mkdir dir="${install.bin.dir}" />
<mkdir dir="${install.log.dir}" />
<!-- install configuration files. -->
<copy toDir="${install.config.dir}">
	<fileset dir="${bigdata.dir}/src/resources/config">
	</fileset>
</copy>
<!-- install documentation. -->
<copy toDir="${install.doc.dir}">
	<!-- javadoc. -->
	<fileset dir="${build.dir}/docs" />
	<!-- common files from the root of the archive. -->
	<!-- @todo cleanup LEGAL into one directory off the root in the src tree? -->
	<fileset dir="${bigdata.dir}">
		<include name="LICENSE.txt" />
		<include name="overview.html" />
		<include name="README-JINI" />
		<include name="bigdata/LEGAL/*" />
		<include name="bigdata-jini/LEGAL/*" />
		<include name="bigdata-rdf/LEGAL/*" />
		<include name="bigdata-sails/LEGAL/*" />
	</fileset>
</copy>
<!-- install JARs. -->
<copy toDir="${install.lib.dir}">
	<fileset dir="${build.dir}/lib" />
	<fileset file="${build.dir}/${version}.jar" />
</copy>
<!-- install scripts. -->
<copy toDir="${install.bin.dir}">
	<fileset dir="src/resources/scripts">
	</fileset>
</copy>
<!-- parameter substitution. -->
<property name="myclasspath" refid="install.classpath" />
<replace dir="${install.bin.dir}" summary="true">
	<replacefilter token="@FED@" value="${FED}" />
	<replacefilter token="@NAS@" value="${NAS}" />
	<replacefilter token="@LAS@" value="${LAS}" />
	<replacefilter token="@JAVA_HOME@" value="${JAVA_HOME}" />
	<replacefilter token="@JINI_CLASS_SERVER_PORT@" value="${JINI_CLASS_SERVER_PORT}" />
	<replacefilter token="@LOAD_BALANCER_PORT@" value="${LOAD_BALANCER_PORT}" />
	<replacefilter token="@SYSSTAT_HOME@" value="${SYSSTAT_HOME}" />
	<replacefilter token="@USE_NIO@" value="${USE_NIO}" />
	<replacefilter token="@BIN_DIR@" value="${install.bin.dir}" />
	<replacefilter token="@LIB_DIR@" value="${install.lib.dir}" />
	<replacefilter token="@LOG_DIR@" value="${install.log.dir}" />
	<replacefilter token="@CONFIG_DIR@" value="${install.config.dir}" />
	<replacefilter token="@INSTALL_USER@" value="${install.user}" />
	<replacefilter token="@INSTALL_GROUP@" value="${install.group}" />
	<replacefilter token="@LOCK_FILE@" value="${LOCK_FILE}" />
	<replacefilter token="@BIGDATA_CONFIG@" value="${bigdata.config}" />
	<replacefilter token="@JINI_CONFIG@" value="${jini.config}" />
	<replacefilter token="@POLICY_FILE@" value="${policyFile}" />
	<replacefilter token="@LOG4J_SOCKET_LOGGER_HOST@" value="${LOG4J_SOCKET_LOGGER_HOST}" />
	<replacefilter token="@LOG4J_SOCKET_LOGGER_PORT@" value="${LOG4J_SOCKET_LOGGER_PORT}" />
	<replacefilter token="@LOG4J_SOCKET_LOGGER_CONFIG@" value="${log4jServer.config}" />
	<replacefilter token="@LOG4J_DATE_PATTERN@" value="${LOG4J_DATE_PATTERN}" />
	<replacefilter token="@LOG4J_CONFIG@" value="${log4j.config}" />
	<replacefilter token="@LOGGING_CONFIG@" value="${logging.config}" />
	<replacefilter token="@ERROR_LOG@" value="${errorLog}" />
	<replacefilter token="@DETAIL_LOG@" value="${detailLog}" />
	<replacefilter token="@EVENT_LOG@" value="${eventLog}" />
	<replacefilter token="@RULE_LOG@" value="${ruleLog}" />
	<replacefilter token="@STATE_LOG@" value="${stateLog}" />
	<replacefilter token="@STATE_FILE@" value="${stateFile}" />
	<replacefilter token="@FORCE_KILL_ALL@" value="${forceKillAll}" />
	<replacefilter token="@NTP_MASTER@" value="${NTP_MASTER}" />
	<replacefilter token="@NTP_NETWORK@" value="${NTP_NETWORK}" />
	<replacefilter token="@NTP_NETMASK@" value="${NTP_NETMASK}" />
	<replacefilter token="@CLASSPATH@" value="${myclasspath}" />
</replace>
<replace dir="${install.config.dir}" summary="true">
	<replacefilter token="@FED@" value="${FED}" />
	<replacefilter token="@NAS@" value="${NAS}" />
	<replacefilter token="@LAS@" value="${LAS}" />
	<replacefilter token="@LOG4J_SOCKET_LOGGER_HOST@" value="${LOG4J_SOCKET_LOGGER_HOST}" />
	<replacefilter token="@JAVA_HOME@" value="${JAVA_HOME}" />
	<replacefilter token="@JINI_CLASS_SERVER_PORT@" value="${JINI_CLASS_SERVER_PORT}" />
	<replacefilter token="@LOAD_BALANCER_PORT@" value="${LOAD_BALANCER_PORT}" />
	<replacefilter token="@SYSSTAT_HOME@" value="${SYSSTAT_HOME}" />
	<replacefilter token="@USE_NIO@" value="${USE_NIO}" />
	<replacefilter token="@BIN_DIR@" value="${install.bin.dir}" />
	<replacefilter token="@LIB_DIR@" value="${install.lib.dir}" />
	<replacefilter token="@LOG_DIR@" value="${install.log.dir}" />
	<replacefilter token="@CONFIG_DIR@" value="${install.config.dir}" />
	<replacefilter token="@INSTALL_USER@" value="${install.user}" />
	<replacefilter token="@INSTALL_GROUP@" value="${install.group}" />
	<replacefilter token="@LOCK_FILE@" value="${LOCK_FILE}" />
	<replacefilter token="@BIGDATA_CONFIG@" value="${bigdata.config}" />
	<replacefilter token="@JINI_CONFIG@" value="${jini.config}" />
	<replacefilter token="@POLICY_FILE@" value="${policyFile}" />
	<replacefilter token="@LOG4J_SOCKET_LOGGER_HOST@" value="${LOG4J_SOCKET_LOGGER_HOST}" />
	<replacefilter token="@LOG4J_SOCKET_LOGGER_PORT@" value="${LOG4J_SOCKET_LOGGER_PORT}" />
	<replacefilter token="@LOG4J_SOCKET_LOGGER_CONFIG@" value="${log4jServer.config}" />
	<replacefilter token="@LOG4J_DATE_PATTERN@" value="${LOG4J_DATE_PATTERN}" />
	<replacefilter token="@LOG4J_CONFIG@" value="${log4j.config}" />
	<replacefilter token="@LOGGING_CONFIG@" value="${logging.config}" />
	<replacefilter token="@ERROR_LOG@" value="${errorLog}" />
	<replacefilter token="@DETAIL_LOG@" value="${detailLog}" />
	<replacefilter token="@EVENT_LOG@" value="${eventLog}" />
	<replacefilter token="@RULE_LOG@" value="${ruleLog}" />
	<replacefilter token="@STATE_LOG@" value="${stateLog}" />
	<replacefilter token="@STATE_FILE@" value="${stateFile}" />
	<replacefilter token="@FORCE_KILL_ALL@" value="${forceKillAll}" />
	<replacefilter token="@NTP_MASTER@" value="${NTP_MASTER}" />
	<replacefilter token="@NTP_NETWORK@" value="${NTP_NETWORK}" />
	<replacefilter token="@NTP_NETMASK@" value="${NTP_NETMASK}" />
	<replacefilter token="@CLASSPATH@" value="${myclasspath}" />
	<!-- updates the configuration file to locate the lubm ontology. -->
	<replacefilter token="@install.lubm.config.dir@" value="${install.lubm.config.dir}" />
</replace>
<!-- fix newlines (otherwise substitutions cause things to break). -->
<fixcrlf srcDir="${install.config.dir}" />
<!-- fix newlines (otherwise substitutions cause things to break). -->
<fixcrlf srcDir="${install.bin.dir}" />
<!-- set execute bit for scripts in this directory (must be the last step). -->
<chmod perm="u+x,g+rx,o-rwx">
	<fileset dir="${install.bin.dir}">
		<exclude name="README"/>
		<exclude name="POST-INSTALL"/>
	</fileset>
</chmod>
<!-- Setup the status file which will be read by the bigdata script and
		     the log on which that script will write its output.  This is used
		     if cron, or a similar process, will execute the script on a periodic
		     basis.  The initial state is always 'status'.  The initial stateLog
		     is always empty.  The state file must be readable by the group, but
		     could be restricted to write by a specific user. The stateLog must be
		     read/write for the group. -->
<echo file="${stateFile}">status</echo>
<echo file="${stateLog}">
</echo>
<chmod perm="g+rw,o-rw" file="${stateFile}" />
<chmod perm="g+rw,o-rw" file="${stateLog}" />
<!-- Make sure that the entire shared directory structure is read/write for the group. -->
<chmod perm="g+rwx" type="both" dir="${NAS}" verbose="true"/>
<!-- Make sure that it is all accessible to the install group (ant 1.6+ plus extension module required). 
<chown file="${NAS}" type="both" owner="${install.user}.${install.group}" verbose="true"/>
-->
<!-- Works for earlier versions of ant LT 1.6 which do not bundle "chown". -->
<apply executable="chown" description="set owner on NAS files" osfamily="unix">
        <arg value="-R"/>
        <arg value="${install.user}.${install.group}"/>
        <dirset dir="${NAS}"/>
</apply>
<!-- @todo check the installed configuration file (after parameter substitution). -->
<!-- @todo also check the installed jini configuration files. -->
<java classname="com.bigdata.jini.util.CheckConfiguration"
	failonerror="true" fork="true" logerror="true">
	<classpath refid="install.classpath" />
	<arg value="${bigdata.config}" />
</java>
<loadfile property="postInstallMessage" srcFile="${install.bin.dir}/POST-INSTALL" />
<echo>

${postInstallMessage}</echo>
</target>

<!-- This may be used to verify that statistics are being collected for the
     target platform and diagnose errors related to a missing or incomplete
     sysstat install or other monitoring dependencies. -->
<target name="test-monitoring" depends="compile" description="Run the statistics collectors for the deployment platform.">
	<java classname="com.bigdata.counters.AbstractStatisticsCollector"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="install.classpath" />
		<jvmarg value="-Dcom.bigdata.counters.linux.sysstat.path=${SYSSTAT_HOME}"/>
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dlog4j.configuration=file:bigdata/src/resources/logging/log4j.properties"/>
		<arg value="1" /><!-- interval between reports. -->
		<arg value="10" /><!-- #of seconds to run. -->
	</java>
</target>
	
<!-- Note: we must fork the JVM to the jvmarg overrides applied. -->
<!-- Note: We disable registration of log4j MBeans since that requires policy file. -->
<!-- @todo add a target to launch the post-mortem counter set/events viewer. -->
<target name="analysis" depends="bundleJar" description="Extracts performance counters from logged XML files.">

	<java classname="com.bigdata.counters.query.CounterSetQuery"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="runtime.classpath" />
		<jvmarg value="-Xmx1500m" />
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dlog4j.configuration=file:bigdata/src/resources/logging/log4j.properties"/>
		<arg value="-outputDir" />
		<arg value="${analysis.out.dir}" />
		<arg value="-mimeType" />
		<arg value="text/plain" />
		<arg value="-queries" />
		<arg file="${analysis.queries}" />
		<arg file="${analysis.counters.dir}" />
	</java>
	
</target>

	<!--                                                                   -->
	<!--                    LUBM TARGETS (OPTIONAL)                        -->
	<!--                                                                   -->
	
<target name="lubm-clean" description="Clean the lubm-integration from the build directory.">
	<delete dir="${build.dir}/lubm" />
</target>

<target name="lubm-prepare" description="Clean the lubm-integration from the build directory.">
	<mkdir dir="${build.dir}/lubm" />
	<mkdir dir="${build.dir}/lubm/classes" />
	<mkdir dir="${build.dir}/lubm/lib" />
</target>

<path id="lubm.build.classpath" description="The lubm build-time classpath (this expects to find the bigdata JAR already installed).">
	<fileset dir="${install.lib.dir}">
		<include name="**/*.jar" />
	</fileset>
</path>

<!-- And now for something totally weird.  If you compile against the bigdata.jar
     rather than build.dir/classes then you will see some errors reported in
     LubmGeneratorMaster.java which otherwise are not reported... -->
<target name="lubm-compile" depends="lubm-prepare" description="Compile the optional lubm integration.">
	<javac destdir="${build.dir}/lubm/classes" classpathref="runtime.classpath" 
	       debug="${javac.debug}" debuglevel="${javac.debuglevel}" verbose="${javac.verbose}"
		   encoding="${javac.encoding}"
    	>
		<!-- note: must also specify -bootclasspath and -extdirs when cross-compiling -->
		<!-- target="${javac.target}" source="${javac.source}" -->
		<src path="${bigdata.dir}/bigdata-lubm/src/java" />
	</javac>
	<!-- copy resources. -->
	<copy toDir="${build.dir}/lubm/classes">
		<fileset dir="${bigdata.dir}/bigdata-lubm/src/java">
			<exclude name="**/*.java" />
		</fileset>
	</copy>
</target>

<target name="lubm-jar" depends="lubm-compile" description="Generates the JAR containing the optional LUBM integration.">
	<jar destfile="${build.dir}/lubm/lib/bigdata-lubm.jar">
		<fileset dir="${build.dir}/lubm/classes" />
	</jar>
</target>

<!-- This explicitly enumerates the lubm scripts so we don't run
	 fixcrlf or set the execute bit on arbitrary files in the 
	 install directory. -->
<fileset dir="${install.bin.dir}" id="lubm-scripts" description="The lubm scripts.">
	<include name="lubmMaster.sh" />
	<include name="lubmQuery.sh" />
	<include name="lubmGen.sh" />
</fileset>

<!-- While this installs the LUBM integration into the same place as the
     bigdata federation, you do not need to have the LUBM classes or the
     integration classes installed when you start the bigdata federation.
     Those classes will be automatically found when you run the lubmMaster
     script, which exposes them using a ClassServer.  You can use this as
     a model for how to install and run your own software against a bigdata 
     federation that is already up and running. -->
<target name="lubm-install" depends="lubm-jar" description="Install the optional lubm integration which may be used for benchmarking the RDF database.">
	<mkdir dir="${install.lubm.dir}"/>
	<mkdir dir="${install.lubm.lib.dir}"/>
	<mkdir dir="${install.lubm.config.dir}"/>
 	<!-- install JAR. -->
 	<copy toDir="${install.lubm.lib.dir}" file="${build.dir}/lubm/lib/bigdata-lubm.jar"/>
	<!-- install ontology, configuration files, and query files. -->
	<copy toDir="${install.lubm.config.dir}">
		<fileset dir="bigdata-lubm/resources/config"/>
	</copy>
	<!-- install scripts. -->
	<copy toDir="${install.bin.dir}">
		<fileset dir="bigdata-lubm/resources/scripts"/>
	</copy>
	<!-- replace will only find those @XXX@ parameters which have not yet been
		 transcribed out by the bigdata ant install. -->
	<replace dir="${install.bin.dir}" summary="true">
		<replacefilter token="@NAS@" value="${NAS}" />
		<replacefilter token="@BIN_DIR@" value="${install.bin.dir}" />
		<replacefilter token="@BIGDATA_CONFIG@" value="${bigdata.config}" />
		<replacefilter token="@LUBM_CLASS_SERVER_PORT@" value="${LUBM_CLASS_SERVER_PORT}" />
		<replacefilter token="@LUBM_CLASS_SERVER_HOSTNAME@" value="${LUBM_CLASS_SERVER_HOSTNAME}" />
		<replacefilter token="@LUBM_RMI_CODEBASE_URL@" value="${LUBM_RMI_CODEBASE_URL}" />
		<replacefilter token="@install.lubm.lib.dir@" value="${install.lubm.lib.dir}" />
		<replacefilter token="@install.lubm.config.dir@" value="${install.lubm.config.dir}" />
	</replace>
	<replace dir="${install.lubm.config.dir}" summary="true">
		<replacefilter token="@NAS@" value="${NAS}" />
		<replacefilter token="@BIN_DIR@" value="${install.bin.dir}" />
		<replacefilter token="@BIGDATA_CONFIG@" value="${bigdata.config}" />
		<replacefilter token="@LUBM_CLASS_SERVER_PORT@" value="${LUBM_CLASS_SERVER_PORT}" />
		<replacefilter token="@LUBM_CLASS_SERVER_HOSTNAME@" value="${LUBM_CLASS_SERVER_HOSTNAME}" />
		<replacefilter token="@LUBM_RMI_CODEBASE_URL@" value="${LUBM_RMI_CODEBASE_URL}" />
		<replacefilter token="@install.lubm.lib.dir@" value="${install.lubm.lib.dir}" />
		<replacefilter token="@install.lubm.config.dir@" value="${install.lubm.config.dir}" />
	</replace>
	<!-- fix newlines (otherwise substitutions cause things to break). -->
	<fixcrlf srcDir="${install.bin.dir}" >
		<!-- file set not supported. <fileset refid="scripts" /> -->
	</fixcrlf>
	<!-- set execute bit for scripts in this directory (must be the last step). -->
	<chmod perm="u+x,g+rx,o-rwx">
		<fileset refid="lubm-scripts" />
	</chmod>
	<!-- Make sure that it is all accessible to the install group (ant 1.6+ plus extension module required). 
	<chown file="${NAS}" type="both" owner="${install.user}.${install.group}" verbose="true"/>
	-->
	<!-- Works for earlier versions of ant LT 1.6 which do not bundle "chown". -->
	<apply executable="chown" description="set owner on NAS files" osfamily="unix">
	        <arg value="-R"/>
	        <arg value="${install.user}.${install.group}"/>
	        <dirset dir="${install.bin.dir}"/>
	</apply>
	<apply executable="chown" description="set owner on NAS files" osfamily="unix">
	        <arg value="-R"/>
	        <arg value="${install.user}.${install.group}"/>
	        <dirset dir="${install.lubm.dir}"/>
	</apply>
</target>

<!-- lubm runtime classpath w/o install. -->
<path id="lubm.runtime.classpath">
	<pathelement location="${build.dir}/lubm/classes"/>
	<pathelement location="${build.dir}/classes" />
	<path refid="build.classpath" />
</path>

<target name="lubm-load" depends="jar, lubm-compile" description="Load data into a configured lubm test harness, typically standalone.">

	<java classname="edu.lehigh.swat.bench.ubt.Test"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="lubm.runtime.classpath"/>
		<jvmarg value="-server" />
		<jvmarg value="-Xmx1024m" />
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dlog4j.configuration=file:bigdata/src/resources/logging/log4j.properties"/>
		<arg value="load" />
		<arg value="bigdata-lubm/src/java/edu/lehigh/swat/bench/ubt/bigdata/config.kb.bigdata" />
	</java>
	
</target>
		
<target name="lubm-test" depends="jar, lubm-compile" description="Run queries against a configured lubm test harness, typically standalone.">

	<java classname="edu.lehigh.swat.bench.ubt.Test"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="lubm.runtime.classpath" />
		<jvmarg value="-server" />
		<jvmarg value="-Xmx1024m" />
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dlog4j.configuration=file:bigdata/src/resources/logging/log4j.properties"/>
		<arg value="query" />
		<arg value="bigdata-lubm/src/java/edu/lehigh/swat/bench/ubt/bigdata/config.kb.bigdata" />
		<arg value="bigdata-lubm/src/java/edu/lehigh/swat/bench/ubt/bigdata/config.query.sparql" />
	</java>
	
</target>

	<!--                                                                   -->
	<!--                    STANDALONE FEDERATION TARGETS                  -->
	<!--                                                                   -->

<target name="standalone-setup" description="Setup properties used by the standalone federation and LUS start/stop.">
    <property name="app.home" location="${bigdata.dir}" />
    <property name="test.codebase.port" value="23333"/>
    <property name="test.codebase.dir" location="${bigdata.dir}/bigdata-jini/lib/jini/lib-dl" />
    <property name="test.codebase" value="http://${this.hostname}:${test.codebase.port}/jsk-dl.jar"/>
    <property name="java.security.policy" value="${bigdata.dir}/policy.all"/>
	<property name="log4j.configuration" value="${bigdata.dir}/src/resources/config/standalone/log4j.properties"/>
    <property name="java.net.preferIPv4Stack" value="true"/>
    <property name="bigdata.fedname" value="${standalone.fed}"/>
</target>

<target name="standalone-startLookup" depends="jar,standalone-setup" description="Start the lookup service for the standalone federation.">
  <java classname="com.bigdata.service.jini.util.LookupStarter"
		fork="true" spawn="true">
		<classpath refid="runtime.classpath" />
    <sysproperty key="app.home" value="${app.home}"/>
    <sysproperty key="jini.lib" value="${dist.lib}"/>
    <sysproperty key="jini.lib.dl" value="${dist.lib.dl}"/>
    <sysproperty key="java.security.policy" value="${java.security.policy}"/>
    <sysproperty key="java.security.debug" value="off"/>
    <sysproperty key="java.protocol.handler.pkgs" value="net.jini.url"/>
    <sysproperty key="log4j.configuration" value="${log4j.configuration}"/>
    <sysproperty key="codebase.port" value="${test.codebase.port}"/>
    <sysproperty key="java.net.preferIPv4Stack" value="${java.net.preferIPv4Stack}"/>
    <sysproperty key="bigdata.fedname" value="${bigdata.fedname}"/>
  </java>
</target>

<target name="standalone-stopLookup" depends="jar,standalone-setup" description="Stop the lookup service for the standalone federation.">
  <java classname="com.bigdata.service.jini.util.LookupStarter"
	failonerror="true" fork="true" logerror="true">
	<classpath refid="runtime.classpath" />
    <sysproperty key="app.home" value="${app.home}"/>
    <sysproperty key="jini.lib" value="${dist.lib}"/>
    <sysproperty key="jini.lib.dl" value="${dist.lib.dl}"/>
    <sysproperty key="java.security.policy" value="${java.security.policy}"/>
    <sysproperty key="log4j.configuration" value="${log4j.configuration}"/>
    <sysproperty key="java.net.preferIPv4Stack" value="${java.net.preferIPv4Stack}"/>
    <sysproperty key="bigdata.fedname" value="${bigdata.fedname}"/>
    <arg value="-stop" />
  </java>
</target>

<!-- Note: You should 'nohup' this, e.g., "nohup ant standalone-start" to 
     avoid taking down the ServicesManagerServer if you are disconnected
     from a terminal. -->
<target name="standalone-start" depends="jar,standalone-setup" description="Start the standalone federation.">
    <!-- Start the lookup service. -->
	<antcall target="standalone-startLookup" />
	<java classname="com.bigdata.jini.start.ServicesManagerServer"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="runtime.classpath" />
		<jvmarg value="-Xmx200m" />
		<jvmarg value="-showversion"/>
		<!-- The name of the federation instance. -->
		<jvmarg value="-Dbigdata.fedname=${standalone.fed}"/>
		<jvmarg value="-Djava.security.policy=policy.all"/>
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dcom.bigdata.counters.linux.sysstat.path=${SYSSTAT_HOME}" />
		<jvmarg value="-Dlog4j.configuration=file:src/resources/config/standalone/log4j.properties"/>
		<arg value="src/resources/config/standalone/bigdataStandalone.config" />
	</java>
</target>

<target name="standalone-stop" depends="jar,standalone-setup" description="Stop the standalone federation.">
	<java classname="com.bigdata.service.jini.util.ShutdownFederation"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="runtime.classpath" />
		<jvmarg value="-Xmx200m" />
		<jvmarg value="-showversion"/>
		<!-- The name of the federation instance. -->
		<jvmarg value="-Dbigdata.fedname=${standalone.fed}"/>
		<jvmarg value="-Djava.security.policy=policy.all"/>
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dcom.bigdata.counters.linux.sysstat.path=${SYSSTAT_HOME}" />
		<jvmarg value="-Dlog4j.configuration=file:src/resources/config/standalone/log4j.properties"/>
		<arg value="src/resources/config/standalone/bigdataStandalone.config" />
	</java>
	<!-- Then take down the lookup service as well. -->
    <antcall target="standalone-stopLookup" />
</target>

<!-- @todo Add target to stand up a SPARQL endpoint for a KB namespace. Could be
     Sesame Server or bigdata REST API. -->
	
<!-- Note: The source files must be "reasonable" for the bulk loader.  Each file
     will be fully parsed into memory before writing onto the database.  Very
     large source files must be split into smaller files.  See the 'split'
     command under unix, but be aware that it will not generate more than 576
     output files (24 x 24 = 576) and only 100 if you are using number suffixes.
     For example, split an NT file into files of 200000 lines each: 
     
     mkdir splits; cd splits
     split -l 200000 ../dataset.nt dataset
     
     You will also have to fix up the file extensions.  You can do this using
     bash as follows:
     
     for file in *; do mv $file $file.nt; done
     
     -->
<target name="standalone-bulk-load" depends="jar" description="Bulk load RDF data into the standalone federation.">
	<java classname="com.bigdata.rdf.load.MappedRDFDataLoadMaster"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="runtime.classpath" />
		<jvmarg value="-Xmx200m" />
		<jvmarg value="-showversion"/>
		<!-- The name of the federation instance. -->
		<jvmarg value="-Dbigdata.fedname=${standalone.fed}"/>
		<jvmarg value="-Djava.security.policy=policy.all"/>
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dcom.bigdata.counters.linux.sysstat.path=${SYSSTAT_HOME}" />
		<jvmarg value="-Dlog4j.configuration=file:src/resources/config/standalone/log4j.properties"/>
		<!--                    -->
		<!-- Per job parameters -->
		<!--                    -->
		<!-- The KB namespace ("kb" is a common default). -->
		<jvmarg value="-Dbigdata.rdf.namespace=U10"/>
		<!-- The job name (same as the KB namespace is a common default). -->
		<jvmarg value="-Dbigdata.rdf.job.name=bulk-load-kb"/>
		<!-- The file or directory containing RDF data to be loaded. 
		
		     Possible interesting data:
		
		     d:/bigdata-perf-analysis/lubm/U10
		     d:/bigdata-perf-analysis/bsbm/bsbm_2785/dataset.nt
		-->
		<jvmarg value="-Dbigdata.rdf.data=d:/bigdata-perf-analysis/lubm/U10"/>
		<!-- The file or directory containing zero or more RDF ontology files to be loaded.
		
			 Note: If you do not want to load any "ontology" data you can point this at an
			 empty directory.  "ontology" data is loaded once - when a new KB instance is
			 created.

			 Possible interesting ontologies:
		
			bigdata-rdf/src/resources/data/lehigh/univ-bench.owl
			d:/bigdata-perf-analysis/emptyDir
		 -->
		<jvmarg value="-Dbigdata.rdf.ontology=bigdata-rdf/src/resources/data/lehigh/univ-bench.owl"/>
		<!-- The main configuration file. -->
		<arg value="src/resources/config/standalone/bigdataStandalone.config" />
	</java>
</target>

	<!--                                                                   -->
	<!--                    MISC. UTILITY TARGETS                          -->
	<!--                                                                   -->
		
<target name="scale-out-sample" description="Run the scale-out sample code.">

		<javac destdir="${build.dir}/classes" classpathref="build.classpath"
		 debug="${javac.debug}" debuglevel="${javac.debuglevel}" verbose="${javac.verbose}"
	     encoding="${javac.encoding}"
	     	>
			<src path="${bigdata.dir}/bigdata-sails/src/samples" />
		</javac>
		<!-- copy resources. -->
		<copy toDir="${build.dir}/classes">
			<fileset dir="${bigdata.dir}/bigdata-sails/src/samples">
				<exclude name="**/*.java" />
				<exclude name="**/package.html" />
			</fileset>
		</copy>
	<java classname="com.bigdata.samples.ScaleOut"
		failonerror="true" fork="true" logerror="true">
		<classpath refid="runtime.classpath" />
		<jvmarg value="-Xmx1500m" />
		<jvmarg value="-Dcom.bigdata.jmx.log4j.disable=true" />
		<jvmarg value="-Dlog4j.configuration=file:bigdata-sails/src/samples/com/bigdata/samples/log4j.properties"/>
		<arg value="${bigdata.config}" />
	</java>
	
</target>

<target name="DataLoader" depends="compile" description="Loads RDF data into a local KB.  You MUST edit this ant target before running it.">
	<java classname="com.bigdata.rdf.store.DataLoader"
          fork="true"
          failonerror="true"
		  >
		<!-- usage: [-namespace namespace] propertyFile (fileOrDir)+ -->
		<!-- Where:                                                  -->
		<!-- [-namespace namespace] is the KB namespace (default is 'kb'). -->
		<!-- propertyFile is a properties file identifying the Journal and
		     giving various Journal and/or kb configuration properties if one
		     or the other needs to be created. -->
		<!-- (fileOrDir)+ is a list of one or more RDF files or directories to
		     be loaded.  zip and gz extensions are recognized, but only one file
		     is loaded per archive. -->
		<arg line="custom.properties fileOrDir"/>
		<jvmarg value="-server"/>
		<!-- Specify the maximum Java heap size. -->
		<jvmarg value="-Xmx10g"/>
		<!-- optionally enable yourkit profiler. 
        <jvmarg value="-DLD_LIBRARY_PATH=/nas/install/yjp-8.0.19/bin/linux-x86-64"/>
        <jvmarg value="-agentpath:/nas/install/yjp-8.0.20/bin/linux-x86-64/libyjpagent.so"/>
        <jvmarg value="-agentlib:yjpagent=disableexceptiontelemetry,disablestacktelemetry"/>
        -->
		<jvmarg value="-XX:+UseParallelOldGC"/>
		<!-- Optional enable GC trace.
		<jvmarg line="-XX:+PrintGCDetails -XX:+PrintGCTimeStamps -Xloggc:jvm_gc.log"/>
		-->
		<classpath>
			<path refid="runtime.classpath" />
        </classpath>
	</java>
</target>

<target name="set-properties" depends="compile"
	 description="Set or change properties for a kb instance. You MUST edit this target to specify the name of the journal.  The new values are read from stdin.">
    <java classname="com.bigdata.rdf.sail.BigdataSailHelper"
          fork="true"
          failonerror="true"
    	  inputstring="com.bigdata.relation.rule.eval.DefaultRuleTaskFactory.nestedSubquery=false"
    	>
<!-- Various things you might want to change:

	  Maximum #of threads for joins.
  	  inputstring="com.bigdata.relation.rule.eval.ProgramTask.maxParallelSubqueries=5"
  	  
  	  Nested subquery vs pipeline joins.
  	  inputstring="com.bigdata.relation.rule.eval.DefaultRuleTaskFactory.nestedSubquery=true"
  	  
-->
          <arg line="d:/LTS.U50.jnl LTS kb"/>
          <classpath>
             <path refid="runtime.classpath" />
          </classpath>
    </java>
</target>

	<!--                                                                   -->
	<!--                    UNIT TESTS ONLY BELOW HERE                     -->
	<!--                                                                   -->
	
    <target name="stage"
            description="stages resources (jar, config, policy, logging files) needed to package or execute the bigdata distribution."
            depends="jar">

      <!-- Create staging directories -->
      <property name="dist.dir" location="${bigdata.dir}/dist/bigdata" />

      <property name="dist.bin" location="${dist.dir}/bin" />
      <property name="dist.lib" location="${dist.dir}/lib" />
      <property name="dist.lib.dl" location="${dist.dir}/lib-dl" />
      <property name="dist.lib.ext" location="${dist.dir}/lib-ext" />
      <property name="dist.var" location="${dist.dir}/var" />

      <property name="dist.var.config" location="${dist.var}/config" />
      <property name="dist.var.config.policy" location="${dist.var.config}/policy" />
      <property name="dist.var.config.logging" location="${dist.var.config}/logging" />
      <property name="dist.var.config.zookeeper" location="${dist.var.config}/zookeeper" />
      <property name="dist.var.config.jini" location="${dist.var.config}/jini" />

      <delete dir="${dist.dir}" quiet="true"/>
      <mkdir dir="${dist.dir}"/>
      <mkdir dir="${dist.bin}"/>
      <mkdir dir="${dist.lib}"/>
      <mkdir dir="${dist.lib.dl}"/>
      <mkdir dir="${dist.lib.ext}"/>
      <mkdir dir="${dist.var}"/>
      <mkdir dir="${dist.var.config}"/>
      <mkdir dir="${dist.var.config.policy}"/>
      <mkdir dir="${dist.var.config.logging}"/>
      <mkdir dir="${dist.var.config.zookeeper}"/>
      <mkdir dir="${dist.var.config.jini}"/>

      <!-- Copy build.properties to the top-level config file -->
      <!-- <root>/dist/bigdata/var/config/bigdata.properties  -->

      <property name="build.properties.from.file" location="${bigdata.dir}/build.properties" />
      <property name="build.properties.to.path" location="${dist.var.config}/build.properties" />
      <property name="build.properties.to.file" location="${build.properties.to.path}/bigdata.properties" />
      <copy file="${build.properties.from.file}"
            tofile="${build.properties.to.file}"/>

      <!-- Copy the jar files created by the jar target to        -->
      <!-- an application-specific but non-version-specific       -->
      <!-- jar file to either the lib or lib-dl staging           -->
      <!-- directory. When a new version of a given application's -->
      <!-- jar file becomes available, the version-specific jar   -->
      <!-- file name should be changed here.                      -->

      <property name="bigdata.lib" location="${bigdata.dir}/bigdata/lib" />
      <property name="bigdata-jini.lib" location="${bigdata.dir}/bigdata-jini/lib/jini/lib" />
      <property name="bigdata-rdf.lib" location="${bigdata.dir}/bigdata-rdf/lib" />
      <property name="bigdata-sails.lib" location="${bigdata.dir}/bigdata-sails/lib" />
      <property name="bigdata-zookeeper.lib" location="${bigdata.dir}/bigdata-jini/lib/apache" />

      <!-- Utility libraries -->

      <copy file="${bigdata.lib}/unimi/colt-1.2.0.jar"
            tofile="${dist.lib}/colt.jar"/>
      <copy file="${bigdata.lib}/ctc_utils-5-4-2005.jar"
            tofile="${dist.lib}/ctc_utils.jar"/>
      <copy file="${bigdata.lib}/cweb-commons-1.1-b2-dev.jar"
            tofile="${dist.lib}/cweb-commons.jar"/>
      <copy file="${bigdata.lib}/cweb-extser-0.1-b2-dev.jar"
            tofile="${dist.lib}/cweb-extser.jar"/>
      <copy file="${bigdata.lib}/unimi/dsiutils-1.0.10.jar"
            tofile="${dist.lib}/dsiutils.jar"/>
      <copy file="${bigdata.lib}/unimi/fastutil-5.1.5.jar"
            tofile="${dist.lib}/fastutil.jar"/>
      <copy file="${bigdata.lib}/icu/icu4j-3_6.jar"
            tofile="${dist.lib}/icu4j.jar"/>
      <copy file="${bigdata.lib}/apache/log4j-1.2.15.jar"
            tofile="${dist.lib}/log4j.jar"/>
      <copy file="${bigdata.lib}/lucene/lucene-analyzers-3.0.0.jar"
            tofile="${dist.lib}/lucene-analyzer.jar"/>
      <copy file="${bigdata.lib}/lucene/lucene-core-3.0.0.jar"
            tofile="${dist.lib}/lucene-core.jar"/>

      <!-- RDF library -->

      <copy file="${bigdata-rdf.lib}/iris-0.58.jar"
            tofile="${dist.lib}/iris.jar"/>
      <copy file="${bigdata-rdf.lib}/openrdf-sesame-2.3.0-onejar.jar"
            tofile="${dist.lib}/openrdf-sesame.jar"/>
      <copy file="${bigdata-rdf.lib}/slf4j-api-1.4.3.jar"
            tofile="${dist.lib}/slf4j.jar"/>
      <copy file="${bigdata-rdf.lib}/slf4j-log4j12-1.4.3.jar"
            tofile="${dist.lib}/slf4j-log4j.jar"/>

      <!-- Zookeeper library -->
      <copy file="${bigdata-zookeeper.lib}/zookeeper-3.2.1.jar"
            tofile="${dist.lib}/zookeeper.jar"/>
<!--
      <copy file="/home/brmurphy/zookeeper/cdd99c5/build/zookeeper-3.3.0.jar"
            tofile="${dist.lib}/zookeeper.jar"/>
-->

      <!-- Jini library -->

      <copy file="${bigdata-jini.lib}/browser.jar"
            todir="${dist.lib}"/>
      <copy file="${bigdata-jini.lib}/classserver.jar"
            todir="${dist.lib}"/>
      <copy file="${bigdata-jini.lib}/jsk-lib.jar"
            todir="${dist.lib}"/>
      <copy file="${bigdata-jini.lib}/jsk-platform.jar"
            todir="${dist.lib}"/>
      <copy file="${bigdata-jini.lib}/jsk-resources.jar"
            todir="${dist.lib}"/>
      <copy file="${bigdata-jini.lib}/reggie.jar"
            todir="${dist.lib}"/>
      <copy file="${bigdata-jini.lib}/start.jar"
            todir="${dist.lib}"/>
      <copy file="${bigdata-jini.lib}/tools.jar"
            todir="${dist.lib}"/>

      <property name="bigdata-jini.lib.dl" location="${bigdata.dir}/bigdata-jini/lib/jini/lib-dl" />

      <copy file="${bigdata-jini.lib.dl}/browser-dl.jar"
            todir="${dist.lib.dl}"/>
      <copy file="${bigdata-jini.lib.dl}/group-dl.jar"
            todir="${dist.lib.dl}"/>
      <copy file="${bigdata-jini.lib.dl}/jsk-dl.jar"
            todir="${dist.lib.dl}"/>
      <copy file="${bigdata-jini.lib.dl}/phoenix-dl.jar"
            todir="${dist.lib.dl}"/>
      <copy file="${bigdata-jini.lib.dl}/reggie-dl.jar/"
            todir="${dist.lib.dl}"/>
      <copy file="${bigdata-jini.lib.dl}/sdm-dl.jar"
            todir="${dist.lib.dl}"/>

      <property name="bigdata-jini.lib.ext" location="${bigdata.dir}/bigdata-jini/lib/jini/lib-ext" />

      <copy file="${bigdata-jini.lib.ext}/jsk-policy.jar"
            todir="${dist.lib.ext}"/>

      <!-- Bigdata library -->
      <property name="bigdata.jar" location="${bigdata.dir}/${build.dir}/${version}.jar" />
      <copy file="${bigdata.dir}/${build.dir}/${version}.jar"
            tofile="${dist.lib}/bigdata.jar"/>

      <property name="src.resources" location="${bigdata.dir}/src/resources" />
      <property name="src.resources.config" location="${src.resources}/config" />

      <!-- Utility scripts -->
      <copy file="${src.resources}/bin/pstart"
            todir="${dist.bin}"/>
      <chmod file="${dist.bin}/pstart" perm="ugo+x"/>


      <!-- Stage security policy (config) files -->
      <copy file="${src.resources.config}/policy.all"
            todir="${dist.var.config.policy}"/>
      <copy file="${src.resources.config}/service.policy"
            todir="${dist.var.config.policy}"/>

      <!-- Stage logging config files -->
      <property name="logging.to.path" location="${dist.var.config.logging}" />

      <property name="log4j.from.file" location="${bigdata.dir}/bigdata/src/resources/logging/log4j.properties" />
      <copy file="${log4j.from.file}"
            todir="${logging.to.path}"/>

      <property name="logging.from.file" location="${bigdata.dir}/bigdata/src/resources/logging/logging.properties" />
      <copy file="${logging.from.file}"
            todir="${logging.to.path}"/>

      <property name="standalone.log4j.from.file" location="${src.resources.config}/standalone/log4j.properties" />
      <property name="standalone.log4j.to.file" location="${logging.to.path}/log4jStandalone.properties" />
      <copy file="${standalone.log4j.from.file}"
            tofile="${standalone.log4j.to.file}"/>

      <property name="server.log4j.from.file" location="${src.resources.config}/log4jServer.properties" />
      <copy file="${server.log4j.from.file}"
            todir="${logging.to.path}"/>

      <copy file="${src.resources.config}/zookeeper-logging.properties"
            todir="${logging.to.path}"/>
      <copy file="${src.resources.config}/reggie-logging.properties"
            todir="${logging.to.path}"/>
      <copy file="${src.resources.config}/browser-logging.properties"
            todir="${logging.to.path}"/>


      <!-- Stage Zookeeper config files -->


      <!-- Stage Jini config files -->
      <copy file="${src.resources.config}/bigdataCluster.config"
            todir="${dist.var.config.jini}"/>
      <copy file="${src.resources.config}/bigdataCluster16.config"
            todir="${dist.var.config.jini}"/>

      <copy file="${src.resources.config}/jini/zookeeper.config"
            todir="${dist.var.config.jini}"/>
      <copy file="${src.resources.config}/jini/reggie.config"
            todir="${dist.var.config.jini}"/>
      <copy file="${src.resources.config}/jini/browser.config"
            todir="${dist.var.config.jini}"/>
      <copy file="${src.resources.config}/jini/serviceStarterAll.config"
            todir="${dist.var.config.jini}"/>
      <copy file="${src.resources.config}/jini/serviceStarterOne.config"
            todir="${dist.var.config.jini}"/>
    </target>

    <target name="testCompile"
            description="compiles the test source and generates the appropriate jar files."
            depends="stage">

      <property name="classes.dir" location="${bigdata.dir}/${build.dir}/classes" />

      <!-- Some of the tests look for build.properties in the user's  -->
      <!-- home directory, so must copy it from its location in the   -->
      <!-- codebase to that home directory.                           -->

      <property name="build.properties.test.to.path" location="${user.home}" />
      <property name="build.properties.test.to.file" location="${build.properties.test.to.path}/build.properties" />

      <!-- Want value (not location) for relative paths to log4j      -->
      <!-- config file so the junit classloader will search for that  -->
      <!-- file on the classpath. Thus, use location (instead of      -->
      <!-- value) for absolute paths so fully-qualified paths are     -->
      <!-- used when copying that file under the classes dir.         -->

      <property name="bigdata.test.log4j.rel.path" value="resources/logging" />
      <property name="bigdata.test.log4j.rel" value="${bigdata.test.log4j.rel.path}/log4j.properties" />

      <property name="bigdata.test.log4j.abs.path" location="${classes.dir}/test/${bigdata.test.log4j.rel.path}" />
      <property name="bigdata.test.log4j.abs" location="${bigdata.test.log4j.abs.path}/log4j.properties" />

      <!-- Version-specific jar files that are only needed when       -->
      <!-- running the tests. When a new version of one of these jars -->
      <!-- is available, change the corresponding property value set  -->
      <!-- below.                                                     -->

      <property name="junit.jar" location="${bigdata.lib}/junit-3.8.1.jar" />
      <property name="cweb-junit-ext.jar" location="${bigdata.lib}/cweb-junit-ext-1.1-b3-dev.jar" />
      <property name="sesame-sparql-test.jar" location="${bigdata-sails.lib}/sesame-sparql-testsuite-2.3.0.jar" />
      <property name="sesame-store-test.jar" location="${bigdata-sails.lib}/sesame-store-testsuite-2.3.0.jar" />

      <property name="classes.test.dir" location="${classes.dir}/test" />
      <mkdir dir="${classes.test.dir}"/>

      <property name="bigdata-test.lib" location="${bigdata.dir}/bigdata-test/lib" />
      <mkdir dir="${bigdata-test.lib}"/>
      <property name="bigdata-test.jar" location="${bigdata-test.lib}/bigdata-test.jar" />

      <property name="javac.test.classpath" value="${classes.dir}:${junit.jar}:${cweb-junit-ext.jar}:${sesame-sparql-test.jar}:${sesame-store-test.jar}:${dist.lib}/classserver.jar:${dist.lib}/ctc_utils.jar:${dist.lib}/cweb-commons.jar:${dist.lib}/cweb-extser.jar:${dist.lib}/dsiutils.jar:${dist.lib}/fastutil.jar:${dist.lib}/icu4j.jar:${dist.lib}/iris.jar:${dist.lib}/log4j.jar:${dist.lib}/openrdf-sesame.jar:${dist.lib}/slf4j.jar:${dist.lib}/jsk-lib.jar:${dist.lib}/jsk-platform.jar:${dist.lib}/zookeeper.jar"/>

      <echo>javac
</echo>
      <echo>    javac.test.classpath="${javac.test.classpath}"
</echo>
      <echo>    destdir="${classes.test.dir}"
</echo>
      <echo>    fork="yes"
</echo>
      <echo>    debug="yes"
</echo>
      <echo>    debuglevel="${javac.debuglevel}"
</echo>
      <echo>    deprecation="no"
</echo>
      <echo>    nowarn="no"
</echo>
      <echo>    source="1.5"
</echo>
      <echo>    target="1.5"
</echo>
      <echo>    verbose="${javac.verbose}"
</echo>

       <javac	fork="yes"
		debug="yes"
		debuglevel="${javac.debuglevel}"
		deprecation="no"
		destdir="${classes.test.dir}"
		nowarn="no"
		source="1.5"
		target="1.5"
		classpath="${javac.test.classpath}"
		verbose="${javac.verbose}">

        <src path="${bigdata.dir}/lgpl-utils/src/test"/>
        <src path="${bigdata.dir}/bigdata/src/test"/>
        <src path="${bigdata.dir}/bigdata-jini/src/test"/>
        <src path="${bigdata.dir}/bigdata-rdf/src/test"/>
        <src path="${bigdata.dir}/bigdata-sails/src/test"/>
<!--
        <src path="${bigdata.dir}/bigdata-gom/src/test"/>
-->
        <compilerarg value="-version"/>
      </javac>

      <!-- Make logging config file available to test framework -->

      <delete file="${bigdata.test.log4j.abs}" quiet="true"/>
      <copy file="${dist.var.config.logging}/log4j.properties"
            todir="${bigdata.test.log4j.abs.path}"/>

      <!-- Generate bigdata-test.jar file -->

      <delete file="${bigdata-test.jar}" quiet="true"/>
      <jar destfile="${bigdata-test.jar}"
           index="false">
        <manifest>
          <attribute name="Manifest-Version" value="1.0"/>
        </manifest>

        <fileset dir="${classes.test.dir}">
            <include name="**/*.class"/>
            <include name="**/log4j*.properties"/>
        </fileset>

        <fileset dir="${bigdata.dir}/bigdata/src/test">
            <include name="**/*.csv"/>
            <include name="**/*.xml"/>
            <include name="**/*.dtd"/>
        </fileset>

        <fileset dir="${bigdata.dir}/bigdata-rdf/src/test">
            <include name="**/*.rdf"/>
        </fileset>

        <fileset dir="${bigdata.dir}">
            <include name="**/*.owl"/>
        </fileset>
      </jar>

      <!-- Generate lookupstarter.jar file -->

      <delete file="${bigdata-test.lib}/lookupstarter.jar" quiet="true"/>
      <jar destfile="${bigdata-test.lib}/lookupstarter.jar"
           index="false">
        <manifest>
          <attribute name="Manifest-Version" value="1.0"/>
          <attribute name="Class-Path" value="log4j.jar jsk-platform.jar jsk-lib.jar start.jar bigdata.jar"/>
          <attribute name="Main-Class" value="com.bigdata.service.jini.util.LookupStarter"/>
        </manifest>

        <fileset dir="${classes.test.dir}">
            <include name="**/LookupStarter*.class"/>
            <include name="**/LogUtil.class"/>
            <include name="**/NicUtil.class"/>
            <include name="**/log4j.properties"/>
        </fileset>
      </jar>

      <!-- For manifest Class-Path to be visible to lookupstarter.jar -->
      <!-- the referenced jar files must be in or under the same      -->
      <!-- directory as lookupstarter.jar itself; which is created    -->
      <!-- in ${bigdata-test.lib}. Thus, the required jar files are   -->
      <!-- copied into that directory.                                -->

      <delete file="${bigdata-test.lib}/log4j.jar" quiet="true"/>
      <delete file="${bigdata-test.lib}/jsk-platform.jar" quiet="true"/>
      <delete file="${bigdata-test.lib}/jsk-lib.jar" quiet="true"/>
      <delete file="${bigdata-test.lib}/start.jar" quiet="true"/>
      <delete file="${bigdata-test.lib}/bigdata.jar" quiet="true"/>

      <copy file="${dist.lib}/log4j.jar"
            todir="${bigdata-test.lib}"/>
      <copy file="${dist.lib}/jsk-platform.jar"
            todir="${bigdata-test.lib}"/>
      <copy file="${dist.lib}/jsk-lib.jar"
            todir="${bigdata-test.lib}"/>
      <copy file="${dist.lib}/start.jar"
            todir="${bigdata-test.lib}"/>
      <copy file="${dist.lib}/bigdata.jar"
            todir="${bigdata-test.lib}"/>

    </target>

    <target name="junit"
            description="starts http class server, lookup service, runs junit tests, stops lookup service, stops http class server."
            depends="testCompile">

      <exec executable="hostname"
        outputproperty="this.hostname">
      </exec>

      <property name="app.home" location="${bigdata.dir}" />

      <property name="test.codebase.port" value="23333"/>
      <property name="test.codebase.dir" value="${dist.lib.dl}"/>
      <property name="test.codebase" value="http://${this.hostname}:${test.codebase.port}/jsk-dl.jar"/>

      <property name="java.security.policy" value="${dist.var.config.policy}/policy.all"/>
      <property name="log4j.configuration" value="${bigdata.test.log4j.rel}"/>
      <property name="java.net.preferIPv4Stack" value="true"/>
      <property name="bigdata.fedname" value="bigdata.test.group-${this.hostname}"/>

      <delete file="${build.properties.test.to.file}" quiet="true"/>
      <copy file="${build.properties.from.file}"
            todir="${build.properties.test.to.path}"/>

      <antcall target="startHttpd" />
      <antcall target="startLookup" />

      <!-- Run the tests -->
      <antcall target="run-junit" />

      <antcall target="stopLookup" />
      <antcall target="stopHttpd" />
    </target>

    <target name="startHttpd">
      <echo>java -jar ${dist.lib}/classserver.jar -verbose -stoppable -port ${test.codebase.port} -dir ${test.codebase.dir}
</echo>
        <java jar="${dist.lib}/classserver.jar"
              fork="true"
              spawn="true">
          <arg value="-verbose"                   />
          <arg value="-stoppable"                 />
          <arg line="-port ${test.codebase.port}" />
          <arg line="-dir  '${test.codebase.dir}'"  />
        </java>
    </target>

    <target name="stopHttpd">
      <echo>java -jar ${dist.lib}/classserver.jar -port ${test.codebase.port} -dir ${test.codebase.dir} -stop
</echo>
        <java jar="${dist.lib}/classserver.jar"
              fork="true"
              failonerror="true">
          <arg line="-port ${test.codebase.port}" />
          <arg line="-dir  '${test.codebase.dir}'"  />
          <arg value="-stop"                      />
        </java>
    </target>

    <target name="startLookup">
      <echo>java -Dapp.home=${app.home} -Djini.lib=${dist.lib} -Djini.lib.dl=${dist.lib.dl} -Djava.security.policy=${java.security.policy} -Djava.security.debug=off -Djava.protocol.handler.pkgs=net.jini.url -Dlog4j.configuration=${log4j.configuration} -Dcodebase.port=${test.codebase.port} -Djava.net.preferIPv4Stack=${java.net.preferIPv4Stack} -Dbigdata.fedname=${bigdata.fedname} -jar ${bigdata-test.lib}/lookupstarter.jar
</echo>
      <echo>
</echo>

      <java jar="${bigdata-test.lib}/lookupstarter.jar"
            fork="true"
            spawn="true">
        <sysproperty key="app.home" value="${app.home}"/>
        <sysproperty key="jini.lib" value="${dist.lib}"/>
        <sysproperty key="jini.lib.dl" value="${dist.lib.dl}"/>
        <sysproperty key="java.security.policy" value="${java.security.policy}"/>
        <sysproperty key="java.security.debug" value="off"/>
        <sysproperty key="java.protocol.handler.pkgs" value="net.jini.url"/>
        <sysproperty key="log4j.configuration" value="${log4j.configuration}"/>
        <sysproperty key="codebase.port" value="${test.codebase.port}"/>
        <sysproperty key="java.net.preferIPv4Stack" value="${java.net.preferIPv4Stack}"/>
        <sysproperty key="bigdata.fedname" value="${bigdata.fedname}"/>
      </java>
    </target>

    <target name="stopLookup">
      <echo>java -Dapp.home=${app.home} -Djini.lib=${dist.lib} -Djini.lib.dl=${dist.lib.dl} -Djava.security.policy=${java.security.policy} -Dlog4j.configuration=${log4j.configuration} -Djava.net.preferIPv4Stack=${java.net.preferIPv4Stack} -Dbigdata.fedname=${bigdata.fedname} -jar ${bigdata-test.lib}/lookupstarter.jar -stop
</echo>
      <echo>
</echo>
      <java jar="${bigdata-test.lib}/lookupstarter.jar"
            fork="true"
            failonerror="true">
        <sysproperty key="app.home" value="${app.home}"/>
        <sysproperty key="jini.lib" value="${dist.lib}"/>
        <sysproperty key="jini.lib.dl" value="${dist.lib.dl}"/>
        <sysproperty key="java.security.policy" value="${java.security.policy}"/>
        <sysproperty key="log4j.configuration" value="${log4j.configuration}"/>
        <sysproperty key="java.net.preferIPv4Stack" value="${java.net.preferIPv4Stack}"/>
        <sysproperty key="bigdata.fedname" value="${bigdata.fedname}"/>
        <arg value="-stop" />
      </java>
    </target>

    <!-- runs all junit tests -->
    <target name="run-junit">

      <path id="run.class.path.id">
        <pathelement location="${junit.jar}"/>
        <pathelement location="${bigdata-test.jar}"/>
        <pathelement location="${cweb-junit-ext.jar}"/>
        <pathelement location="${sesame-sparql-test.jar}"/>
        <pathelement location="${sesame-store-test.jar}"/>
        <pathelement location="${dist.lib}/bigdata.jar"/>
        <pathelement location="${dist.lib}/colt.jar"/>
        <pathelement location="${dist.lib}/cweb-commons.jar"/>
        <pathelement location="${dist.lib}/cweb-extser.jar"/>
        <pathelement location="${dist.lib}/ctc_utils.jar"/>
        <pathelement location="${dist.lib}/dsiutils.jar"/>
        <pathelement location="${dist.lib}/fastutil.jar"/>
        <pathelement location="${dist.lib}/icu4j.jar"/>
        <pathelement location="${dist.lib}/iris.jar"/>
        <pathelement location="${dist.lib}/jsk-lib.jar"/>
        <pathelement location="${dist.lib}/jsk-platform.jar"/>
        <pathelement location="${dist.lib}/log4j.jar"/>
        <pathelement location="${dist.lib}/lucene-analyzer.jar"/>
        <pathelement location="${dist.lib}/lucene-core.jar"/>
        <pathelement location="${dist.lib}/openrdf-sesame.jar"/>
        <pathelement location="${dist.lib}/slf4j.jar"/>
        <pathelement location="${dist.lib}/slf4j-log4j.jar"/>
        <pathelement location="${dist.lib}/zookeeper.jar"/>
      </path>

      <property name="run.class.path" value="${junit.jar}:${bigdata-test.jar}:${cweb-junit-ext.jar}:${sesame-sparql-test.jar}:${sesame-store-test.jar}:${dist.lib}/bigdata.jar:${dist.lib}/colt.jar:${dist.lib}/cweb-commons.jar:${dist.lib}/cweb-extser.jar:${dist.lib}/ctc_utils.jar:${dist.lib}/dsiutils.jar:${dist.lib}/fastutil.jar:${dist.lib}/icu4j.jar:${dist.lib}/iris.jar:${dist.lib}/jsk-lib.jar:${dist.lib}/jsk-platform.jar:${dist.lib}/log4j.jar:${dist.lib}/lucene-analyzer.jar:${dist.lib}/lucene-core.jar:${dist.lib}/openrdf-sesame.jar:${dist.lib}/slf4j.jar:${dist.lib}/slf4j-log4j.jar:${dist.lib}/zookeeper.jar"/>

      <echo>    classpath:    ${run.class.path}
</echo>
      <echo>    log4j.config: ${log4j.configuration}
</echo>
      <echo>    log4j.abs:    ${bigdata.test.log4j.abs}
</echo>
      <echo>    app.home:     ${app.home}
</echo>
      <echo>    jini.lib:     ${dist.lib}
</echo>
      <echo>    jini.lib.dl:  ${dist.lib.dl}
</echo>
      <echo>    policy:       ${java.security.policy}
</echo>
      <echo>    hostname:     ${this.hostname}
</echo>
      <echo>    preferIPv4:   ${java.net.preferIPv4Stack}
</echo>
      <echo>    federation:   ${bigdata.fedname}
</echo>
      <echo>
</echo>

      <property name="test.results.dir" location="${classes.test.dir}/test-results" />
      <delete dir="${test.results.dir}" quiet="true"/>
      <mkdir dir="${test.results.dir}"/>

      <condition property="testClass" value="${testName}">
        <isset property="testName" />
      </condition>

      <junit printsummary="on" haltonfailure="no" fork="no" dir="${classes.dir}" timeout="60000">
        <formatter type="xml"/>

        <sysproperty key="java.security.policy" value="${java.security.policy}"/>
        <sysproperty key="java.net.preferIPv4Stack" value="{java.net.preferIPv4Stack}"/>

        <sysproperty key="log4j.configuration" value="${log4j.configuration}"/>
<!--
        <sysproperty key="log4j.debug" value="true"/>
-->
        <!-- There is at least one service that is started by the test  -->
        <!-- infrastructure from within program control (zookeeper).    -->
        <!-- Prior to starting that service, a number of values may be  -->
        <!-- retrieved from a jini configuration file. To avoid         -->
        <!-- hard-coding things like absolute paths and version         -->
        <!-- information in those jini configuration files, the Java    -->
        <!-- property substitution mechanism is employed to allow one   -->
        <!-- to set the necessary values in a system property here, in  -->
        <!-- one place, and then simply reference that system property  -->
        <!-- in the appropriate places in each configuration file.      -->
        <!--                                                            -->
        <!-- For example, prior to starting the zookeeper component,    -->
        <!-- the entry named 'log4j' is retrieved from a jini config    -->
        <!-- and the system property '-Dlog4j.configuration' is set to  -->
        <!-- the value that is retrieved. Because the ant-build/classes -->
        <!-- directory is not included in the classpath used to start   -->
        <!-- zookeeper, the relative path value in the                  -->
        <!-- 'log4j.configuration' system property that is set in       -->
        <!-- this file cannot be used in the zookeeper component of     -->
        <!-- the jini config file; rather, the absolute path must be    -->
        <!-- used. Because of this, the 'log4j.path' system property    -->
        <!-- is set to the absolute path below; and will be substituted -->
        <!-- when the 'log4j' entry is retrieved from the config file.  -->
        <!--                                                            -->
        <!-- To avoid having to specify a specific jar file versions    -->
        <!-- for the classpath entry of such a config file, system      -->
        <!-- properties referencing the absolute paths of the various   -->
        <!-- versioned jar files referenced above are similarly set.    -->
        <!-- In this way, when a new version of such a jar is deployed, -->
        <!-- changing the appropriate property value above is all       -->
        <!-- that should be required.                                   -->

        <sysproperty key="log4j.path" value="${bigdata.test.log4j.abs.path}"/>

        <sysproperty key="classserver.jar" value="${dist.lib}/classserver.jar" />
        <sysproperty key="colt.jar" value="${dist.lib}/colt.jar" />
        <sysproperty key="ctc_utils.jar" value="${dist.lib}/ctc_utils.jar" />
        <sysproperty key="cweb-commons.jar" value="${dist.lib}/cweb-commons.jar" />
        <sysproperty key="cweb-extser.jar" value="${dist.lib}/cweb-extser.jar" />
        <sysproperty key="dsiutils.jar" value="${dist.lib}/dsiutils.jar" />
        <sysproperty key="fastutil.jar" value="${dist.lib}/fastutil.jar" />
        <sysproperty key="icu4j.jar" value="${dist.lib}/icu4j.jar" />
        <sysproperty key="jsk-lib.jar" value="${dist.lib}/jsk-lib.jar" />
        <sysproperty key="jsk-platform.jar" value="${dist.lib}/jsk-platform.jar" />
        <sysproperty key="log4j.jar" value="${dist.lib}/log4j.jar" />
        <sysproperty key="iris.jar" value="${dist.lib}/iris.jar" />
        <sysproperty key="openrdf-sesame.jar" value="${dist.lib}/openrdf-sesame.jar" />
        <sysproperty key="slf4j.jar" value="${dist.lib}/slf4j.jar" />
        <sysproperty key="zookeeper.jar" value="${dist.lib}/zookeeper.jar" />

        <!-- Jini group name -->
        <sysproperty key="bigdata.fedname" value="${bigdata.fedname}"/>

        <classpath refid="run.class.path.id"/>

        <!-- Individual test suite to run when -DtestName is set -->
        <!-- to the fully-qualified name of the test suite       -->
        <!-- ant -DtestName=com.bigdata.cache.TestAll junit      -->

        <sysproperty key="testClass" value="${testClass}"/>
        <test name="${testName}" todir="${test.results.dir}" if="testName"/>

        <!-- Test suites to run when -DtestName is not set -->

        <test name="com.bigdata.cache.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.io.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.net.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.config.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.util.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.util.concurrent.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.striterator.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.counters.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.rawstore.TestAll" todir="${test.results.dir}" unless="testName" />

        <test name="com.bigdata.btree.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.concurrent.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.journal.TestAll" todir="${test.results.dir}" unless="testName" />

        <test name="com.bigdata.resources.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.mdi.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.service.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.sparse.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.search.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.relation.TestAll" todir="${test.results.dir}" unless="testName" />

      	<!-- See https://sourceforge.net/apps/trac/bigdata/ticket/53 -->
        <test name="com.bigdata.jini.TestAll" todir="${test.results.dir}" unless="testName" />
        	
        <test name="com.bigdata.rdf.TestAll" todir="${test.results.dir}" unless="testName" />
        <test name="com.bigdata.rdf.sail.TestAll" todir="${test.results.dir}" unless="testName" />

<!-- All tests.
        <test name="com.bigdata.TestAll" todir="${test.results.dir}" unless="testName" />
-->
      </junit>

      <!-- Clean out the SPARQL test suite unpacked by Sesame. -->
      <antcall target="clean-sparql-test-suite"/>

      <!-- Generate an HTML report. -->
      <junitreport todir="${test.results.dir}">
        <fileset dir="${test.results.dir}">
          <include name="TEST-*.xml"/>
         </fileset>
         <report format="frames" todir="${test.results.dir}/report"/>
      </junitreport>

    </target>

	<target name="clean-sparql-test-suite" description="delete the files unpacked by the Sesame SPARQL test suite.">
		<echo>"clearing: ${java.io.tmpdir}/sparql-*"</echo>
	    <delete verbose="true">
	    	<dirset dir="${java.io.tmpdir}" includes="sparql-*"/>
		</delete>
	</target>
	
	<!--                                                                   -->
	<!--                    PERFORMANCE TESTS                              -->
	<!--                                                                   -->

	<target name="run-performance-tests" depends="testCompile, lubm-jar" description="Runs a variety of performance tests.">
		<!-- Note: This depends on the stage target. -->
	      <path id="run.class.path.id">
	        <pathelement location="${junit.jar}"/>
	        <pathelement location="${bigdata-test.jar}"/>
	        <pathelement location="${cweb-junit-ext.jar}"/>
	        <pathelement location="${sesame-sparql-test.jar}"/>
	        <pathelement location="${sesame-store-test.jar}"/>
	        <pathelement location="${dist.lib}/bigdata.jar"/>
	        <pathelement location="${dist.lib}/colt.jar"/>
	        <pathelement location="${dist.lib}/cweb-commons.jar"/>
	        <pathelement location="${dist.lib}/cweb-extser.jar"/>
	        <pathelement location="${dist.lib}/ctc_utils.jar"/>
	        <pathelement location="${dist.lib}/dsiutils.jar"/>
	        <pathelement location="${dist.lib}/fastutil.jar"/>
	        <pathelement location="${dist.lib}/icu4j.jar"/>
	        <pathelement location="${dist.lib}/iris.jar"/>
	        <pathelement location="${dist.lib}/jsk-lib.jar"/>
	        <pathelement location="${dist.lib}/jsk-platform.jar"/>
	        <pathelement location="${dist.lib}/log4j.jar"/>
	        <pathelement location="${dist.lib}/lucene-analyzer.jar"/>
	        <pathelement location="${dist.lib}/lucene-core.jar"/>
	        <pathelement location="${dist.lib}/openrdf-sesame.jar"/>
	        <pathelement location="${dist.lib}/slf4j.jar"/>
	        <pathelement location="${dist.lib}/slf4j-log4j.jar"/>
	        <pathelement location="${dist.lib}/zookeeper.jar"/>
	      </path>
	      <property name="run.class.path" value="${junit.jar}:${bigdata-test.jar}:${cweb-junit-ext.jar}:${sesame-sparql-test.jar}:${sesame-store-test.jar}:${dist.lib}/bigdata.jar:${dist.lib}/colt.jar:${dist.lib}/cweb-commons.jar:${dist.lib}/cweb-extser.jar:${dist.lib}/ctc_utils.jar:${dist.lib}/dsiutils.jar:${dist.lib}/fastutil.jar:${dist.lib}/icu4j.jar:${dist.lib}/iris.jar:${dist.lib}/jsk-lib.jar:${dist.lib}/jsk-platform.jar:${dist.lib}/log4j.jar:${dist.lib}/lucene-analyzer.jar:${dist.lib}/lucene-core.jar:${dist.lib}/openrdf-sesame.jar:${dist.lib}/slf4j.jar:${dist.lib}/slf4j-log4j.jar:${dist.lib}/zookeeper.jar"/>
		<!-- Generate the LUBM dataset. 
		<mkdir dir="${data}"/>
		<java classname="edu.lehigh.swat.bench.uba.Generator" dir="${data}" fork="yes">
			<classpath>
				<path refid="run.class.path.id"/>
				<pathelement location="${build.dir}/lubm/lib/bigdata-lubm.jar"/>
			</classpath>
			<jvmarg value="-server"/>
			<jvmarg value="-Xmx400m"/>
			<jvmarg value="-Dlog4j.configuration=file:bigdata/src/resources/logging/log4j-perf-tests.properties"/>
			<arg value="-subdirs"/>
			<arg value="-compress"/>
			<arg value="GZip"/>
			<arg value="-univ"/>
			<arg value="50"/>
			<arg value="-onto"/>
			<arg value="http://www.lehigh.edu/~zhp2/2004/0401/univ-bench.owl"/>
		</java>
		-->
		<!-- Delete the generated LUBM data set.
		<delete dir="${data}"/>
		-->
		<!-- Run the data load, closure and query performance tests. -->
		<copy file="bigdata/src/resources/logging/log4j-perf-tests.properties" todir="${perf.run.dir}"/>
		<copy file="bigdata-sails/src/test/com/bigdata/rdf/stress/testLubm.xml" todir="${perf.run.dir}"/>
		<java classname="com.bigdata.test.ExperimentDriver" dir="${perf.run.dir}" fork="yes">
			<classpath refid="run.class.path.id"/>
			<jvmarg value="-server"/>
			<jvmarg value="-Xmx2g"/>
			<!-- Override the temporary directory to the specified run directory. -->
			<jvmarg value="-Djava.io.tmpdir=${perf.run.dir}"/>
			<jvmarg value="-Dlog4j.configuration=file:log4j-perf-tests.properties"/>
			<jvmarg value="-Dontology=${perf.data.dir}/lubm/univ-bench.owl"/>
			<jvmarg value="-Ddata=${perf.data.dir}/lubm/U50"/>
			<jvmarg value="-Dquery=${perf.data.dir}/lubm/config.query.sparql"/>
			<arg value="testLubm.xml"/>
		</java>
		<!-- Copy the results from the performance run @todo w/ append! 
		
		Consider an after-action to do that and then delete the perf.run.dir.
		
		<copy file="${perf.run.dir}/com.bigdata.rdf.stress.LoadClosureAndQueryTest.exp.csv" todir="."/>
		-->
		<!-- Delete the runs directory, but FIRST copy out the results (with append).
		<copy></copy>
		<delete dir=${perf.run.dir}/>
		-->
	</target>

	<!--                                                                   -->
	<!--                    SESAME SERVER TARGETS                          -->
	<!--                                                                   -->
	
	<target name="install.sesame.server" depends="jar">
	
		<!-- copy resources to Sesame webapp. -->
		<copy toDir="${sesame.server.dir}/WEB-INF/lib" 
				file="${build.dir}/${version}.jar"/>
				
		<copy toDir="${sesame.server.dir}/WEB-INF/lib" flatten="true">
			<fileset dir="${bigdata.dir}/bigdata/lib">
			    <include name="**/*.jar" />
			</fileset>
		</copy>
		
		<!-- copy resources to Workbench webapp. -->
		<copy toDir="${workbench.server.dir}/WEB-INF/lib" 
				file="${build.dir}/${version}.jar"/>
				
		<copy toDir="${workbench.server.dir}/WEB-INF/lib" flatten="true">
			<fileset dir="${bigdata.dir}/bigdata/lib">
			    <include name="**/*.jar" />
			</fileset>
		</copy>
		
		<!-- copy template resources to ADUNA_DATA dir -->
		<copy toDir="${aduna.data.dir}">
			<fileset dir="${bigdata.dir}/bigdata-sails/src/resources/sesame-server">
	            <include name="templates/**"/>
			</fileset>
		</copy>
		
		<!-- copy bigdata jar to Sesame installation. -->
		<copy toDir="${sesame.dir}/lib" 
				file="${build.dir}/${version}.jar"/>
				
	</target>

	<path id="samples.build.classpath">
		<pathelement location="${build.dir}/classes" />
		<path refid="build.classpath" />
	</path>

	<path id="samples.runtime.classpath">
		<pathelement location="${build.dir}/samples/classes"/>
		<path refid="samples.build.classpath" />
	</path>

	<target name="samples.compile" depends="compile">
		<mkdir dir="${build.dir}/samples/classes" />
		<javac destdir="${build.dir}/samples/classes" classpathref="samples.build.classpath"
		 debug="${javac.debug}" debuglevel="${javac.debuglevel}" verbose="${javac.verbose}"
	     encoding="${javac.encoding}"
	     	>
			<src path="${bigdata.dir}/bigdata-sails/src/samples" />
			<compilerarg value="-version"/>
		</javac>
		<!-- copy resources. -->
		<copy toDir="${build.dir}/samples/classes">
			<fileset dir="${bigdata.dir}/bigdata-sails/src/samples">
				<exclude name="**/*.java" />
			</fileset>
		</copy>
	</target>
	
	<target name="DemoSesameServer" depends="samples.compile" description="Runs the DemoSesameServer sample code.">
		<java classname="com.bigdata.samples.remoting.DemoSesameServer"
			failonerror="true" fork="false" logerror="true">
			<classpath refid="samples.runtime.classpath" />
			<arg value="http://localhost:8080/openrdf-sesame"/>
			<arg value="bigdata"/>
		</java>
	</target>



</project>
