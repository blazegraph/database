nciOncology.owl, embedded federation.

INFO : 31844   Main Thread com.bigdata.rdf.rio.BasicRioLoader.loadRdf(BasicRioLoader.java:194): parse complete: elapsed=28187ms, toldTriples=464841, tps=16491

INFO : 882875   Main Thread com.bigdata.rdf.store.DataLoader.loadData(DataLoader.java:517): Loaded 1 resources: 464841 stmts added in 28.265 secs, rate= 528, commitLatency=0ms
rule    	ms	#entms	entms/ms
RuleFastClosure13	15	0	0
RuleOwlEquivalentProperty	16	0	0
RuleRdfs02	5890	395806	67
RuleRdfs03	3297	395806	120
RuleRdfs08	31	41618	1342
RuleRdfs09	12109	41724	3
RuleRdfs10	110	41618	378
RuleRdfs11	720126	5324314	7
totals: elapsed=741594, nadded=376849, numComputed=6241034, added/sec=508, computed/sec=8415

Note: this appears to be incremental TM rather than database at once closure.

========================================

Modified to use database at once closure.

nciOncology.owl, embedded federation.

INFO : 36188   Main Thread com.bigdata.rdf.store.DataLoader.loadData2(DataLoader.java:628): 464841 stmts added in 32.109 secs, rate= 14476, commitLatency=0ms

rule    	ms	#entms	entms/ms
RuleOwlEquivalentProperty	157	0	0
RuleRdf01	110	43	0
RuleRdfs02	8859	395958	44
RuleRdfs03	7125	395958	55
RuleRdfs08	250	41631	166
RuleRdfs09	11406	41759	3
RuleRdfs10	219	41631	190
RuleRdfs11	240719	3951672	16
totals: elapsed=268845, nadded=3951672, numComputed=4868778, added/sec=14698, computed/sec=18109

Computed closure in 301500ms yeilding 841842 statements total, 376849 inferences, entailmentsPerSec=1249


============================================================


nciOncology.owl, no closure.

ids: #entries(est)=289871
SPO: #entries(est)=464993
POS: #entries(est)=464993
OSP: #entries(est)=464993
just: #entries(est)=0

!!!Note: be careful to choose the line that reports after the commit on the store!!!

local, unisolated:

run 1: Loaded 1 resources: 464841 stmts added in 23.656 secs, rate= 19650, commitLatency=172ms
run 2: Loaded 1 resources: 464841 stmts added in 24.094 secs, rate= 19292, commitLatency=156ms
run 3: Loaded 1 resources: 464841 stmts added in 24.328 secs, rate= 19107, commitLatency=235ms (after refactor for procedures)
(Computed closure in 141047ms yeilding 841842 statements total, 376849 inferences, entailmentsPerSec=2671)

local, isolated:

run 1: Loaded 1 resources: 464841 stmts added in 26.735 secs, rate= 17386, commitLatency=438ms
run 2: Loaded 1 resources: 464841 stmts added in 25.719 secs, rate= 18073, commitLatency=297ms

embedded data service:
run 1: Loaded 1 resources: 464841 stmts added in 27.532 secs, rate= 16883, commitLatency=0ms (SPOArrayIterator)
(Computed closure in 375953ms yeilding 841842 statements total, 376849 inferences, entailmentsPerSec=1002)
run 2: Loaded 1 resources: 464841 stmts added in 27.016 secs, rate= 17206, commitLatency=0ms (SPOIterator - no mem cap)
(Computed closure in 482453ms yeilding 841842 statements total, 376849 inferences, entailmentsPerSec=781)
ren 3: Loaded 1 resources: 464841 stmts added in 27.485 secs, rate= 16912, commitLatency=0ms (SPOIterator - no mem cap)
(Computed closure in 436266ms yeilding 841842 statements total, 376849 inferences, entailmentsPerSec=863)

embedded federation:

run 1: Loaded 1 resources: 464841 stmts added in 32.313 secs, rate= 14385, commitLatency=31ms

jini federation:

run 1: Loaded 1 resources: 464841 stmts added in 57.204 secs, rate= 8126, commitLatency=16ms
run 2: Loaded 1 resources: 464841 stmts added in 49.172 secs, rate= 9453, commitLatency=16ms

(done) Report more data about the scale-out indices, including the #of
partitions, where each partition is located, and the size on disk on
the partition (the btrees on the journal are conflated so the journal
space needs to be factored out but we can report the #of entries on
the journal and maybe even the bytes written on the journal by the
btree).  Call out the time spent on each index - we need better
counters to report that correctly, or even counters on the data
service.

The embedded federation has a substantial drop in performance when
compared to the local store using isolated indices (the data services
always use isolated indices so that is the point for comparison), but
the big drop is the jini federation - presumably that cost is entirely
attributable to the serialization overhead for RPCs.

Examine in more depth why the embedded federation is slower.  Try a
run on a larger data set and see if this is related to start up costs.

Thesaurus.owl: #terms=586945, #stmts=1,047,647

local, unisolated  : Loaded 1 resources: 1086012 stmts added in  59.609 secs, rate= 18218, commitLatency=312ms
                   : Loaded 1 resources: 1086012 stmts added in  57.765 secs, rate= 18800, commitLatency=328ms
                   : Loaded 1 resources: 1086012 stmts added in  58.313 secs, rate= 18623, commitLatency=312ms
		   : Loaded 1 resources: 1086012 stmts added in  58.687 secs, rate= 18505, commitLatency=312ms (keybuilder refactor)
local,   isolated  : Loaded 1 resources: 1086012 stmts added in  64.562 secs, rate= 16821, commitLatency=156ms
embedded federation: Loaded 1 resources: 1086012 stmts added in  76.969 secs, rate= 14109, commitLatency=31ms
                   : Loaded 1 resources: 1086012 stmts added in  76.938 secs, rate= 14115, commitLatency=16ms
jini federation    : Loaded 1 resources: 1086012 stmts added in 103.734 secs, rate= 10469, commitLatency=0ms
                   : Loaded 1 resources: 1086012 stmts added in 103.859 secs, rate= 10456, commitLatency=31ms

Results for a variety of serialization/compression approaches for the
various Procedures (IndexWriteProc, JustificationWriteProc, etc), but
NOT for serialization changes to the ResultSet (which is really only
used during inference).  In all cases these results are obtained for
the jini federation since that is the only case where we are forced to
serialize the data in a Procedure or a ResultSet for RPC.

NoCompression.  This serializes each key and value as a full length
byte[].

   Loaded 1 resources: 1086012 stmts added in 107.922 secs, rate= 10062, commitLatency=0ms
   Loaded 1 resources: 1086012 stmts added in 105.531 secs, rate= 10290, commitLatency=16ms

NoCompression, but writing on a DataOutputBuffer and then copying the
results to the output stream (see if this case improves if we reuse
the buffer for each request or using a thread-local variable):

   Loaded 1 resources: 1086012 stmts added in 149.484 secs, rate= 7265, commitLatency=16ms

BTreeCompression.  This uses prefix compression on the keys and simple
serialization of the values.

   Loaded 1 resources: 1086012 stmts added in 103.203 secs, rate= 10523, commitLatency=16ms

FastRDFCompression

   Loaded 1 resources: 1086012 stmts added in 102.109 secs, rate= 10635, commitLatency=16ms
   Loaded 1 resources: 1086012 stmts added in  99.75  secs, rate= 10887, commitLatency=16ms (NIO)
   Loaded 1 resources: 1086012 stmts added in  99.313 secs, rate= 10935, commitLatency=15ms (NIO)

The "FastRDF" approach is probably as good as I can make it for the
statement indices.  It performs only marginally better than the no
compression approach.

Perhaps the additional overhead is a mixture of:

 - de-serialization to support RPC;
 - the mechanisms of RPC (client, server, protocol, network)
 - the added burden on the heap

NIO for the RPC protocol appears to help a bit, but it runs out of
memory in the test suite (this shows up as an NPE in ByteBuffer).


Concurrent load rates:

Explore interaction of the group commit policy.  If we check point vs
commit vs do not wait around then how does that effect the
throughput!!!

Note: smaller buffer sizes (1000 statements) makes the total run much
slower.  Try this with more threads, but we will probably have to wait
on the group commit so that won't help with the current policy.

Note: larger buffer sizes will cap out since there is only so much
data in the LUBM files.

U10

embedded data service:

Finished: #loaded=189 files in 96015 ms, #stmts=1272577, rate=13253.0
(#threads=3, largestPoolSize=3, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 73797 ms, #stmts=1272577, rate=17244.0
(#threads=20, largestPoolSize=20, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 85625 ms, #stmts=1272577, rate=14862.0
(#threads=20, largestPoolSize=20, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 78750 ms, #stmts=1272577, rate=16159.0
(#threads=20, largestPoolSize=20, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 73203 ms, #stmts=1272577, rate=17384.0
(#threads=20, largestPoolSize=20, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

All done: #loaded=189 files in 63172 ms, #stmts=1272577, rate=20144.0
(#threads=20, largestPoolSize=20, bufferCapacity=100000,
autoFlush=false, #done=189, #ok=189, #err=0)

All done: #loaded=189 files in 59734 ms, #stmts=1272577, rate=21304.0
(#threads=20, class=LocalTripleStoreWithEmbeddedDataService,
largestPoolSize=20, bufferCapacity=100000, autoFlush=false, #done=189,
#ok=189, #err=0)

embedded federation:

Finished: #loaded=189 files in 191828 ms, #stmts=1272577, rate=6633.0
(#threads=1, largestPoolSize=1, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 122343 ms, #stmts=1272577, rate=10401.0
(#threads=3, largestPoolSize=3, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 282140 ms, #stmts=1272577, rate=4510.0
(#threads=3, largestPoolSize=3, bufferCapacity=1000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 90860 ms, #stmts=1272577, rate=14005.0
(#threads=10, largestPoolSize=10, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 85735 ms, #stmts=1272577, rate=14843.0
(#threads=20, largestPoolSize=20, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 88453 ms, #stmts=1272577, rate=14387.0
(#threads=20, largestPoolSize=20, bufferCapacity=20000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 87359 ms, #stmts=1272577, rate=14567.0
(#threads=30, largestPoolSize=30, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

All done: #loaded=189 files in 105203 ms, #stmts=1272577, rate=12096.0
(#threads=20, class=ScaleOutTripleStore, largestPoolSize=20,
bufferCapacity=100000, autoFlush=false, #done=189, #ok=189, #err=0)

All done: #loaded=189 files in 106109 ms, #stmts=1272577, rate=11993.0
(#threads=20, class=ScaleOutTripleStore, largestPoolSize=20,
bufferCapacity=100000, autoFlush=false, #done=189, #ok=189, #err=0)

   disk: 1,230,029,630 {osp,spo,terms} + 51,870,457 {ids,pos}

Alternative index allocation: 

   Note: This case appears to be much more efficient in term and
   space, at least for the embedded federation:

   disk: 80,506,107 {terms,spo} + 90,515,091 {ids,pos,osp}

   All done: #loaded=189 files in 88016 ms, #stmts=1272577,
   rate=14458.0 (#threads=20, class=ScaleOutTripleStore,
   largestPoolSize=20, bufferCapacity=100000, autoFlush=false,
   #done=189, #ok=189, #err=0)

jini federation:

Finished: #loaded=189 files in 392078 ms, #stmts=1272578, rate=3245.0
(#threads=20, largestPoolSize=20, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

Finished: #loaded=189 files in 371297 ms, #stmts=1272582, rate=3427.0
(#threads=20, largestPoolSize=20, bufferCapacity=10000, #done=189,
#ok=189, #err=0)

All done: #loaded=189 files in 82328 ms, #stmts=1272577, rate=15457.0
(#threads=20, class=ScaleOutTripleStore, largestPoolSize=20,
bufferCapacity=100000, autoFlush=false, #done=189, #ok=189, #err=0)

    Note: This is an extremely odd result.  It was obtained by running
    immediately after the previous jini federation run.  Overall, jini
    seems very sensitive to initial conditions.  Perhaps this is
    related to memory limits on the laptop platform?  Often the jini
    run appears to be very nearly single threaded.

All done: #loaded=189 files in 241672 ms, #terms=314871,
#stmts=1272577, rate=5265.0 (#threads=20, class=ScaleOutTripleStore,
largestPoolSize=20, bufferCapacity=100000, autoFlush=false, #done=189,
#ok=189, #err=0)

server1: All done: #loaded=190 files in 74049 ms, #terms=314871,
#stmts=1272577, rate=17185.0 (#threads=20, class=ScaleOutTripleStore,
largestPoolSize=20, bufferCapacity=100000, autoFlush=false, #done=190,
#ok=189, #err=1)

server1: All done: #loaded=190 files in 76956 ms, #terms=314871,
#stmts=1272577, rate=16536.0 (#threads=20, class=ScaleOutTripleStore,
largestPoolSize=20, bufferCapacity=100000, autoFlush=false, #done=190,
#ok=189, #err=1)

   disk: 90,926,328 {terms,spo} + 90,926,328 {ids,pos,osp}

server1: All done: #loaded=2008 files in 739904 ms, #terms=3301736,
#stmts=13405383, rate=18117.0 (#threads=20, class=ScaleOutTripleStore,
largestPoolSize=20, bufferCapacity=100000, autoFlush=false,
#done=2008, #ok=2007, #err=1) (U100 is 13M triples)

   disk: 1,110,058,584 {terms,spo} + 1,071,640,537 {ids,pos,osp}

[INFO ][memory ] Memory usage report
[INFO ][memory ] young collections
[INFO ][memory ]     total GC time =         140.096 s
[INFO ][memory ] old collections
[INFO ][memory ]     total GC time =         112.644 s (pause 15.700 s)

server1: #loaded=20022 files in 11419382 ms, #terms=32885169,
#stmts=133573856, rate=11697.0 (#threads=20,
class=ScaleOutTripleStore, largestPoolSize=20, bufferCapacity=100000,
autoFlush=false, #done=20022, #ok=20020, #err=2)

   disk: 14,110,887,061 {terms,spo} + 12,039,810,264 {ids,pos,osp}

[INFO ][memory ] Memory usage report
[INFO ][memory ] young collections
[INFO ][memory ]     total GC time =         1319.038 s
[INFO ][memory ] old collections
[INFO ][memory ]     total GC time =         693.036 s (pause 103.692 s)

server1: All done: #loaded=20022 files in 11633794 ms, #terms=32885169,
#stmts=133573856, rate=11481.0 (#threads=20,
class=ScaleOutTripleStore, largestPoolSize=20, bufferCapacity=100000,
autoFlush=false, #done=20022, #ok=20020, #err=2)

   disk: 14,093,839,353 {terms,spo} + 12,038,914,891 {ids,pos,osp}

[INFO ][memory ] Memory usage report
[INFO ][memory ] young collections
[INFO ][memory ]     total GC time =         1279.318 s
[INFO ][memory ] old collections
[INFO ][memory ]     total GC time =         666.388 s (pause 100.395 s)

============================================================

Notes on store level record checksums and record compression.

1. many record compression schemes will fail if the data are corrupt,
   but logically you compress first and then checksum the record.

   compression is often a technique using a stream of blocks.

   checksum is a streaming technique.

   // IRawStore#write()
   write(ByteBuffer b) : addr

   // AbstractJournal#write()

   if(compress) {

      b = compress(b)

   }

   int chksum;
   if(useChecksum) {

      bytesRequired = b.remaining() + 4;

      chmsum = computeChecksum( b );

   } else bytesRequired = b.remaining();

   bufferStrategy.write(b,chksum,useChecksum)

   Note: buffer strategy write() probably needs to have the checksum
   value pass along in addition to the record to avoid re-allocation
   of the ByteBuffer just to tack on the additional 4 bytes.  We could
   either always write those additional 4 bytes or optionally write
   them if checksums are enabled.

2. the root block needs to hold the critical data indicating whether
   or not checksums in use and what record compression technique, if
   any, to apply.  We need this on hand before we can either read or
   write a record on the store.

3. we need 4 bytes (int32) for the checksum.  this should be at the
   end of the record, so the size in the store is extended by 4 bytes
   and the address for the record on the store is adjusted to also
   include those 4 bytes.  However, when you read from the store it
   will give you a slice WITHOUT those four bytes.  Further, if it is
   using compression then it will decompress the slice, resulting in a
   new slice that can be much larger than the record on the store
   whose size is encoded within the address.  This will probably break
   a variety of asserts that assume that the returned ByteBuffer will
   be exactly the size of the byte count encoded in the address.

4. Compression should run on the byte[] not on the slower ByteBuffer.
   Serialization generally writes on a byte[], but sometimes that is
   wrapped up as a ByteBuffer - and it can even be a slice() onto a
   larger array (NodeSerializer does this since it returns a view onto
   an internal buffer).

    /**
     * The {@link Adler32} checksum. This is an int32 value, even through the
     * {@link Checksum} API returns an int64 (aka long integer) value. The
     * actual checksum is in the lower 32 bit.
     */
    static final int SIZEOF_CHECKSUM = Bytes.SIZEOF_INT;

    /**
     * Offset of the int32 value that is the {@link Adler32} checksum of the
     * serialized node or leaf. The checksum is computed for all bytes exclusing
     * the first 4 bytes, on which the value of the computed checksum is
     * written.
     */
    static final int OFFSET_CHECKSUM = 0;

    /**
     * When <code>true</code>, checksums will be generated for serialized
     * nodes and leaves and verified on read. Checksums provide a check for
     * corrupt media and make the database more robust at the expense of some
     * added cost to compute a validate the checksums.
     * <p>
     * Computing the checksum is ~ 40% of the cost of (de-)serialization.
     * <p>
     * When the backing store is fully buffered (it is entirely in RAM) then
     * checksums are automatically disabled.
     * 
     * @deprecated See {@link #setUseChecksum(boolean)}
     */
    public final boolean getUseChecksum() {return useChecksum;}

============================================================

    - Tune indices

      - The ids index should benefit from value compression since the
        values are the serialized terms.  This will require custom
        code to break the values into symbols and then use huffman
        encoding.  Alternatively, simply treat each value as a symbol
        and code from that (assuming that value reuse is common - if
        not then at least URIs can be broken down into common
        symbols).

	Done. Do not store bnodes in the id:term index.

      - The terms (term:id) index is on the order of 5x larger than
        the ids (id:term) index.  Presumably this is because updates
        are distributed more or less randomly across the terms index
        as new terms become defined but are strictly append only for
        the ids index since new ids are always larger than old ids.
	
         - A larger branching factor may benefit the ids index.

	 - A compacting merge of the terms index should greatly reduce
           its size.

	 - Nearly ALL _read_ time between the SPO and TERMS index is
           reading the TERMS index (99%).

	 - Nearly ALL _write_ time between the SPO and the TERMS index
           is writing the SPO index (99%).  Statements are more likely
           to be distinct than terms, so it makes sense that we write
           on the statement index more often.  However, note that this
           is true even though the TERMS index is 3x larger than the
           SPO index.

    - BTree

     - The RecordCompressor as utilized by the NodeSerializer is NOT
       thread-safe as it relies on a single cbuf field.  Either the
       static buffer pool (if direct buffers are performant for this),
       a heap buffer pool, dynamic heap allocations for
       (de-)compression, or a serialized access to an instance per
       NodeSerializer instance (and hence per BTree instance).

     - Change checksums to be at the store/record level.  Interpret
       the record length as having 2 additional bytes for read/write
       of the checksum.  Put it at the end of the record.
       Enable/disable at the store level.

       Add an option for read-back validation of writes?
       
       Add an option for a fully synchronized raw store interface on
       the Journal?

    - Distributed file repository

         - handle overflow of blocks to the index segments during MOVE

	 - provide streaming socket api on data service for reading
           blocks (low level in the DiskOnlyStrategy - if in the write cache
           then return directly else return buffered input stream reading on
           the disk file and interrupt if journal is closed).

	 - range delete

	 - logical row scan for headers of documents in a key range.

    - (**) Map/Reduce demo jobs.

      - Rework the map/reduce implementation to use local writes and
        distributed gathers.

      - Download, prepare, extract.

      - Concurrent RDF data load as a map/reduce job.

    - Tune network IO

      - huffman encoding is appropriate for network IO, but hu-tucker
        is not required since we have to decompress keys to get them
        inserted into the btree.

      - tokenization needs to be specified for RDF Value types for the
        purposes of compression.  In fact, we are guarenteed that
        values are NOT duplicated in a given batch so tokenization
        needs to uncover common symbols.  This is easy for URIs but
        less so for literals and impossible for BNodes (which do not
        really need to be in the lexicon anyway).

    - Try jini federation using only the terms index to assign
      consistent term identifiers, bulk loading into local SPO-only
      indices, and then range partitioning the indices into global
      SPO, POS, and OSP orders and bulk loading the global statement
      indices.  The data loader should be concurrent and a filter
      should be applied such that each "host" loads only the files
      that hash MOD N to that host.  (note that only AddTerms and
      AddIds go across the network API in this case.)

    - The temp triple store supports concurrent read only but not
      concurrent write, so it is not appropriate for a concurrent bulk
      loader.

    - An extended transaction model can be used for truth maintenance.
      The focus store is built up within isolated indices (that do not
      actually correspond to persistent indices, they only exist on
      the per-tx per-dataservice TemporaryStore).  The application can
      simply combine sets of assertions or retractions within a single
      transaction.  Either the application or an extension of the
      transaction manager MUST serialize the commits.  Within the
      commit processing, first do retractions then do assertions.

      - Provide for transaction local indices.  The index is dropped
        when the tx completes.

      - Provide for registration of a global index within a
        transaction, but the transaction will fail if the index
        already exists when it commits.

      - For full transactions, explore a synchronous overflow variant
        from a managed journal hosting named indices (as isolated by
        the tx) backed by a transient buffer to a managed journal
        backed by a disk buffer that would let us keep full
        concurrency.  The overflow should be a buffer -> disk transfer
        and then the disk file should be allowed to grow without
        bounds (or to the resource limit of the tx).  Asynchronous
        overflow processing for transaction journals would add a layer
        of complexity throughout as the MDI would need to be
        instantiated on a per-tx basis.

	The WriteExecutorService for the transaction would identify
	and support synchronous overflow exactly as it does now for
	unisolated journals.

     - Raw temporary stores such as are used by the index manager must
       be handled differently since (a) there are no indices in use;
       and (b) the use is always single threaded (no write executor
       service).  This case requires a direct buffer to disk transfer,
       but the API can be declare an assumption that the caller is
       single threaded and the writer can simply block during that
       transfer.

     * Some of the buffer strategy implementations appear to assume
       that by synchronizing one method, such as truncate() or
       transferTo(), that concurrent writers are automatically
       synchronized for those operations.  This is NOT true unless the
       write() method is also synchronized, and it is not for at least
       the DirectBufferStrategy.  This could show up as a concurrency
       problem with the indices when the store is used in a mode that
       is in fact concurrent and an overflow is triggered.

Short term tasks:

   - (*) Builds and releases.
   
      - Change over to subversion so that the edit trail does not get
        lost (complex process).

      - add alternative license.

      - Maven 2.x build
      
         - Start doing snapshot releases.

	 - Start periodic project documentation builds, perhaps on SF.
           Publish on the www.bigdata.com site.

         - Change the dependency to dsiutils.  I tried to do this with
           dsiutils-1.0.4 and ran into problems with
           (de-)serialization when compared to the lgpl-utils versions
           of the same classes.  Try this again and pay close
           attention to the lgpl-utils versions of the classes now
           located in dsiutils and see if I can isolated the problem.
           The problem was demonstrated by the bigdata-rdf test suites
           for both the temp and local triple stores but not for the
           bigdata test suites.

	 - Done. Update the Sesame 2.x dependency.

	 - Put all properties into the com.bigdata namespace.

   - Counters

     - Done. Work the counter path, name, and date(s) into the table
       which shows the counters history values so that it can all get
       copied easily into a worksheet.

     - Done. #commit is not being encoded property and shows up as a
       URL anchor and not as part of the PATH parameter.

     - Done. Counter XML MUST persist the HISTORY in the XML so that
       the log files can be useful for post-mortem.
       
     - Done. Write a final log file ('-final.xml') when the LBS
       terminates.

     - Done. This is now a configuration property.  The load balancer
       is not writing its counters into the correct location (logDir).
       The directory needs to be relative to the service directory, so
       a method needs to expose that directory to the service.

     - Done. (Not quite sure what the problem was here, but I made a
       few changes and it appears to be fixed.)  The concurrent data
       loader was failing to halt once it started the flush tasks.

     - Done.  (Modified to accept samples out of timestamp order and
       to record the #of and total of samples falling within a given
       period.)  Loosing some samples through reporting w/in the same
       period.  Round up to the next period if this period is filled.
       An alternative is to sum the samples in the period and report
       their average by also tracking the #of samples in the period!

     - Done. When writing the path in the table rows, only write the
       path from the selected root.

     - Done. Problem with double-decoding of URL in NanoHTTP.

     - Done. (Can be a bit odd when also using a regex filter.) Add
       depth query parameter to limit the #of levels resolved from the
       path.

     - Done. (Currently using engineering notation, should be query
       parameter).  Set to 6 digits precision, not {3,6} after the
       decimal.  Or right justify decimal value with fixed N digits
       after the decimal (could be query param).

     - Done. (Also added the timestamp itself.) When converting to
       minutes, hours, and days in httpd make sure to have a few
       digits after the decimal -- otherwise false boundaries.

     - Done. (uses wildcards before and after and ORs together.) The
       filter needs to accept regex characters or prefix and post-fix
       with ".*".  Since things are quoted, right now nothing is
       actually matched.

     - Done. Since the log files provide post-mortem, there should be
       a way to view the files through the same httpd tool - a mode
       where it reads a single named counter XML file and then lets
       you browse it.  This will make it easy to find interesting
       views.

     - Done. The IndexManager should report the #of index views open
       concurrently.  Either sample once per second and take a moving
       average track the total number and compute the instanteous
       average per minute.
 
     - Done (reports the #of stores in the weak value
       cache). Likewise, the StoreManager should report the #of open
       journals and index segments.

     - Done. Anything with "%" or "percent" in the name should be
       formatted as a percentage in [0.00:1.00].

     - Done.  The data service should report its configuration
       properties under "Info".

       Done. This should be done for the other services as well.
       Refactor the code in DataService, moving it into the counters
       package.

       Note: Servers should add their Jini configuration information
       as well.  This probably has to be done explicitly for the
       configuration items of interest.

     - Done. Compute average response time.  Throughput is 1/average
       response time.

     - Done. Add counters for #of index partition split, move, and
       join operations (OverflowManager).

       Done. Also report #of errors during asynchronous overflow
       processing.

       Note: There should also be a counter of the #of index
       partitions moved onto a data service.  However there is no
       place in the code to easily note this on the target data
       service since the move is made atomic by an action on the
       metadata service.

     - Done. Add counter to the write service that reports the #of
       tasks which have their locks and are actually doing their work
       concurrently (LockManager defines such a counter but we need
       its moving average not the instantaneous value).  This is the
       real concurrency of the tasks.  The #of active tasks in the
       write service is a red herring since those tasks could be
       waiting for their locks.

     - Done. Add per-process counters for GarbageCollectorMXBeans.

     - Done. (NanoHTTPD was not reporting errors in the serve() method
       anywhere and was failing to send back an error to the client.)
       For some reason a query for the hostname on host3 does not
       return the counters in the browser.  Response is fast both
       beneath that level at at the root.  Maybe the problem is in the
       /host/CPU and /host/Info counter sets - those appear to hang
       while /host/service is fine.... that does not seem to pay out
       either.

     - Done.  (I am assuming that Format was not thread safe - it was
       being used concurrently by the Sar collector and the pidstat
       collector, even with only one service). pidstat : Problem
       parsing [02:08:24 PM] as a time for input string "".  This is
       odd.  I can test this out and it works for the specified
       format.  And it is the only error reported for pidstat parsing.
       Ah.  Format is doubtless not thread-safe.

     - Done. Fixed issue where sar and pidstat would overflow the
       field, eating into whitespace to the right.  The data lines are
       now split based on whitespace after first skipping over a date
       field (based on the ISO date format).

     - Done. The per-process counters for linux are not being reported
       under "service" but instead directly under the service UUID.

     - Done. Group services under their service type in the counters.

     - Done (also fixed a bug where the LDS was not sending a join
       message to the LBS and modified notify(), warn(), and urgent()
       to invoke join() on the behalf of remote clients). The LBS
       should add counters for the host scores.  This will provide
       transparency in how it interprets the data from the various
       hosts.

     - Done. The client can discover the LBS and report data every so
       often.  This would result in redundent reporting when there is
       more than one client if the counter reflects the database
       state, but there is no harm in that.

     - Done. Could report the #of files read, #of triples processed,
       triples in the db, average throughput rate for that client (or
       all clients), etc

       - (**??) tps appears low as reported by the client to the LBS
         when compared to the final value computed by the client.
         This may be a function of the outstanding writers that have
         not yet completed, in which case the loader clearly needs to
         force the report of the final counter values when a load
         completes.

         Maybe this is reporting the upper bound for statements?  That
         does not make sense though since only deleted entries or
         views with an index segment cause the upper bound to be
         higher than the actual entey count.

       - Compute bytes per statement in the db (requires a db op to
         correlate the journal size with the #of stmts or #of terms)

       - Done. report success and errors from the concurrent data
         loader.

       - Done. incremental evaulate futures for the concurrent data
         loader.

     - Done. Report response time measures on the client, which will
       require a class similar to TaskCounters that is intimate with
       the ClientIndexView.  That will give a client perspective on
       the latency of tasks, which will aggregate across the data
       services that it uses and include the costs of RMI, in contrast
       to a data service perspective, which aggregates across the
       clients using that service and discount RMI.

       Note: The LDS does not use RMI - it submits tasks directly to
       the data service queues.

     - Done. Need to aggregate statistics for the partitions of an
       index as reported to the LBS for analytics.

     - Need to remove index partitions which are known to be stale
       from the LBS after a bit, or at least allow them to be hidden.
       The data will eventually grow beyond what can be held by an LDS
       if we do nothing.

     - Done. Show metadata about the open index segments in the
       IndexManager

     - Done. Send stale locator notices to the LBS and replace the
       counters (or nest them under) on the LBS when the index
       partition is reported as stale.

       Done. Note: having a local httpd for the data service would
       make it much easier to inspect the indices.
    
     - (**) The IndexManager should report the #of open indices.  We
       can have an exact count of that if we use a static atomic
       integer in AbstractBTree.
       
       Likewise, we can get the exact count of the #of open journals
       vs index segment stores and BTree vs IndexSegments using the
       same technique.

       Done. The statistics that are used by the overflow manager to
       compute which indices are move candidates are not being exposed
       via the counters to the LBS.  This includes all of the
       per-index bytes read, bytes written, etc. data.

     - Done. The IndexManager should report the index partitions on the
       data service, at least until this exceeds 100s of indices.
       This should be done not via counters but rather via the httpd
       service itself making an RMI request to the data service and
       listing out the named indices. Present additional information
       when the service is a metadata service, e.g., by listing out
       the tuples of the index, which are in fact the locators for the
       index partitions.  Also, provide some aggregation over the MDI,
       including the total #of partitions and tuples.

     - The counters are overflowing to days before midnight.  Check
       the locale and see when timestamp causes an overflow to the
       next hour and the next day in some unit tests.

     - Done. When restoring the LBS counters from XML, the history on
       the counters is being ignored.

     - (****) Make it possible to have more than 60 minutes in the
       buffer but still overflow after 60 minutes onto the hours.
       This will allow a longer reachback at a given level of
       aggregation.

     - Add UI elements to set the filter(s), depth, decimalFormat,
       etc.  These should be a FORM with a GET action.

     - May be loosing some samples by running multiple typeperf's at
       once.  Explore.  If true, then trying combining all w/in same
       JVM using reference counter for process or identifying one
       process in the JVM which will have responsibility for those
       counters.

     - syslogd integration so that I see ERROR and FATAL messages for
       the hosts in the federation.

     - Done. Add option to NOT run typeperf and use for the unit tests
       of the services when performance counters are not required.

     - Done. Add reporting by the client on the indices that it is
       using.

     - Done. Add reporting to the concurrent data loader for #errors.

     - Done. The CDL tps counter needs to stop counter time once the
       load is complete.  As it is the rate continues to drop with
       elapsed non-load time.  This makes the value reported to the
       load balancer wrong! (Even the value available from the client
       is wrong since it can be off by up to 60 seconds of load time).

     - Done. Problem w/ correlated view of counters. Was plotting a
       String[] rather than its elements.


     - Add counters to the client index view showing the times for
       each operation and also showing the times for querying the
       metadata index to split an key[] operation or map a key-range
       operation.  This will be help identify if/when the MDI is a
       bottleneck for the client.

   - Admin UI
   
     - It would be nice to be able to drill down into the index data,
       but that should be an admin UI not the counters UI.

     - Expose the known triple stores, a view on the global sparse row
       store, etc.

     - Offer commands to force overflow of a data service.

   - Sparse row store support.

     - JSON API

       - Add a web application that let's people easily write on or
         read from the sparse row store using JSON or the like.

       - The JSON API should be compatible to the extent possible with
         HBASE and GAE.

       - This web application will have to be distributed in order to
         eliminate bottlenecks.  One approach is to re-direct HTTP
         clients to an embedded web service co-located with the data
         service on which the row resides.  HTTP clients can continue
         to address that server until they receive a redirect.

     - Add a BLOB reference column type.  There are at least two
       design options for this.  I think that we should support at
       least (1) and (2).

       (1) the blocks are stored locally and hence are always
           available from the same data service as the BLOB reference
           column value - this might limit the maximum effective blob
           size (in bytes) since the data will have to fit in the same
           index partition and hence be co-located on a single host.
           In fact, the blocks will be in the same index segment as
           the column value once the journal overflows.  One advantage
           of this approach is the block updates can be atomic with
           block metadata updates - a feature that is not otherwise
           available without full transactions.
       
       (2) the blob reference includes the name of the scale-out index
           on which the blocks for that blob are stored - in this
           model the blocks can reside anywhere and splits of the
           blocks will have no relevance to splits of the metadata.
           This also makes it easier to locate the partitions of the
           index containing the blocks on data services that are
           specifically provisioned for large data blocks.

       (3) the blob reference contains the primary key for the blob
           and the blob is stored either in the same index or in
           another index.  I am not sure that this variant adds value
           over (1) and (2).

     - Refactor the BigdataRepository to use the BLOB reference type.

   - IndexSegment

     - Done. Verify that there is an atomic commit point for the
       IndexSegment so that partial index segment writes can be
       recognized.

     - Done. The addrLeaves and addrNodes can not be expressed as a
       single long since they are regions spanning many records and a
       long would limit their byteCount to whatever was allowed by the
       offsetBits.

     - Done. The logic to buffer the nodes was actually examining the
       extent of the leaves.

     - Done. Added checksum to the index segment store checkpoint
       record.

     - Done (the problem was failing to flush the write cache to the
       disk before initiating the channel to channel transfer - since
       the data were not on the channel they naturally were not being
       transferred.)  Stress test of U100 and very large runs of
       TestIndexSegmentBuilderWithLargeTrees (m=32, nentries=m**4)
       cause corrupt leaves in an index segment build.

     - Done. Modify IndexSegmentBuilder to support fast reverse scan,
       at least in the data and in DumpIndexStore.

     - Done. IndexSegmentBuilder should be refactored to implement
       Runnable/Callable.  The ctor can do the setup and the index
       build will run in run()/call().  The return can be a status code
       for the operation or statistics on the operation.  Throw an
       exception for an error.

     - Done. Modify IndexSegmentBuilder to support fast forward scan,
       at least in the data and in DumpIndexStore.

     - An index segment build that could operate without the actual #of
       entries would avoid one pass over the data.  See how expensive
       that traversal is (it is done in one location) and decide
       whether it is worth trying to operate without that information
       on hand.  Eg, by using the upper bound on the entry count and
       then allowing leaves and nodes to underflow.

     - Done. Support transparent byte[] <=> value (de-)serialization
       using a serializer object associated with the index metadata.

     - Done. Add Map and Set impls. based on the BTree.

     - Done (IUpdateStore). I need to create an interface extending
       IRawStore, put those methods on that interface, and then declare
       that interface on TemporaryRawStore in order to be able to
       access these methods.

   - DiskOnlyStrategy

     - Done. write tests of transferTo.  I did find a bug in
       writeAll(), but that was not the problem (it was writing each
       pass at the same offset in the file when a write required
       multiple IOs).

     - Done. Refactor to create a Journal using a Temporary BufferMode.

     - Done. Refactor DiskOnlyStrategy to permit lazy creation of the
       backing file.

     - Done. Refactor of TemporaryRawStore to use DiskOnlyStrategy with
       lazy creation of the backing file.

     - Done. Found a bug in DiskOnlyStrategy where it was always
       reading a record three times....  Probably there was little
       performance impact since the read would have come from the OS
       cache after the first time, but still....

     - Evaluate effect of the write cache capacity.  If 1M is as good
       as 10M then just use the DirectBufferPool for the write cache
       for the live journal, which will simplify some things.

     * Add counters reporting the #of bytes written/commit.

     * Test suite for Temporary mode journals.

   - DirectBufferPool

     - Done. Static config via System#getProperties() for the direct buffer pool

     - Done. Counters for reporting out the pool state.

     - Done. Report "bytesUsed" for the DirectBufferPool.

   - Transaction support.

     - Overhaul transaction processing and support full, 2-/3- phase
       transactions

     - A problem is reported by StressTestConcurrentTx.  Revisit this
       when I overhaul the full transaction support.

     - Transaction identifiers need to be "symbols" that respect the
       timestamp ordering for historical reads and the transaction
       start time.  Since the timestamps are discrete it is possible
       that the factory will have to wait until it can assign a
       transaction identifier for the interval implied by some desired
       historical start time.

     - ** Change tx timestamps to negative and use positive timestamps
       for historical reads.  Changes to AbstractTask, ITx,
       ITransactionManager, StoreFileManager, IsolationEnum, and the
       post-processing tasks.  This will greatly simplify thinking
       about historical read operations since they will simply use the
       actual commit time while transactions will use a free
       (-timestamp) value selected by the transaction manager.

     - AbstractResourceManagerTask - documents a potential problem
       with MDI updates without 2-phase commits.  Look into this
       further and see if this problem can be addressed without using
       a full transaction.  If not, then we will need to use a full
       transaction to avoid this issue.

  - (*****) Iterator refactor

     - Cursor based tuple:

       - BTree (uses listeners to support concurrent modification).

       - IndexSegment (uses prior/next leaf and data are immutable).

       - FusedView

     - Modify the procedure logic to abstract a 'next key/val'
       iterator using a shared buffer for de-compression in order to
       minimize heap churn on the data server.

     - **** Modify IndexSegment to use fast forward and fast reverse
	    scans.  I need to override or replace the iterator to do
	    this.  It should use a priorLeaf/nextLeaf method in order
	    for this to be easy to do.

	    Ah. There is a protected [AbstractBTree#leafIterator()]
	    method, but it is not being used.  Perhaps this could be
	    modified to accept a fromKey and toKey and then used to
	    allow replacement of the striterator-based
	    postOrderNodeIterator().

	    Modify the iterator to support prior/next and modification
	    with concurrent traversal.  This really should not be any
	    more complicated than the case for the GOM link set
	    iterator.

     - **** I have seen the index segment store closed during iterator
	    traversal.  I've modified the class slightly to re-open the
	    store transparently and we will see how that goes.

	    *** The observed problem was during iterator traversal.  I
	    suspect that iterator traversal should not allow the index
	    to be closed since it requires valid hard references to the
	    stack of nodes being traversed.  Figure out who is closing
	    the index.  We may have to ignore the close if there is an
	    open iterator.

	    If the iterator is modified to use prior/next leaf methods
	    for traversal and those methods are robust, then they can
	    simply reopen() the index if it has been asynchronously
	    closed.  The version for the index segment will not need
	    the node stack.  A version that does not rely on a node
	    stack could also be written for the BTree using lookup() to
	    re-discover the current leaf and tuple.

	    * Consider modifying the leaf iterator to require calling
	      next() for the first leaf.  Consider changing next() to
	      nextLeafInScanOrder().

     - Support copy in/out of keys and vals in lookup(), insert(),
       remove(), and rangeIterator so that we can (a) be more
       efficient in handling keys and vals by copying; (b) handle keys
       and vals that are byte aligned or bit aligned in the node or
       leaf; (c) reduce GC by converting to a compacting record for
       the node/leaf; and (d) expose the version counter and deletion
       marker for fused views of indices with isolation.

     - Turn off sendVals for rangeIterators if we recognize the value
       serialized as the NoDataSerializer?

     - (***) The distinct term scan (really, the prefix scan) needs to
       be optimized for the data service and the federation use cases.
       This also effects the sparse row store.  Also, the sparse row
       store needs to use an extended split handler that always
       chooses a split point which is on a logical row boundary.

     - (*) Need ability to request a rangeIterator that reads in
       reverse key order and the ability to visit the prior or next
       key.  This requirement arises in particular for the bigdata
       repository which is currently using the ILinearList API for the
       AtomicAppend.  This will also help us to replace the
       requirement for the ILinearList API in the metadata index.
       
       The change needs to occur at several levels and should include
       a prior() method on ITupleIterator and the ability to acquire
       an ITupleIterator for ITuple returned from lookup(), insert(),
       etc. so that it can be turned into an iterator for prior/next
       visitation.

       This is a good time to do efficient prior/next leaf operations
       for the IndexSegment and to make that more efficient for the
       BTree as well.

     * There are some heavy costs for the tuple iterator for the
       distributed mode because it is sending around more data than is
       strictly required.

     - (*****) The consistentRead option used by the
       PartitionedIndexRangeIterator needs to use the most recent
       commit time for the federation.

       Currently it uses the lastCommitTime for the first index
       partition which it scans.  However, it is quite possible that
       there have been writes on other index partitions since which
       would not be reflected in BTree#lastCommitTime.  The
       consistentRead would therefore reflect an older history rather
       than the most recent writes when it moved onto the other index
       partitions.

       In order to fix this the data services MUST discover and use a
       centralized timeservice.  This can be essentially a stripped
       down centralized transaction manager.  The data services will
       obtain their commitTime timestamps from this centralized time
       service and MUST also notify the centralized timeservice once
       they have successfully committed.  The PartitionedRangeIterator
       will then query the centralized time service for the last
       commit time for the federation as a whole and use that as the
       time for a consistentRead operation.

       As an alternative, the data services could periodically publish
       their commit times.  I need to see how much of a bottleneck it
       is for clients calling nextTimestamp().

   - LocalTripleStoreWithEmbeddedDataService

     - Benchmark with owl:sameAs backchainer.

     - (*****) Optimized JOIN that assumes that all indices are local
       within the data service and reads locally on both access paths.
       This would probably be implemented as a AbstractTask and it
       would need to declare access to the indices being used for the
       left and right hand sides of the join.

     - test small and large document sets with and without incremental
       closure:

       -server -Xmx500m -DtestClass=com.bigdata.rdf.store.TestLocalTripleStore -Ddocuments.directory=../rdf-data/metrics/smallDocuments -Ddocuments.ontology=../rdf-data/metrics/metricsOntology_v1.9.rdfs -Dfile=C:/smallDocuments.jnl -DdataLoader.commit=None -DdataLoader.closure=None

   - ScaleOutTripleStore

     - ConcurrentDataLoader

       - ? stagger the entrance of the first few tasks to help stagger
         the nature of the their work.

       - retry long running tasks (map/reduce style).  In fact, this
         already happens because the ClientIndexView times out the
         request to the data service which results in a
         CancelledException and the task is marked as an error and
         then retried.

       - More cleanup.

       - Reconcile with m/r architecture and bigdata repo.

     - (*****) Optimized JOIN for the scale-out triple store.  It
       needs to block up a set of right hand tuples that will be
       joined against data on a given data service and then send those
       tuples to that data service, recieving the results in
       return. It will also have to handle stale locators if the join
       is running in an read-committed mode, but not if it is
       transactional or a historical read.

       Inference is slow due to a large #of small join results.
       Parallel sub-query is probably the way to beat that.  After
       tuning, compare to the purely local unconcurrent line.

       Consider batching a set of rangeQueries together in a single
       operation vs parallel submits.

     - Done. (get() and find() were running as unisolated tasks.)  I
       am seeing a lot of tasks in the concurrency manager for the
       metadata service, but few commits on the live journal.  What
       the heck is the being reported for the metadata service?

   - OverflowManager

      - Could optionally convert from  a fully-buffered to a disk-only
        store  in  order to  reduce  the  memory  footprint for  fully
        buffered  stores,  but in  that  case  this conversion  should
        happen once asynchronous overflow handling was complete.

   - StoreManager / IndexManager

      - Done. Add counter for bytes under management on the
        StoreManager.  I want to see bytes placed under management,
        bytes for stores that have been deleted, and bytes for stores
        that are remaining.  It would also be great to see the bytes
        remaining on the volume where the data are stored in the same
        view.

      - Modify  LRU  to  purge  entries  older than  a  specified  age
        (including an asych  daemon thread to make sure  that they get
        purged even if the LRU is not being touched).  Do this for the
        index segment cache in the IndexManager as well.

      - (*) Better concurrency for openIndex, openStore, getJournal,
        and getIndexOnStore

      - Modify WeakValueCache to use ConcurrentHashMap and support an
        atomic putIfAbsent operation.  This will reduce the latency
        imposed when we need to re-open an index segment from a store.

      - Should recognize a "disk full" situation and shutdown the data
        service cleanly.

   - LockManager

       - Use a WeakValueCache to purge unused resources.  The size of
         its internal map from resource name to resource queue will
         grow without bound on a data service as index partitions are
         split and moved around.  There are notes on this issue in the
         LockManager class.

   - DiskOnlyStrategy
   
     - Done. Lazy creation of the backing file.

     - Done (No performance change for small stores - I still need to
       review the data for large stores.  Of interest, the write cache
       on a large store is nearly never a hit when trying to read a
       record - this suggests that a read cache will be of no
       benefit).  An LRU read cache for records.

       This could be a big win for the DiskOnlyStrategy.  Either make
       this its own layer that can be interposed between the journal
       and the DiskOnlyStrategy or add directly to the
       DiskOnlyStrategy since a read cache is not required for the
       fully buffered modes. Regardless, allow configuration of the
       cache size.

       Also, efficient nextLeaf could improve read performance by
       reducing node reads.

       Write through to the write cache and flush through to the disk.
       On read, test the read cache.  If not found, read the write
       cache, then the disk.  These are simple layering semantics.

       Use an LRU with a capacity of ~5k records.  The records are
       read-only so we do not need to worry about a canonicalizing
       mapping.

       The read cache is specific to a journal.  Each journal gets its
       own read cache.  Historical journals might have a smaller read
       cache capacity, or maybe 2k records is enough for any journal.
       Experiment and find out.

       (***) Look at the effect [host3] on readSecs, on the ratio of
       readSecs to writeSecs, and on IOWait, especially as the size of
       the journal grows.  If the LRU is not paying its way then
       disable it by default.

     - CounterSets

       - Add counters designed to give insight into whether the write
         cache tends to full up completely or only partly before the
         next group command and the #of bytes that tend to be written.
         What I want to understand is whether the cache is too large
         and whether an asynchronous of the cache to the disk would be
         a benefit.

	 *** #bytes/commit (measured delta in offset from commit to
              commit).

	      Also, #flushes / commit - when ~ 1:1 the write cache is
	      at least large enough.

	 Note that writes which would exceed the remaining cache size
         cause the existing cache to be flushed while writes that
         exceed the cache capacity are written directly to the disk -
         the cache itself is always dense in terms of the bytes
         written on the address space.

   - Done. Full text indexing for KB.

       - Done. Analyzers are not thread-safe.

       - Try out an mg4j integration for an alternative text indexer
         and search.

   - Consider thread pool size defaults, especially for the Temporary
     Journal mode.  What is a good policy?

   - Done.  Either never retry an error task when the queue is likely
     to be full or make the retry itself robust.  Otherwise the CDL
     risks reporting fatal error for a task which could have been run
     successfully.

   - Done (uses a static pool). Provide option to pass in a write
     cache buffer for a temporary store and use that buffer as the
     in-memory store before it overflows onto the disk.

   - *** Batch API for extractor, allowing runs directly against the
         KB.  Form a single prefix-scan query from a sort of all
         simple terms in the document and then piece together the
         phrases from the result.

   - Consider dropping the BasicRioLoader, PresortRioLoader, etc.  All
     of the benefit is in the use of the StatementBuffer.  These
     loaders just obscure the RIO mechanism and make them harder to
     configure.

     The DataLoader might be a utility class.

     The ConcurrentDataLoader is certainly a useful utility class.

   - Quad store.

    - ** Sesame 2 TCK (integration tests)

         (temp fix) You should add the following URL as a maven
	 repository to your maven settings.xml file:

	    http://repo.aduna-software.org/maven2/releases/

    - ***** Two database modes: named-graph mode (quads with all 6
      indices) and provenance mode (3+1 where the context position
      holding a bnode with a 1:1 relationship to the triple and
      therefore serving as a statement identifier and is stored as the
      value associated to the triple in the index; The source
      extension for RDF/XML needs to be supported such that the given
      BNode or URI for the source is correlated to the use of that
      same Resource elsewhere in the same RDF/XML document - we need
      to extend RIO for this).

      1. 3+1

	 - Done. value serializer must be different when using sids

	 - Note: any partition of the term:id index may be used to
           assign term identifiers for bnodes since the bnode ID is
           only required to be distinct, but not stable.

	 - Done. TMStatementBuffer needs to recursively wipe out
           statements using a statement identifier.  this should be
           part of truth maintenance.  when we get the original set of
           explicit statements to be removed we collect their
           statement identifiers and then collect all statements using
           those statement identifiers in either the subject or object
           position and add them to the original set of statements to
           be removed.

	   Done. AccessPath#removeAll() we also need to collect the
	   set of statements using a statement identifier and delete
	   them as well.  this will wind up being a double test for
	   the original set of statements if TM is being used, but it
	   is required when TM is not in use.

	   Done. Do not generate statement identifiers if the SPO is
	   marked as an inference (an optimization).
	   
	   Done. Modify the procedure that actually writes on the
	   statement index to write a ZERO (0L) statement identifier
	   if the statement is (in fact at the time that we examine
	   the statement index) an inference or an axiom.  If an
	   explicit statement is later asserted for the same SPO, then
	   we need to overwrite that 0L with the assigned statement
	   identifier.

	   Done. override ISPOIterator#close() when returning an
	   iterator backed by a temporary store.

	   Done. infinite loop test case fails when sids NOT used. I'm
	   not sure how the test was succeeding before, but the
	   problem was failing to verify that a statement was in the
	   database before adding it to the focusStore.

	   Done. TestTripleStore#removeStatements() has problem with
	   sids.  The problem is that the sid is not getting placed
	   onto the SPO by the unit test, but it highlights the fact
	   that with sids you need to either have the SID on hand
	   before calling removeStatements() or I need to modify the
	   code to resolve the sids as a first step when I compute
	   their fixed point (at which point I could also discard any
	   statements that were not actually in the database).
	   (addStatements already resolves sids so as to always make
	   them consistent).

	   Done. write unit tests for TM cases when using statement
	   identifiers to make metadata statements.

	 - Work through an import scenario from an application that is
           using URIs generated from the {s,p,o} to represent the
           statement identifier.

	 - Survey all of the ways in which reportStatement/3 gets
           called in RDFXMLParser and decide whether or not "context"
           (the variable set based on bigdata:sid) is always correct
           (either "" or the sid) or if there are some uses, such as
           reification, where "context" should be ignored and update
           the calls to reportStatement/3 or reportStatement/4 as
           appropriate.
      
      2. Done. RDF/XML w/ statement identifiers in/out.

         - Reduce to only an "explicit" flag rather than {explicit,
           axiom, inferred} since we can not differentiate between
           constructed statements and inferences.

      3. High level query for reading variable bindings out.

	 - Done. Verify a CONSTRUCT query.

	 - Done. Verify a SELECT query using statement identifiers.

      4. (****) JOIN optimization.

	 - (*) direct term scan.

	 - Map the first triple pattern over its index, and for each
           mapped key-range of the index collect intermediate results
           and map them over the next index.  This must use
           read-historical or read-committed access to avoid locking
           up the unisolated index, but that's going to be automatic
           since the join operator itself does not write on an index.
           the buffer in which we accumulate the join results needs to
           write somewhere, and the choices either back to the client,
           onto the focusStore, or onto the database.  All of those
           can be handled since the read-only procedure will be either
           returning a result or submitting a write procedure.  A join
           variable buffer should accumulate those results and then
           write only the selected variables into any of the
           appropriate locations on overflow (via subclassing or a
           ctor parameter for the writer).

	 - Any SPARQL query which can be directly mapped onto a series
           of JOINS can be directly translated into a rule and run by
           the existing rule engine.  If it has filters that need to
           be applied then they should be handled by a filter applied
           to the buffered join results.  That filter can even handle
	   batch filtering by inspection of datatyped literals.

	 - A further optimization is possible for the local data
           service since all indices are known to be local and the
           index lookups do not need to be batched since they will
           always be continuous unbuffered local reads.

	 - ***** Replace Sesame 2 JOINs by re-writes into our rule
                 engine.
      
      6. Publish on statement level provenance and truth maintenance
         for SPARQL end points.

      7. Defer "named-graph" style quad store for now.

      8. (***) implement prefix compression and apply to the lexicon.
         test it out also on the statement indices and see how it
         stacks up against the "fast rdf key" compression and compare
         with huffman encoding of the decoded long identifiers as
         well.

	 See it.unimi.dsi.fastutil.bytes#ByteArrayFrontCodedList.

	 Note: We should use front compression by default for the
	 nodes of the BTree.  Since the separator keys in the nodes
	 are dynamically determined prefixes, application specified
	 compression generally can't be used.

   - Done.  Correctness testing for scale-out with index partition
     split, move, and join.  See services/StressTestConcurrent. It can
     be parameterized for this purpose.

   - streaming io for block read/write.

     - Asynch IO for the disk only strategy will not have an impact if
       we are doing commits whose size fits within a single write
       cache (10M by default).

     - Use a pool of direct buffers (the same pool that is used for
       the TemporaryRawStore) for the data service and handle all
       block io/out requests with that pool.  this will help about OOM
       problems with "temporary" direct byte buffers.

     - It is possible that we will need to use the TemporaryRawStore
       static buffer pool for all reads from the store (or writes that
       are not via a write cache backed by a direct buffer) since
       otherwise Java could allocate for us, and then fail to
       correctly release, a "temporary" direct buffer. This would
       impose ReentrantLock on all reads....

   - write performance test drivers and run on cluster.

      - rdf concurrent query (rdf lubm is not designed to test with
        concurrent loads).

      - bigdata file system workload (must provide reverse traversal
        iterator to handle atomic append for the key-range partitioned
        indices).

      - (****) Write script to allocate services to nodes.

        - N data services; 1 MDS; 1 LBS; 1 TS, etc.

	- The script needs to start the services on a LOCAL disk on
          each machine (I am currently setup on NAS so that means the
          DISK is REMOTE).  This means replicating the environment
          onto the local host (at least the configuration) and then
          starting the service.  The classpath could be resolved on
          NAS or replicated onto the local host and resolve there. (I
          just need to copy [policy.all,
          bigdata-rdf/src/resources/logging/log4j.properties, and
          bigdata-rdf/src/resources/config/standalone ->
          .../src/resources/config/standalone {create the directory
          path first}].  I could also copy the classpath resources,
          but presumably they will be fetched quickly enough and
          become stable - or maybe not?

	- Need to touch up launch-all after the jini install as well
          as installing from a pre-touched version fixing the
          LD_ASSUME_KERNEL_VERSION bug.

	- (***) Get clusterondemand account.

	- Support downloadable code in the configuration, including a
          an optional security model.

        - Make sure that yum-updatesd does not run on the servers.  It
          absorbs an entire CPU for quite a while.

      - (*******) rdf concurrent data load.

	- Still an annoying problem with the service names as
          displayed by the jini browser....  This may well be an issue
          with failing to expose the interfaces and service classes
          via an http service as downloadable code.
 
============================================================

	Looks like virtuoso is running a clustered triple store!

	http://virtuoso.openlinksw.com/wiki/main/Main/VOSArticleLUBMBenchmark

	http://www.openlinksw.com/weblog/oerling/?id=1336

	http://www.openlinksw.com/weblog/oerling/?id=1335

	http://docs.openlinksw.com/virtuoso/clusterprogrammingsqlexmod.html

============================================================

    - Done. (There was a fence post when the releaseTime was less than
      the first commit time for any journal.) Saw "no data for release
      time" error.  Twice.  This will prevent overflow from succeeding
      since it occurs during synchronous overflow.  I have changed the
      configuration for the data services to set [minReleaseAge = 0],
      which is probably more appropriate for this test, but this needs
      to be debugged.

    - Done. Get the basic overflow tests running.

    - Done. ClientIndexView : retry count exceeded - need to report
      the underlying cause(s)

    - Done. (Added more detailed warnings and made robust to such
      failures) Fence post for DefaultSplitHandler (#ntuples == 0)

    - Done (DataService needed to notify() the LBS during startup).
      Jini client is not reporting counters on either machine.  The
      problem is the client configuration.

    - Done. Dynamically refresh the httpd view for the data service to
      make the counter set for the index manager live.

	Done. Modify to report the counters retained by the
	concurrency manager as they are longer lived.

	Done. Report partition metadata for the view, including the
	checkpoints for the index segments.

	Done. Report stale locators.

	*** I am not seeing StaleLocatorExceptions for read-committed
            views, at least not in the counter set generated by the
            concurrency manager.  Part of the problem is that the fast
            overflow rate is making the views update very quickly.

============================================================

**** The group commit behavior when interrupted during shutdown needs
     to be reviewed with respect to the recent changes to AbstractTask
     and Name2Addr.

ERROR: 397768 pool-1-thread-559   commitCounter=397 com.bigdata.resources.SplitIndexPartitionTask$AtomicUpdateSplitIndexPartitionTask [test_POS#18, test_POS#40, test_POS#41] 0 waitingOnCommit  com.bigdata.journal.WriteExecutorService.groupCommit(WriteExecutorService.java:1102): Problem with commit? : java.lang.InterruptedException
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:1878)
	at com.bigdata.journal.WriteExecutorService.waitForRunningTasks(WriteExecutorService.java:1230)
	at com.bigdata.journal.WriteExecutorService.groupCommit(WriteExecutorService.java:1024)
	at com.bigdata.journal.WriteExecutorService.afterTask(WriteExecutorService.java:655)
	at com.bigdata.journal.AbstractTask.doUnisolatedReadWriteTask(AbstractTask.java:1638)
	at com.bigdata.journal.AbstractTask.call2(AbstractTask.java:1546)
	at com.bigdata.journal.AbstractTask.call(AbstractTask.java:1437)


============================================================

This indicates passing an old locator that could not be found in the
MDI.  I've modified the code to report back the old locator in the
exception.

Caused by: java.util.concurrent.ExecutionException: java.lang.NullPointerException
	at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:205)
	at java.util.concurrent.FutureTask.get(FutureTask.java:80)
	at com.bigdata.service.MetadataService.splitIndexPartition(MetadataService.java:280)
	at com.bigdata.resources.SplitIndexPartitionTask$AtomicUpdateSplitIndexPartitionTask.doTask(SplitIndexPartitionTask.java:805)
	at com.bigdata.journal.AbstractTask$InnerWriteServiceCallable.call(AbstractTask.java:1829)
	at com.bigdata.concurrent.LockManagerTask.call(LockManagerTask.java:325)
	at com.bigdata.journal.AbstractTask.doUnisolatedReadWriteTask(AbstractTask.java:1605)
	at com.bigdata.journal.AbstractTask.call2(AbstractTask.java:1546)
	... 6 more
Caused by: java.lang.NullPointerException
	at com.bigdata.mdi.PartitionLocator.equals(PartitionLocator.java:231)
	at com.bigdata.service.MetadataService$SplitIndexPartitionTask.doTask(MetadataService.java:502)
	... 10 more

============================================================

Observed once: clearly a timing issue.

ERROR: 62 pool-1-thread-5         com.bigdata.resources.StoreManager$Startup.run(StoreManager.java:895): Problem during startup? : java.lang.IllegalStateException
java.lang.IllegalStateException
	at com.bigdata.resources.ResourceManager.getConcurrencyManager(ResourceManager.java:340)
	at com.bigdata.resources.StoreManager$Startup.start(StoreManager.java:963)
	at com.bigdata.resources.StoreManager$Startup.run(StoreManager.java:888)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:417)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:269)
	at java.util.concurrent.FutureTask.run(FutureTask.java:123)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:650)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:675)
	at java.lang.Thread.run()V(Unknown Source)

============================================================

1. Run U10, U100 on host3.

2. Write script and run U10, U100, U1000 on host{1,2,3}.

   - Done. pidstat is reporting under /host/client/UUID not
     /host/service/iface/UUID

   - Done. sar/pidstat parsing problem.

   - verify syslogd reporting and configure on host{2,3}.
   
     I need to look further into how the stuff gets logged by syslog
     and what, if anything, needs to be configured for this to work.
     This is only interesting to obtain a combined log of the services
     - and primarily to obtained a combined log of their ERROR level
     messages.

   - Done. reduce log levels (review log4j config).

   - Done. Reduced the branching factor default for the indices as it
     was overflowing the maximum record size.

   - document setup.

   - jini class setup, httpd, and codebase property.
   
   - Done. The various server setups either all need to be copied into
     appropriate locations on the host on which they will run or they
     need to specify a dataDir that is local to the host on which they
     will run, e.g., /var/bigdata/DataServer0

   - Done. verify jini using nio.

   - timestamp service should notify the load balancer.  this will be
     extended to be the transaction service and that will have things
     to report.

   - Startup should be event driven.

      - The server startup for bigdata should be more event driven.
        You should be able to discover jini itself and then any of the
        services in any order.  some services clearly must wait for a
        join (e.g., the client and the data service must wait for the
        timestamp service) while others can come and go as they like
        (if the load balancer is not there then things should run
        anyway but centralized reporting will not work and index
        partition moves will not happen).

      - Done? Modify to have an observable event or callback that
        assigns the service UUID and that indicates when the resource
        manager is running and refactor the LDS and DS startup logic
        to use that to configure the reporting of counters and an
        optional httpd service (at least for the LDS). The relevant
        Jini method is ServiceIDNotify().  For the moment I have
        disabled the httpd for the LDS.

   - Done. review jdk (1.6.0_03), sysstat (8.0.3) {version 7 on
     host{1,2}, solved using rpm -U to update rather than install},
     /etc/hosts, /etc/fstab{/NAS vs /nas}, jini (not really required
     on all hosts since we are bundling the jars) for consistency.
     also emacs install.

   - Done. problem with multicase. solved using unicast to host3.

   - Run multiple clients as well as multiple servers specifying
     nclients=3 and clientNum={0,1,2}

   - (*) Ala log4j, use a set named property model for property
     values.  This will let us warn people when the property value is
     not defined.
   
LDS U10 13.6k

JF host3 U10 7.7k

JF host3 U10 startAll 6.7k

====================
jrockit:

LDS U10 SIDS=true nthreads=10 bufferCapacity=100000 wrkstn : 6.6k

LDS U10 SIDS=false nthreads=10 bufferCapacity=100000 wrkstn : 7.2k

LDS U10 SIDS=false nthreads=10 bufferCapacity=100000 wrkstn 1G : 7.5k

LDS U10 SIDS=false nthreads=20 bufferCapacity=100000 wrkstn 1G : 8.4k

LDS U10 SIDS=false nthreads=30 bufferCapacity=100000 wrkstn 1G : 7.8k

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 wrkstn 1G : 8.6k

LDS U10 SIDS=false nthreads=20 bufferCapacity=100000 wrkstn 1G noText : 10.8k, 11.6k, 11.3k

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 wrkstn 1G noText : 11.6k, 12.7k

LDS U10 SIDS=false nthreads=30 bufferCapacity=200000 wrkstn 1G noText : 11.8k

LDS U10 SIDS=false nthreads=40 bufferCapacity=200000 wrkstn 1G noText : 11.9k

LDS U10 SIDS=false nthreads=20 bufferCapacity=300000 wrkstn 1G noText : 12.0k

LDS U10 SIDS=false nthreads=20 bufferCapacity=400000 wrkstn 1G noText : 12.3k

LDS U10 SIDS=false nthreads=20 bufferCapacity=500000 wrkstn 1G noText : 12.7k

LDS U10 SIDS=false nthreads=20 bufferCapacity=300000 wrkstn 1G : 9.1k

LDS U10 SIDS=false nthreads=30 bufferCapacity=1000 wrkstn : 4.5k

jdk 1.6.0_03 -server

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 host3 2G noText : 14.5k, 14.4k

LDS U10 SIDS=false nthreads=20 bufferCapacity=200000 host3 2G noText localData : 14.6k, 15.0k

LDS U100 SIDS=false nthreads=20 bufferCapacity=200000 host3 2G noText localData : 16.4k
	 Run saved as bigdata-rdf/host3-U100-LDS-countersfinal.xml (13M stmts, 3M terms)

LDS U100 SIDS=false nthreads=20 bufferCapacity=200000 host2 2G noText localData : 16.2k

LDS U1000 SIDS=false nthreads=20 bufferCapacity=200000 host2 2G noText localData : 11.4k
    #terms=32,905,188; #stmts=133,613,894; rate=11412; 68G journal.
    Run saved as: U1000-host2-countersfinal.xml

    - Done. Add moving average w/ and w/o locks.  Perhaps there is a
      queue but it is before the locks are obtained?

      Done. Also add the commit wait time and commit service time
      measures.

    - The LockManager could report the queue size and queue waiting
      time per resource.  This would let us know which resources are
      the bottlenecks.

    - Done. The LockManager could report the total #of waiting tasks,
      which is not showing up anywhere right now.

    - (*) Per-procedure/index/isolation counters {#submitted,
      #completed, task service time (queue waiting times are always
      shared by a queue but lock waiting times and task service times
      can differ by task)}.

(**) Note: Compare the performance for LDS against 16k tps with
     [autoFlush=false] (before sids and before the text indexing).
     Experiment more with buffer sizes, combining writes, etc.

============================================================

Main issues:

============================================================

(*) map/reduce processing.

    (-) If the ConcurrentDataLoader was a map/reduce job then I could
        start the whole thing by running a single master.  I would of
        course have to have map and reduce services running on the
        cluster.

    (-) ...

============================================================

(*) Optimize JOINs

    (-) LDS optimization (all indices are local, use read-committed
        view).

    (-) Scale-out optimization (essentially unrolling the loops).

    (-) Integrate optimized JOINs with Sesame 2.

    (-) Generalize the JOIN paradigm so that it can be used for things
        other than RDF.

    (-) Original LUBM benchmark.

    (-) Modified LUBM benchmark.

	Can this be modified to generate the data dynamically for
	distributed clients?

============================================================

(*) Index and other performance tuning.

    (*) Implement prefix compression algorithm using mg4j.

    (*) Try prefix compression for statement indices to see if I can
	reduce the (de-)serialization times!

    (-) Replace use of "immutable nodes" throughout and introduce the
        default prefix compression algorithm in its place.

    (-) Experiment with higher branching factors on the journal
        indices now that we will overflow periodically.

    (*) Try co-threading the search index writes with the reverse
	lexicon write, but that should only reduce a single load
	latency where as overall parallelism should reduce the total
	load latency.

    (*) Try co-threading the forward index writes for the statements with
	the reverse index writes for the term identifiers.

============================================================

(*) Scale-out performance

    - Estimate parameters for the scale-out model.

      Note: Concurrency and throughput SHOULD NOT increase as indices
      are broken down into index partitions on a single server since
      we are CPU bound in the unisolated index tasks.  However, an
      increase SHOULD be observed with or without index partition
      splits (and with or without overflow) when running on more than
      one host since we have more CPU resources.

      Find the LDS baseline for U100.

      Find the EF baseline w/ one data service and no overflow for
      U100.

      Find the EF baseline w/ two data services and no overflow for
      U100.      

      Find the intercept for a linear scale-out model using JF with
      two data services (and hence RMI) on U100 w/o overflow.
      
      Find the slope of the linear scale-out using JF where one of
      data services is located on a second machine, still w/o
      overflow.

      Done. (Multicase configuration issue was resolved.)  There is
      still a problem with multicast which is preventing scale-out
      runs.

      Note: Ideally the client will also be distributed but that is
      not critical to proving the point as the client is faster than a
      single host can service.


All runs:

    -DtextIndex=true -DstatementIdentifiers=true -Xmx=2G -Dnthreads=20
    -DbufferCapacity=200000

    Note: EF runs use -DoverflowEnabled=false

    Note: JF runs configure overflowEnabled=false in
    bigdata.properties for DataService4 on host3.

LDS-U100-host3-noText-noSids : 16784 (798910 ms (13m)) 13M stmts.

LDS-U100-host3 : 16783

EF-U100-host3-1DS-noOverflow: 12877

EF-U100-host3-2DS-noOverflow: 11332

JF-U100-host3-1DS-noOverflow: 8528

JF-U100-host3-2DS-noOverflow: 

JF-U100-host23-2DS-noOverflow: 

	*** Why does EF run so much slower than LDS?  Is the overhead
            the MDI?  The cost of setup for the client index
            operations (ClientIndexView vs DataServiceIndex)?
            Removing the existing journal files (try the EF runs with
            the [test] directory pre-deleted)?

      Retest all of the above on U1000 (requires use to use host1 or
      host2 for the additional disk space).

LDS-U1000-host2
EF-U1000-host2-1DS-noOverflow
EF-U1000-host2-2DS-noOverflow
JF-U1000-host2-2DS-noOverflow
JF-U1000-host12-2DS-noOverflow

============================================================

(*) Dynamic index partitioning

    - What cost is associated with overflow processing?

      Evaluate for:

      (a) EF with one data service;

EF-U100-host3-1DS-5M: 5965

	Note: This used a 5M initial extent and 5M maximum extent.
	There were 15 overflows in 46 minutes (a stress test run).
	The initial and maximum extent were configured in the test
	suite code.  Run was successful.  The only reported errors
	were index partition split tasks that were still executing
	when the run was terminated.

EF-U100-host3-1DS: 5922 (this is not the final tally since the client
		         died during shutdown).

        w/ 200M initial extent and 200M maximum extent.

	--------------------

      (b) for JF with one data services with on one machine; 

JF-U100-host3-1DS: 5543

	Note: This run came close to using all RAM on the machine
	80%).  The RAM was mostly going to the sole data service.  In
	fact, the data service RSS was 2G, which is maxed out.

	Note: Some overflow tasks were cancelled! (timeout).  

	Several index partition split tasks began but all were
	cancelled due to timeout.  I have increased the default
	timeout and I will run again.  I have also added counters to
	report failed and cancelled async overflow tasks.

	* Once splits start, look for the overhead of the MDS (there
          is still an MDS overhead since we need to find the locator
          to decide that there are no splits)

	* Look at the LBS host and service scores.

	* Look for index _moves_.

	* Network counters begin to become interesting.

	--------------------

      (c) for JF with two data services with on one machine; and

JF-U100-host3-2DS:

	--------------------
      
      (d) for JF with two data services on two machines.

JF-U100-host23-2DS:  ******** RUNNING NOW *********

	Note: I am only running a single client for this test.  The
	client is on host3.  This should be Ok since we are data
	service bound.  If the client can not keep up with the data
	services on two machines then that's good news :-)

	--------------------

      Choose runs where we have the data w/o overflow from above.

      Do at least one run with post-facto validation turned on.

      Note: It is important to also save the service nohup.out files
      since they show interesting data about the asynchronous index
      partition overflow tasks and any errors reported by the service
      during such tasks (those errors do not make it back to the
      clients since the tasks are run by the services themselves).

    --------------------

    Note: It is best to run EF with one data service to test index
    partitioning questions and JF to test marshalling, robustness, and
    index move questions.

    Running JF U100 on host3 right now to get some data on queue
    behavior with dynamic index partitioning.  Some questions are:

    - Change the default split point and verify build and split
      behavior on both the workstation and the server using U100 and
      one data service.

    - Do I need to increase the client timeout for Jini?  It seems
      that I probably do.  Perhaps double it to 40 seconds?  Or
      perhaps make the default much longer (1 minute, 5 minutes or
      infinite) since tasks could be queued up.

    - Are good decisions being made with regard to build and split of
      index partitions?

    - Are good decisions being made with regard to index partition
      moves?

    * Configure to hold more indices open per data service.  This
      should be done in the bigdata.properties files for each data
      service.

    * Observe the metadata service response time and verify that it
      does not become a bottleneck since the current implementation is
      NOT caching.

    * Verify that we use read-committed or read-historical operations
      whenever possible (e.g., for asynchronous overflow processing,
      joins, metadata service reads, etc).

    - Should report the #of tasks, action on each index, and the
      duration of overflow processing for each event, but that event
      oriented data does not fit well within the counters model.

(*) Load-balancing

    * Watch the load balancer and see how host utilization and service
      response time change as the run progresses, for different #of
      client threads, and as index splits occur, and as index moves
      occur.

    * Review the LBS host and service scores.  Can they predict host
      and service load well enough to move index partitions around
      without the host-based physical disk counters under linux?

    - Try U10000 reading the data from NAS with 2 clients, 10 threads
      each and 2 or 3 servers.  See if scale-out holds as we increase
      the data size.  The point of comparison is the 1B run that we
      did on server2 (single host, non-scale-out architecture,
      non-concurrent load).

    - Delay start of some data services, either on each host or on one
      of the hosts and then see how the load changes once we start
      additional data services (this could be expanded into a variety
      of hardware add and hardware fail tests).

============================================================

- Presentations

  - Provenance

  - Scale-out 

  - LUBM & Modified LUBM

  - Updated whitepapers

  - Cloud computing & travel plans.

============================================================


- MetadataService

    - Caching.

       - Collect statistics and monitor the MDS as we split the
         indices.

       - Consider caching to reduce RMI for splitting operations
         across index partitions.

- Scale-out scripts

    - Script to collect nohups, config files, and counters in a
      directory and tarball for post-mortem.

- Service and host statistics:
      
   - **** There are no majorFaultsPerSec or percentFreeDiskSpace
          numbers on a per-host basis so only defaults are being used
          for those values when computing the host score.  I need to
          write a new SAR collector to get those data.

    ** The per-host physical disk counters for linux are not being
       collected, including the major page faults per second for the
       _host_.  This is one of the primary clues so we need that.

       Write the Sar, iostat, or vmstat utility to collect these data.
       This is a bit more complex under Linux since the data are
       reported by device and the relationship of the devices to the
       file system should be explicated.

       Use [df] to report the % free space remaining?  There should be
       one value for the logical disk (perhaps), and there should be a
       report of the % free space remaining on the volume on which the
       dataDir is located and the volume on which the tmpDir is
       located.

       Note: The StoreManager also reports the free space on the
       volume for both the data dir and the temp dir.

   *** IP Addr shows up for host2 but not host1 or host3.

       192.168.20.27 is showing up as a host for DataServer3 but no
       host statistics are being reported for that IP addr (they are
       reported for the hostname instead) with the result that the IP
       addr is getting the default values for the metrics used to
       compute the host scores.

       There is still the problem with how that IP addr is getting
       reported and with whether or not any services are understood to
       be running on that host (they are not).
       
       *** A host without services running on it effects the ranking
           of the hosts and the host with the highest score. Does it
           also effect any recommendations made by the LBS?

   - Done. Modified host score to interpret high IO Wait as high
     utilization.

   - Done (mostly). The counter names need to be symbolic to avoid
     edits causing counters to not be found during analysis.

- Overflow processing

   *** If overflow processing is taken so long then there is a
       problem.  Perhaps there needs to be an alternative that lies
       between an index partition "copy" and a full compacting build,
       e.g., an incremental build that lets us discard the old
       journal.  It would generate an index segment having just the
       last committed state for the BTree absorbing writes for that
       index partition on the old journal.  The view of the index
       partition on the new journal would be updated when the task was
       complete.  A full build would have the effect of combining the
       history from several such incremental builds.

       Likewise, we may need to trade off how many splits we perform
       choosing to do incremental builds instead to keep down the
       total processing time/costs for asynchronous overflow
       processing.

       Can an analysis of the queue concurrency with locks held help
       decide whether some index partition should be moved to another
       data service?

   - Done. Asynch overflow needs to report the index and task for each
     failure as part of the exception.

   - Done. Metadata service needs to report the scale-out index name
     (or the index partition name) for "No such locator" errors.

   - Done. Add the createTime to the live journal counters.

   - Done. Move the LBS counters from /var/log/bigdata to
     /var/bigdata.  Update scripts in CVS and on the server and the
     script documentation.

   * It would be useful to have AND as well as OR semantics for
     "filter=".

   * Change the TITLE for the httpd counter view to the hostname and
     the last component of the path, e.g.:

	  hostname  ... serviceIFace ... lastComponent

     Or use the last 60 characters of the path, etc.  The point is to
     have titles that are somewhat easier to figure out.

   * It could be useful to have a view by serviceIface rather than
     host.  This could be assembled dynamically by a scan of the
     services across the hosts.

   - The IndexManager view of the LBS needs to aggregate some key
     statistics by index across the index partitions including the #of
     index entries on the data service and the time spent on the index
     (perhaps broken down by IO, serialization, key search, etc., but
     definately the aggregate time).  I am just not getting enough
     information from this view and digging down makes it too
     difficult to get the gestalt state of the indices without copying
     a correlated view of the counters into Excel.

   - Done. Review the per-service scores, but I really need to have
     more than one service on a host for this.  It should probably be
     using a response time measure, e.g., averageQueuingTime.

   - Done (problem was timestamp parsing since only the time of day
     was being reported, not the UTC time - it now uses the system
     clock). Now I am not seeing any host CPU scores aggregated by the
     load balancer.

   - Done. The normalized [score] is not being computed for hosts or
     services (it is always zero).

============================================================

Index allocation:

      The initial index allocation appears to assign much more of the
      effort to host3.  Either try random assignment or reconsider the
      2-host assignment behavior.

log files:

    The log files do not interleave the logs by timestamp.  Clearly
    there is no way to do this exactly in a distributed system.
    However it might be done better if it all went through syslog.
    Rather than an elapsed ms (or in addition) I need the UTC time in
    a field that I can readily identify.  With that I could even merge
    sort the logs together.

DataServer3:

The problem here is that there is no entry under the leftSeparatorKey
for the partition in the MDS.  I am not clear why.  I have added a
test for this condition and an exception which will provide more
information.

Caused by: java.lang.NullPointerException
	at com.bigdata.mdi.PartitionLocator.equals(PartitionLocator.java:231)
	at com.bigdata.service.MetadataService$MoveIndexPartitionTask.doTask(MetadataService.java:803)

What led up to this was:

testSPO#0	 = willBuild(name=testSPO#0)
testterm2id#0	 = willSplit(name=testterm2id#0)

and

testSPO#0	 = willMove(name=testSPO#0,target=ba2214f9-b220-43f5-9f50-8f1095ce3ec6)
testterm2id#1	 = willBuild(name=testterm2id#1)
testterm2id#2	 = willBuild(name=testterm2id#2)

and the exception was for the move.

--------------------

DataServer4:

Caused by: java.lang.RuntimeException: Expected

oldLocator={ partitionId=1, dataServices=[ba2214f9-b220-43f5-9f50-8f1095ce3ec6], leftSeparator=[], rightSeparator=null}, but
    actual={ partitionId=0, dataServices=[2eed9964-6c1c-40ee-8b3f-ceb5b30278d5], leftSeparator=[], rightSeparator=null}
	at com.bigdata.service.MetadataService$SplitIndexPartitionTask.doTask(MetadataService.java:519)

This is what was happening at the time.

__global_namespace_index#0	 = wasCopied(name=__global_namespace_index#0)
testOSP#1	 = willBuild(name=testOSP#1)
testOSP#2	 = willBuild(name=testOSP#2)
testPOS#1	 = willBuild(name=testPOS#1)
testPOS#2	 = willBuild(name=testPOS#2)
testSPO#1	 = willSplit(name=testSPO#1)
testid2term#0	 = willBuild(name=testid2term#0)
testjust#0	 = wasCopied(name=testjust#0)
testsearch#0	 = willBuild(name=testsearch#0)

So this looks like a cascade of the move problem.  So we need some
compensating action for the failed move since it seems to have been at
least partly effective even through there was an exception thrown.

--------------------

This was in the client's stack trace.  i've added the index name to
the stack trace, but again it looks linked to the problem with the SPO
MOVE failure.

Caused by: java.lang.NullPointerException
	at com.bigdata.service.ClientIndexView.splitKeys(ClientIndexView.java:1751)
	at com.bigdata.service.ClientIndexView.submit(ClientIndexView.java:877)
	at com.bigdata.rdf.store.SPOIndexWriter.call(SPOIndexWriter.java:280)
	at com.bigdata.rdf.store.SPOIndexWriter.call(SPOIndexWriter.java:73)
	... 5 more



============================================================

Integrate new rule execution layer while maintaining the old inference
engine for comparison tests (if possible).

   FIXME performance and correctness testing w/ and w/o full text
   index and sids!!!  The text indexer seems slow, but performance
   seems fine w/o it.  Make it a hard reference, etc.

   - Rip out all of the IResourceIdentifier nonsense and replace it
     with the simple String namespace. 

   - Simplify finding "contained" resource with a logical row scan
     from the namespace to fix-length bit string successor of the
     namespace - that will cover all spanned resources.  Of course,
     that scan could bridge an index partition, but that should be Ok
     since we use a global lock anyway for create/destroy.

   *** Snapshot release

       - web app for row store & how to

       - how to for Sesame 2.

       - publish current javadoc.

   *** Must defeat cache for READ-COMMITTED resource locator views.

	  Note: Currently not allowed into the cache.          

	  !!! TestDefaultResourceLocator !!!

	  Note: the global row store unisolated writes are not
          auto-committed when using a Journal, just when using a
          federation.  This means that the read-committed resource
          views are not available until an explicit commit for a
          Journal.

   *** Could have ReadCommitted BTree variant that was notified of (or
       simply noticed) commits and re-loaded itself from the new
       checkpoint.  This could be done in getRoot() and in a few
       additional methods that return fields (index metadata,
       entryCount, etc).

       Could also lookup the last commit time (or the last closure
       time) and use that timestamp rather than specifying
       READ_COMMITTED.

   *** The Justifications writer must be driven by the ISolutions
       generated by the rules.
       
       modified to mostly write the justifications -- still need to
       extract them from the solutions via the rule (since they are
       unfortunately unordered).  if I assign variable indices per my
       notes, then they will be ordered and can be indexed by position
       -- it seems like a good idea.  otherwise I will have to
       materialize the rule for each solution in order to extract the
       bindings for the justification chains.

   - Delete the "Isolation" local triple store tests?  There is no way
     to turn on isolation right now.

   - Monitor the [executorService] queue.

   - verify basic triple store semantics.
     
	- The access paths must respect the timestamp of the index
          views.  In particular, an UNISOLATED relation view MUST use
          UNISOLATED reads - if it uses READ_COMMITTED reads then it
          will not see its own writes!
	  
	  The situation is different for the rule execution layer
	  since (a) the read and write timestamps are explicitly
	  specified to the IJoinNexus; and (b) we often choose a
	  consistent historical read and unisolated writes in order to
	  have better concurrency during rule execution.

	  *** However, this means that you MUST do a commit before
              performing closure!!!  That logic probably needs to be
              encapsulated on the database, which perhaps should offer
              a "closure" method.  The method will do the commit.

	      It could also obtain an exclusive write lock on the
              database, thus raising our lock criteria to exclusive,
              exclusiveWrite, and share.  These lock levels could
              probably be refined or simplified: the concerns are (a)
              the ability to create or drop a database or relation;
              (b) the ability to perform an exlusive operation on the
              unisolated indices, such as closure; and (c) locks that
              conflict with exclusive locks so that the database or
              relation is not dropped during (b) or (b).

          *** Equally, after running a program someone needs to do a
              commit before the results will be visible to Query
              (which uses a read-committed view).
	 
     LocalTripleStore
     
     TempTripleStore

     ScaleOutTripleStore {LDS, EDS, JDS}

         Note: You CAN place indices onto specific data services
         running on a set of machines and set [enableOverflow :=
         false] such that the indices never become partitioned. In
         that case you can have optimized joins for some relations on
         one data service and for other relations on another data
         service. E.g., locating the statement indices for the triple
         store on one data service, the lexicon on another, and a repo
         on a third. This will give very good performance for Query
         and Truth Maintenance since the JOINs will be mostly
         executing against live index objects.

       - Verify serialziation of the JoinNexusFactory, setup of the
         JoinNexus on the data service, and distributed execution.

       - Export a proxy for IChunkedOrderedIterator when using an
         async process, but if LT 1000 results then fully buffer
         instead of creating a proxy (have to wait to figure that
         out).

       - Unroll loops for faster distributed joins.

       - Scale-out version of distinct term scan (rdf01, rdfs4a,
         rdfs4b), the closure over the various property sets
         (fastClosure 3, 5, 6, 7 and 9), and the MatchRule (completion
         scan against the full text index with join to the
         SPORelation).  This MAY require driving through the CURSOR
         and ITupleFilter changes.

       - Modify the JOIN to be more efficient for the scale-out case
         and compare the performance for LTS, LDS, and JDS.  The main
         change is to unroll the inner loop for each chunk of the
         outer loop and parallelize the inner loop queries.  Be
         careful with the parallelization as the thread pools are
         typically uncapped and a large #of elements are in each
         chunk.  However, the maximum parallelization will be the #of
         index partitions and the ClientIndexView should provide that
         parallelization automatically if I unroll the loop.
     
   - verify closure and truth maintenance.

      - *** Verify that justifications are maintained correctly and
            verify that we have unit tests for all of the following:

	    - SPOAccessPath#removeAll() must remove justifications
	      that are no longer supported.

	    - Running an Insert rule with justify := true must cause
              the solutions to be interpreted as justifications and
              written onto the justications index.  This is handled by
              the RDFJoinNexus.

	    - Running an Delete rule with justify := true must cause
              the justifications no longer supported once the
              statements are retracted to be retracted themselves.
              This is handled by
              AbstractTripleStore#removeStatements().

	    - We do NOT need the solutions when running a Delete rule.
	      They are only required for Query (and for Insert IFF we
	      are maintaining justifications).  Make sure that we do
	      NOT materialize solutions unless they are required!

      - *** database at once closure is the place to start.  do this
            for each of the database variants.  the point to look for
            problems is reading from the last committed view and, of
            course, getting the right answers!

	    Then try TM.

      - Modify TM to remove constraints on scaling imposed by the use
        of fully buffered iterators to avoid concurrency problems.

      - For the TempTripleStore, the data will wind up on disk in any
        case since we have to checkpoint the temporary store in order
        to have the read-committed view available.

	Maybe we should read on the UNISOLATED view for the temp
        store, which is safe for concurrent readers as long as there
        is no writer.  This is with regard to the use as a place into
        which we load the file whose closure will be computed against
        the database (the focusStore).  Once we have loaded the
        focusStore, the rules just read on it when they compute the
        closure.

	There is another place where the temp store shows up - TM for
	statement removal.  Check that out also.

      - BlockingBuffer - tune for effective chunk sizes.  The buffer
        sizes can be easily configured by the IJoinNexusFactory, as
        can parameters for timeouts, etc. for the blocking buffer's
        iterator.

      - verify fix point programs.

      - verify write of justifications (must use a different buffer
        impl to write the solution bindings).

      - verify concurrency

      - verify update of the read-behind point so that rules in each
        CLOSURE ROUND read from the commit point corresponding to the
        end of the prior round (so there must be a commit for the
        LocalTripleStore at the end of each round!)

      - verify read-committed view of kb is of the last closure
        checkpoint, not the last commit.

	Extend the federation to allow communication of the commit
        timestamp corresponding to the last closure of the kb.

      - Run some performance tests, specifically of the
        LocalTripleStore against the LDS for closure rates.

Translate Sesame2 queries to Rules dynamically so that they can
execute on the native rule engine.

   - verify that query is against the last committed state of the kb.

   - simple conjunctive query.

   - optionals

   - resolution of terms to term ids and visa versa using JOINs?

   - filters for various kinds of things, especially those that can be
     computed directly from the bit markings on the term identifiers.

   - filters that require JOINs to the lexicon and ordered scans by
     datatype literals.

- Snapshot release:

   - Move the ant build to the bigdata module and also the startup kit
     and its documentation.

           // fully grounded.
           buf.add(x, rdfType, Software); // stmt1
           
           // statements using [_bigdata] and/or [_systap] blank nodes.
           buf.add(_systap, rdfsLabel, SYSTAP);   // stmt2
           buf.add(_systap, dcCreator, _bigdata); // stmt3
           buf.add(_bigdata, rdfType, Software);  // stmt4 
           buf.add(_bigdata, rdfsLabel, bigdata); // stmt5

           // statement using a distinct blank node [_b1].
           buf.add(_b1, rdfsLabel, java);         // stmt6
           buf.add(_b1, rdfType, Software);       // stmt7

B41 := bigdata
B45 := _b1
B49 := systap

#1	Explicit     : < http://www.foo.org/x(12), rdf:type(16), http://www.foo.org/Software(8) > : id=39 stmt1
#2	Explicit     : < B41(41), rdf:type(16), http://www.foo.org/Software(8) > : id=55 
#3	Explicit     : < B41(41), rdfs:label(20), bigdata(26) > : id=59
#4	Explicit     : < B45(45), rdf:type(16), http://www.foo.org/Software(8) > : id=63
#5	Explicit     : < B45(45), rdfs:label(20), java(30) > : id=67
#6	Explicit     : < B49(49), http://purl.org/dc/terms/creator(4), B41(41) > : id=71
#7	Explicit     : < B49(49), rdfs:label(20), SYSTAP, LLC(34) > : id=75
