import net.jini.jeri.BasicILFactory;
import net.jini.jeri.BasicJeriExporter;
import net.jini.jeri.tcp.TcpServerEndpoint;

import net.jini.discovery.LookupDiscovery;
import net.jini.core.discovery.LookupLocator;
import net.jini.core.entry.Entry;
import net.jini.lookup.entry.Name;
import net.jini.lookup.entry.Comment;
import net.jini.lookup.entry.Address;
import net.jini.lookup.entry.Location;
import net.jini.lookup.entry.ServiceInfo;
import net.jini.core.lookup.ServiceTemplate;

import java.io.File;
import java.net.InetAddress;
import java.net.InetSocketAddress;
import java.util.UUID;

import com.bigdata.util.NV;
import com.bigdata.util.config.NicUtil;
import com.bigdata.journal.Options;
import com.bigdata.journal.BufferMode;
import com.bigdata.journal.jini.ha.HAJournal;
import com.bigdata.jini.lookup.entry.*;
import com.bigdata.service.IBigdataClient;
import com.bigdata.service.AbstractTransactionService;
import com.bigdata.service.jini.*;
import com.bigdata.service.jini.lookup.DataServiceFilter;
import com.bigdata.service.jini.master.ServicesTemplate;
import com.bigdata.jini.start.config.*;
import com.bigdata.zookeeper.util.ConfigMath;

import org.apache.zookeeper.ZooDefs;
import org.apache.zookeeper.data.ACL;
import org.apache.zookeeper.data.Id;

// imports for various options.
import com.bigdata.btree.IndexMetadata;
import com.bigdata.btree.keys.KeyBuilder;
import com.bigdata.rdf.sail.BigdataSail;
import com.bigdata.rdf.spo.SPORelation;
import com.bigdata.rdf.spo.SPOKeyOrder;
import com.bigdata.rdf.lexicon.LexiconRelation;
import com.bigdata.rdf.lexicon.LexiconKeyOrder;
import com.bigdata.util.Bytes;
import java.util.concurrent.TimeUnit;
import java.util.concurrent.TimeUnit.*;

/*
 * This is a sample configuration file for a highly available Journal. A
 * version of this file must be available to each HAJournalServer in the
 * pipeline.
 */

/*
 * Globals.
 */
bigdata {

   private static fedname = "benchmark";
   
   // The RMI port for the HAGlue interface (may be ZERO for a random port).
   private static rmiPort = ConfigMath.add(9080,4);

   // write replication pipeline port (listener).
   private static haPort = ConfigMath.add(9090,4);

   // The #of services in the write pipeline.
   private static replicationFactor = 5; // Note: overridden in the HA5 test suites.
   
   // The logical service identifier shared by all members of the quorum.
   private static logicalServiceId = System.getProperty("test.logicalServiceId","CI-HAJournal-1");

   // The service directory.
   // Note: Overridden by environment property when deployed.
   private static serviceDir = new File(System.getProperty("test.serviceDir",ConfigMath.getAbsolutePath(new File(new File(fedname,logicalServiceId),"E"))));
   //new File(new File(fedname,logicalServiceId),"E");
   
   // journal data directory.
   private static dataDir = serviceDir;

   // one federation, multicast discovery.
   //static private groups = LookupDiscovery.ALL_GROUPS;

   // unicast discovery or multiple setups, MUST specify groups.
   static private groups = new String[]{bigdata.fedname};

    /**
     * One or more unicast URIs of the form <code>jini://host/</code>
     * or <code>jini://host:port/</code> (no default).
     *
     * This MAY be an empty array if you want to use multicast
     * discovery <strong>and</strong> you have specified the groups as
     * LookupDiscovery.ALL_GROUPS (a <code>null</code>).
     */
    static private locators = new LookupLocator[] {

      // runs jini on the localhost using unicast locators.
      new LookupLocator("jini://localhost/")

    };

    /**
     * A common point to set the Zookeeper client's requested
     * sessionTimeout and the jini lease timeout.  The default lease
     * renewal period for jini is 5 minutes while for zookeeper it is
     * more like 5 seconds.  This puts the two systems onto a similar
     * timeout period so that a disconnected client is more likely to
     * be noticed in roughly the same period of time for either
     * system.  A value larger than the zookeeper default helps to
     * prevent client disconnects under sustained heavy load.
     *
     * If you use a short lease timeout (LT 20s), then you need to override 
     * properties properties for the net.jini.lease.LeaseRenewalManager
     * or it will run in a tight loop (it's default roundTripTime is 10s
     * and it schedules lease renewals proactively.)
     */

    // jini
    static private leaseTimeout = ConfigMath.s2ms(20); 

    // zookeeper
    static private sessionTimeout = (int)ConfigMath.s2ms(20); 

    /*
     * Configuration for default KB.
     */

    private static namespace = "kb";
    
    private static kb = new NV[] {

      /* Setup for QUADS mode without the full text index. */
       
      new NV(BigdataSail.Options.TRUTH_MAINTENANCE, "false" ),
      new NV(BigdataSail.Options.QUADS, "true"),
      new NV(BigdataSail.Options.STATEMENT_IDENTIFIERS, "false"),
      new NV(BigdataSail.Options.TEXT_INDEX, "false"),
      new NV(BigdataSail.Options.AXIOMS_CLASS,"com.bigdata.rdf.axioms.NoAxioms"),
      new NV(BigdataSail.Options.QUERY_TIME_EXPANDER, "false"),

      // Bump up the branching factor for the lexicon indices on the named kb.
      // com.bigdata.namespace.kb.lex.com.bigdata.btree.BTree.branchingFactor=400
      new NV(com.bigdata.config.Configuration.getOverrideProperty
          ( namespace + "." + LexiconRelation.NAME_LEXICON_RELATION,
            IndexMetadata.Options.BTREE_BRANCHING_FACTOR
            ), "400"),

      // Bump up the branching factor for the statement indices on the named kb.
      // com.bigdata.namespace.kb.spo.com.bigdata.btree.BTree.branchingFactor=1024
      new NV(com.bigdata.config.Configuration.getOverrideProperty
          ( namespace + "." + SPORelation.NAME_SPO_RELATION,
            IndexMetadata.Options.BTREE_BRANCHING_FACTOR
            ), "1024"),
    };

}

/*
 * Zookeeper client configuration.
 */
org.apache.zookeeper.ZooKeeper {

    /* Root znode for the federation instance. */
    zroot = "/" + bigdata.fedname;

    /* A comma separated list of host:port pairs, where the port is
     * the CLIENT port for the zookeeper server instance.
     */
    // standalone.
    servers = "localhost:2081";

    /* Session timeout (optional). */
    sessionTimeout = bigdata.sessionTimeout;

    /* 
     * ACL for the zookeeper nodes created by the bigdata federation.
     *
     * Note: zookeeper ACLs are not transmitted over secure channels
     * and are placed into plain text Configuration files by the
     * ServicesManagerServer.
     */
    acl = new ACL[] {

       new ACL(ZooDefs.Perms.ALL, new Id("world", "anyone"))

    };
}

/*
 * You should not have to edit below this line.
 */

/*
 * Jini client configuration.
 */
com.bigdata.service.jini.JiniClient {

    groups = bigdata.groups;

    locators = bigdata.locators;

    entries = new Entry[] {
      
      // Optional metadata entries.
      new Name("E"),
      
      // Note: Used to assign the ServiceID to the service.
      new ServiceUUID(UUID.fromString(System.getProperty("test.serviceId")))
       
    };

}

net.jini.lookup.JoinManager {

   maxLeaseDuration = bigdata.leaseTimeout;
   
}

/*
 * Server configuration options.
 */
com.bigdata.journal.jini.ha.HAJournalServer {

   args = new String[] {
   "-showversion",
   "-Djava.security.policy=policy.all",
   "-Dlog4j.configuration=file:log4j-E.properties",
   "-Djava.util.logging.config.file=logging-E.properties",
   "-server",
   "-Xmx1G",
   "-ea",
   "-Xdebug","-Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=1054"
   };

   serviceDir = bigdata.serviceDir;

   // Default policy.
   restorePolicy = new com.bigdata.journal.jini.ha.DefaultRestorePolicy();

   // Suppress automatic snapshots.
   snapshotPolicy = new com.bigdata.journal.jini.ha.NoSnapshotPolicy();

   logicalServiceId = bigdata.logicalServiceId;

   writePipelineAddr = new InetSocketAddress("localhost",bigdata.haPort);

   /*
   writePipelineAddr = new InetSocketAddress(//
                    InetAddress.getByName(//
                            NicUtil.getIpAddress("default.nic", "default",
                                    false// loopbackOk
                            )), //
                    bigdata.haPort
            );
   */   

   replicationFactor = bigdata.replicationFactor;

   exporter = new BasicJeriExporter(TcpServerEndpoint.getInstance(bigdata.rmiPort),
                            new BasicILFactory());

   // Use the overridden version of the HAJournal by default so we get the
   // HAGlueTest API for every test.
   HAJournalClass = "com.bigdata.journal.jini.ha.HAJournalTest";

}

/*
 * Journal configuration.
 */
com.bigdata.journal.jini.ha.HAJournal {

   properties = (NV[]) ConfigMath.concat(new NV[] {
   
      new NV(Options.FILE,
         ConfigMath.getAbsolutePath(new File(bigdata.dataDir,"bigdata-ha.jnl"))),
   
      new NV(Options.BUFFER_MODE,""+BufferMode.DiskRW),

      new NV(com.bigdata.journal.Journal.Options.GROUP_COMMIT,System.getProperty("groupCommit","false")),

      new NV(IndexMetadata.Options.WRITE_RETENTION_QUEUE_CAPACITY,"4000"),

      new NV(IndexMetadata.Options.BTREE_BRANCHING_FACTOR,"128"),

      new NV(AbstractTransactionService.Options.MIN_RELEASE_AGE,"1"),

      new NV(com.bigdata.journal.PlatformStatsPlugIn.Options.COLLECT_PLATFORM_STATISTICS,"true"),
      new NV(com.bigdata.journal.GangliaPlugIn.Options.GANGLIA_LISTEN,"true"),

   }, bigdata.kb);

}
